{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import scipy.ndimage as ndimage\n",
    "from torchvision import transforms, utils\n",
    "from toolz.curried import pipe, curry, compose\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "\n",
    "import scores\n",
    "\n",
    "import argparse\n",
    "import datetime\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_data.csv', 'training_data.csv']\n",
      "(2572, 99)\n",
      "/gpfs/pace1/project/coc-fujimoto/dmo7/citrine_data_challenge/data/training_data.csv\n"
     ]
    }
   ],
   "source": [
    "path_f=os.getcwd()\n",
    "\n",
    "path_f_1=os.path.join(path_f, 'data')\n",
    "\n",
    "\n",
    "names=[]\n",
    "for files_txts in os.listdir(path_f_1):\n",
    "    if files_txts.endswith(\".csv\"):\n",
    "        #print(files_txts)\n",
    "        names.append(files_txts)\n",
    "\n",
    "print(names)\n",
    "path_train=os.path.join(path_f_1, names[1])\n",
    "path_test=os.path.join(path_f_1, names[0])\n",
    "\n",
    "df_train=pd.read_csv(path_train)\n",
    "print(df_train.shape)\n",
    "print(path_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2572, 110)\n",
      "(2572, 110)\n",
      "(1228, 110)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formulaA</th>\n",
       "      <th>formulaB</th>\n",
       "      <th>formulaA_elements_AtomicVolume</th>\n",
       "      <th>formulaB_elements_AtomicVolume</th>\n",
       "      <th>formulaA_elements_AtomicWeight</th>\n",
       "      <th>formulaB_elements_AtomicWeight</th>\n",
       "      <th>formulaA_elements_BoilingT</th>\n",
       "      <th>formulaB_elements_BoilingT</th>\n",
       "      <th>formulaA_elements_BulkModulus</th>\n",
       "      <th>formulaB_elements_BulkModulus</th>\n",
       "      <th>...</th>\n",
       "      <th>A82B</th>\n",
       "      <th>A73B</th>\n",
       "      <th>A64B</th>\n",
       "      <th>A55B</th>\n",
       "      <th>A46B</th>\n",
       "      <th>A37B</th>\n",
       "      <th>A28B</th>\n",
       "      <th>A19B</th>\n",
       "      <th>B</th>\n",
       "      <th>Stable_compunds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89</td>\n",
       "      <td>47</td>\n",
       "      <td>37.433086</td>\n",
       "      <td>17.075648</td>\n",
       "      <td>227.0</td>\n",
       "      <td>107.868200</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>2435.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89</td>\n",
       "      <td>13</td>\n",
       "      <td>37.433086</td>\n",
       "      <td>16.594425</td>\n",
       "      <td>227.0</td>\n",
       "      <td>26.981539</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>2792.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>89</td>\n",
       "      <td>35</td>\n",
       "      <td>37.433086</td>\n",
       "      <td>42.527825</td>\n",
       "      <td>227.0</td>\n",
       "      <td>79.904000</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>89</td>\n",
       "      <td>49</td>\n",
       "      <td>37.433086</td>\n",
       "      <td>26.082658</td>\n",
       "      <td>227.0</td>\n",
       "      <td>114.818000</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>2345.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>89</td>\n",
       "      <td>81</td>\n",
       "      <td>37.433086</td>\n",
       "      <td>28.640877</td>\n",
       "      <td>227.0</td>\n",
       "      <td>204.383300</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>1746.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    formulaA  formulaB  formulaA_elements_AtomicVolume  \\\n",
       "0         89        47                       37.433086   \n",
       "1         89        13                       37.433086   \n",
       "5         89        35                       37.433086   \n",
       "10        89        49                       37.433086   \n",
       "28        89        81                       37.433086   \n",
       "\n",
       "    formulaB_elements_AtomicVolume  formulaA_elements_AtomicWeight  \\\n",
       "0                        17.075648                           227.0   \n",
       "1                        16.594425                           227.0   \n",
       "5                        42.527825                           227.0   \n",
       "10                       26.082658                           227.0   \n",
       "28                       28.640877                           227.0   \n",
       "\n",
       "    formulaB_elements_AtomicWeight  formulaA_elements_BoilingT  \\\n",
       "0                       107.868200                      3473.0   \n",
       "1                        26.981539                      3473.0   \n",
       "5                        79.904000                      3473.0   \n",
       "10                      114.818000                      3473.0   \n",
       "28                      204.383300                      3473.0   \n",
       "\n",
       "    formulaB_elements_BoilingT  formulaA_elements_BulkModulus  \\\n",
       "0                       2435.0                            0.0   \n",
       "1                       2792.0                            0.0   \n",
       "5                        332.0                            0.0   \n",
       "10                      2345.0                            0.0   \n",
       "28                      1746.0                            0.0   \n",
       "\n",
       "    formulaB_elements_BulkModulus       ...         A82B  A73B  A64B  A55B  \\\n",
       "0                           100.0       ...            0     1     0     1   \n",
       "1                            76.0       ...            0     1     0     0   \n",
       "5                             1.9       ...            0     1     0     0   \n",
       "10                            0.0       ...            0     1     0     0   \n",
       "28                           43.0       ...            0     0     0     0   \n",
       "\n",
       "    A46B  A37B  A28B  A19B  B  Stable_compunds  \n",
       "0      0     0     0     0  1                1  \n",
       "1      0     0     0     0  1                1  \n",
       "5      0     0     0     0  1                1  \n",
       "10     0     0     1     0  1                1  \n",
       "28     0     0     1     0  1                1  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stab_vector=df_train['stabilityVec'].values\n",
    "y=[]\n",
    "for x in stab_vector:\n",
    "    #print(x)\n",
    "    a=np.fromstring(x[1:-1],sep=',').astype(int)\n",
    "    y.append(a)\n",
    "y=np.array(y) \n",
    "\n",
    "df_tmp = pd.DataFrame(y, columns = ['A', 'A91B', 'A82B','A73B','A64B','A55B','A46B','A37B','A28B','A19B','B'])\n",
    "stab_vec_list=[ 'A91B', 'A82B','A73B','A64B','A55B','A46B','A37B','A28B','A19B']\n",
    "\n",
    "df_train=df_train.drop(\"stabilityVec\",axis=1) #removing the results which originally are a string\n",
    "feature_cols=list(df_train)\n",
    "\n",
    "\n",
    "\n",
    "df_train['formulaA']=df_train['formulaA_elements_Number']\n",
    "df_train['formulaB']=df_train['formulaB_elements_Number']\n",
    "\n",
    "\n",
    "df_train=pd.concat([df_train, df_tmp],axis=1)\n",
    "\n",
    "y_all=df_train[stab_vec_list]\n",
    "df_tmp_stable = pd.DataFrame( columns = ['Stable_compunds'])\n",
    "df_tmp_stable['Stable_compunds']=np.logical_not(y_all.sum(axis=1)==0).astype(int) ## A one means it has a stable value  a 0 \n",
    "\n",
    "df_train=pd.concat([df_train, df_tmp_stable],axis=1)\n",
    "print(df_train.shape)\n",
    "\n",
    "\n",
    "print(df_train.shape)\n",
    "\n",
    "\n",
    "df_stable=df_train.loc[np.logical_not(y_all.sum(axis=1)==0)]\n",
    "print(df_stable.shape)\n",
    "df_stable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new=df_stable[feature_cols]\n",
    "y_target=df_stable[stab_vec_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1228, 98)\n"
     ]
    }
   ],
   "source": [
    "## Normalizing by Zscore\n",
    "from scipy.stats import zscore\n",
    "X_train_new_Z_score=X_train_new.apply(zscore)\n",
    "print(X_train_new_Z_score.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A91B</th>\n",
       "      <th>A82B</th>\n",
       "      <th>A73B</th>\n",
       "      <th>A64B</th>\n",
       "      <th>A55B</th>\n",
       "      <th>A46B</th>\n",
       "      <th>A37B</th>\n",
       "      <th>A28B</th>\n",
       "      <th>A19B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A91B  A82B  A73B  A64B  A55B  A46B  A37B  A28B  A19B\n",
       "0      0     0     1     0     1     0     0     0     0\n",
       "1      0     0     1     0     0     0     0     0     0\n",
       "5      0     0     1     0     0     0     0     0     0\n",
       "10     0     0     1     0     0     0     0     1     0\n",
       "28     0     0     0     0     0     0     0     1     0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.argv=['']; del sys\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument_group('Optimization related arguments')\n",
    "parser.add_argument('-num_epochs', default=200, type=int, help='Epochs')\n",
    "parser.add_argument('-batch_size', default=64, type=int, help='Batch size')\n",
    "parser.add_argument('-lr', default=1e-3, type=float, help='Learning rate')\n",
    "parser.add_argument('-lr_decay_rate', default=0.9997592083, type=float, help='Decay for lr')\n",
    "parser.add_argument('-min_lr', default=5e-5, type=float, help='Minimum learning rate')\n",
    "parser.add_argument('-weight_init', default='xavier', choices=['xavier', 'kaiming'], help='Weight initialization strategy')\n",
    "parser.add_argument('-overfit', action='store_true', help='Overfit on 5 examples, meant for debugging')\n",
    "parser.add_argument('-gpuid', default=-1, type=int, help='GPU id to use')\n",
    "        \n",
    "parser.add_argument('-input_csv', default='./training_data.csv')\n",
    "parser.add_argument('-normalize', default=True)\n",
    "parser.add_argument('-test_size', default=0.33)\n",
    "\n",
    "parser.add_argument_group('Checkpointing related arguments')\n",
    "parser.add_argument('-load_path', default='', help='Checkpoint to load path from')\n",
    "parser.add_argument('-save_path', default='checkpoints/', help='Path to save checkpoints')\n",
    "parser.add_argument('-save_step', default=2, type=int, help='Save checkpoint after every save_step epochs')\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# input arguments and options\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class arg_dataset(Dataset):\n",
    "    \"\"\"Face landmarks Dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, data, y_true,test_size):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"        \n",
    "        self.data=data\n",
    "        self.y_true=y_true\n",
    "        self.test_size = test_size\n",
    "        assert len(data) == len(y_true)\n",
    "        \n",
    "    \n",
    "        X_train, X_test, y_train, y_test = train_test_split(data, y_true,\n",
    "                                                            test_size=test_size,\n",
    "                                                            shuffle=True,\n",
    "                                                            random_state=42)\n",
    "        self.data = data\n",
    "\n",
    "        self.X_train = torch.from_numpy(X_train.values).float()\n",
    "        self.y_train = torch.from_numpy(y_train.values).float()\n",
    "        self.X_test = torch.from_numpy(X_test.values).float()\n",
    "        self.y_test = torch.from_numpy(y_test.values).float()\n",
    "\n",
    "        self.num_data_points = {}\n",
    "        self.num_data_points['train'] = len(X_train)\n",
    "        self.num_data_points['test'] = len(X_test)\n",
    "        \n",
    "        self._split = 'train'\n",
    "\n",
    "    @property\n",
    "    def split(self):\n",
    "        return self._split\n",
    "\n",
    "    @split.setter\n",
    "    def split(self, split):\n",
    "        self._split = split\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # methods to override - __len__ and __getitem__ methods\n",
    "    # ------------------------------------------------------------------------\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_data_points[self._split]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dtype = self._split\n",
    "        item = {'index': idx}\n",
    "        item['features'] = self.X_train[idx,:]\n",
    "        item['outputs'] = self.y_train[idx,:]\n",
    "        return item\n",
    "\n",
    "    #-------------------------------------------------------------------------\n",
    "    # collate function utilized by dataloader for batching\n",
    "    #-------------------------------------------------------------------------\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        dtype = self._split\n",
    "        merged_batch = {key: [d[key] for d in batch] for key in batch[0]}\n",
    "        out = {}\n",
    "        for key in merged_batch:\n",
    "            if key in {'index'}:\n",
    "                out[key] = merged_batch[key]\n",
    "            else:\n",
    "                out[key] = torch.stack(merged_batch[key], 0)\n",
    "\n",
    "        batch_keys = ['features', 'outputs']\n",
    "        return {key: out[key] for key in batch_keys}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(98, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(60, 30),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(30, 15),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(15, 9)\n",
    "        )\n",
    "    def forward(self, batch):\n",
    "        return self.layers(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = arg_dataset(X_train_new_Z_score, y_target,.33)\n",
    "dataloader = DataLoader(dataset,\n",
    "                        batch_size=args.batch_size,\n",
    "                        shuffle=True,\n",
    "                        collate_fn=dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 iter per epoch.\n"
     ]
    }
   ],
   "source": [
    "setattr(args, 'iter_per_epoch', math.ceil(dataset.num_data_points['train'] / args.batch_size))\n",
    "print(\"{} iter per epoch.\".format(args.iter_per_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network(model_args)\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "criterion = nn.MultiLabelSoftMarginLoss()\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=args.lr_decay_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start time: 23-Jan-2019-05:32:05\n",
      "[0:00:00.390055][Epoch:   1][Iter:      5][Loss: 0.669745][val loss: 0.666676][accuracy: 0.018229][lr: 0.001000]\n",
      "[0:00:01.747813][Epoch:   1][Iter:      5][Loss: 0.664610][val loss: 0.646542][accuracy: 0.031250][lr: 0.000998]\n",
      "[0:00:02.341572][Epoch:   2][Iter:     18][Loss: 0.661996][val loss: 0.638974][accuracy: 0.026042][lr: 0.000997]\n",
      "[0:00:03.919283][Epoch:   2][Iter:     18][Loss: 0.646100][val loss: 0.599980][accuracy: 0.057292][lr: 0.000994]\n",
      "[0:00:04.487911][Epoch:   3][Iter:     31][Loss: 0.638523][val loss: 0.587757][accuracy: 0.062500][lr: 0.000994]\n",
      "[0:00:06.277722][Epoch:   3][Iter:     31][Loss: 0.606604][val loss: 0.524428][accuracy: 0.088542][lr: 0.000991]\n",
      "[0:00:06.864728][Epoch:   4][Iter:     44][Loss: 0.594324][val loss: 0.509541][accuracy: 0.062500][lr: 0.000991]\n",
      "[0:00:08.667184][Epoch:   4][Iter:     44][Loss: 0.554157][val loss: 0.477895][accuracy: 0.062500][lr: 0.000988]\n",
      "[0:00:09.111633][Epoch:   5][Iter:     57][Loss: 0.543558][val loss: 0.471198][accuracy: 0.062500][lr: 0.000988]\n",
      "[0:00:10.854654][Epoch:   5][Iter:     57][Loss: 0.514677][val loss: 0.460705][accuracy: 0.091146][lr: 0.000985]\n",
      "[0:00:11.367560][Epoch:   6][Iter:     70][Loss: 0.508101][val loss: 0.462926][accuracy: 0.085938][lr: 0.000984]\n",
      "[0:00:12.967114][Epoch:   6][Iter:     70][Loss: 0.489955][val loss: 0.450739][accuracy: 0.109375][lr: 0.000982]\n",
      "[0:00:13.457560][Epoch:   7][Iter:     83][Loss: 0.485488][val loss: 0.452326][accuracy: 0.091146][lr: 0.000981]\n",
      "[0:00:15.175363][Epoch:   7][Iter:     83][Loss: 0.473039][val loss: 0.441249][accuracy: 0.117188][lr: 0.000979]\n",
      "[0:00:15.769240][Epoch:   8][Iter:     96][Loss: 0.472469][val loss: 0.451111][accuracy: 0.109375][lr: 0.000978]\n",
      "[0:00:17.510412][Epoch:   8][Iter:     96][Loss: 0.462967][val loss: 0.440106][accuracy: 0.130208][lr: 0.000976]\n",
      "[0:00:17.967788][Epoch:   9][Iter:    109][Loss: 0.459124][val loss: 0.438383][accuracy: 0.111979][lr: 0.000975]\n",
      "[0:00:19.460998][Epoch:   9][Iter:    109][Loss: 0.451611][val loss: 0.441724][accuracy: 0.127604][lr: 0.000973]\n",
      "[0:00:20.098740][Epoch:  10][Iter:    122][Loss: 0.448964][val loss: 0.439957][accuracy: 0.119792][lr: 0.000972]\n",
      "[0:00:21.810148][Epoch:  10][Iter:    122][Loss: 0.443327][val loss: 0.431396][accuracy: 0.119792][lr: 0.000970]\n",
      "[0:00:22.277456][Epoch:  11][Iter:    135][Loss: 0.442881][val loss: 0.427907][accuracy: 0.138021][lr: 0.000969]\n",
      "[0:00:23.944376][Epoch:  11][Iter:    135][Loss: 0.439240][val loss: 0.421510][accuracy: 0.125000][lr: 0.000967]\n",
      "[0:00:24.448277][Epoch:  12][Iter:    148][Loss: 0.435605][val loss: 0.428545][accuracy: 0.127604][lr: 0.000966]\n",
      "[0:00:25.719172][Epoch:  12][Iter:    148][Loss: 0.435027][val loss: 0.420056][accuracy: 0.130208][lr: 0.000964]\n",
      "[0:00:26.134318][Epoch:  13][Iter:    161][Loss: 0.432981][val loss: 0.428281][accuracy: 0.109375][lr: 0.000963]\n",
      "[0:00:27.834603][Epoch:  13][Iter:    161][Loss: 0.431803][val loss: 0.423620][accuracy: 0.143229][lr: 0.000961]\n",
      "[0:00:28.443729][Epoch:  14][Iter:    174][Loss: 0.427145][val loss: 0.418960][accuracy: 0.125000][lr: 0.000960]\n",
      "[0:00:29.984856][Epoch:  14][Iter:    174][Loss: 0.425132][val loss: 0.417591][accuracy: 0.151042][lr: 0.000958]\n",
      "[0:00:30.270919][Epoch:  15][Iter:    187][Loss: 0.424521][val loss: 0.413887][accuracy: 0.140625][lr: 0.000957]\n",
      "[0:00:31.701015][Epoch:  15][Iter:    187][Loss: 0.423501][val loss: 0.416296][accuracy: 0.148438][lr: 0.000955]\n",
      "[0:00:32.419676][Epoch:  16][Iter:    200][Loss: 0.422475][val loss: 0.420267][accuracy: 0.122396][lr: 0.000954]\n",
      "[0:00:34.409816][Epoch:  16][Iter:    200][Loss: 0.418615][val loss: 0.420637][accuracy: 0.158854][lr: 0.000952]\n",
      "[0:00:34.956191][Epoch:  17][Iter:    213][Loss: 0.419465][val loss: 0.422094][accuracy: 0.153646][lr: 0.000951]\n",
      "[0:00:36.999529][Epoch:  17][Iter:    213][Loss: 0.418596][val loss: 0.414323][accuracy: 0.151042][lr: 0.000949]\n",
      "[0:00:37.558050][Epoch:  18][Iter:    226][Loss: 0.416800][val loss: 0.416701][accuracy: 0.127604][lr: 0.000948]\n",
      "[0:00:39.182214][Epoch:  18][Iter:    226][Loss: 0.415245][val loss: 0.410288][accuracy: 0.148438][lr: 0.000946]\n",
      "[0:00:39.721972][Epoch:  19][Iter:    239][Loss: 0.411303][val loss: 0.408349][accuracy: 0.125000][lr: 0.000945]\n",
      "[0:00:41.252783][Epoch:  19][Iter:    239][Loss: 0.410617][val loss: 0.413955][accuracy: 0.145833][lr: 0.000943]\n",
      "[0:00:41.812510][Epoch:  20][Iter:    252][Loss: 0.408165][val loss: 0.414728][accuracy: 0.125000][lr: 0.000942]\n",
      "[0:00:43.993817][Epoch:  20][Iter:    252][Loss: 0.408140][val loss: 0.411812][accuracy: 0.130208][lr: 0.000940]\n",
      "[0:00:44.391760][Epoch:  21][Iter:    265][Loss: 0.411030][val loss: 0.412653][accuracy: 0.130208][lr: 0.000939]\n",
      "[0:00:46.207622][Epoch:  21][Iter:    265][Loss: 0.408926][val loss: 0.404004][accuracy: 0.148438][lr: 0.000937]\n",
      "[0:00:46.549643][Epoch:  22][Iter:    278][Loss: 0.412562][val loss: 0.412698][accuracy: 0.127604][lr: 0.000936]\n",
      "[0:00:48.406625][Epoch:  22][Iter:    278][Loss: 0.407386][val loss: 0.410775][accuracy: 0.127604][lr: 0.000934]\n",
      "[0:00:49.054833][Epoch:  23][Iter:    291][Loss: 0.406032][val loss: 0.403254][accuracy: 0.151042][lr: 0.000933]\n",
      "[0:00:50.621214][Epoch:  23][Iter:    291][Loss: 0.406004][val loss: 0.395482][accuracy: 0.130208][lr: 0.000931]\n",
      "[0:00:51.283016][Epoch:  24][Iter:    304][Loss: 0.405219][val loss: 0.401516][accuracy: 0.153646][lr: 0.000931]\n",
      "[0:00:52.484242][Epoch:  24][Iter:    304][Loss: 0.404217][val loss: 0.394312][accuracy: 0.158854][lr: 0.000928]\n",
      "[0:00:53.086923][Epoch:  25][Iter:    317][Loss: 0.401901][val loss: 0.404581][accuracy: 0.119792][lr: 0.000928]\n",
      "[0:00:54.867258][Epoch:  25][Iter:    317][Loss: 0.399400][val loss: 0.401328][accuracy: 0.156250][lr: 0.000925]\n",
      "[0:00:55.352454][Epoch:  26][Iter:    330][Loss: 0.397573][val loss: 0.403272][accuracy: 0.143229][lr: 0.000925]\n",
      "[0:00:57.051050][Epoch:  26][Iter:    330][Loss: 0.395252][val loss: 0.394863][accuracy: 0.171875][lr: 0.000922]\n",
      "[0:00:57.655527][Epoch:  27][Iter:    343][Loss: 0.400492][val loss: 0.400919][accuracy: 0.140625][lr: 0.000922]\n",
      "[0:00:59.219079][Epoch:  27][Iter:    343][Loss: 0.394673][val loss: 0.398848][accuracy: 0.135417][lr: 0.000920]\n",
      "[0:00:59.832535][Epoch:  28][Iter:    356][Loss: 0.393895][val loss: 0.401892][accuracy: 0.135417][lr: 0.000919]\n",
      "[0:01:01.068490][Epoch:  28][Iter:    356][Loss: 0.394960][val loss: 0.396536][accuracy: 0.164062][lr: 0.000917]\n",
      "[0:01:01.561204][Epoch:  29][Iter:    369][Loss: 0.396205][val loss: 0.395852][accuracy: 0.177083][lr: 0.000916]\n",
      "[0:01:03.286538][Epoch:  29][Iter:    369][Loss: 0.395908][val loss: 0.397760][accuracy: 0.156250][lr: 0.000914]\n",
      "[0:01:03.780593][Epoch:  30][Iter:    382][Loss: 0.393481][val loss: 0.397250][accuracy: 0.174479][lr: 0.000913]\n",
      "[0:01:05.534902][Epoch:  30][Iter:    382][Loss: 0.393596][val loss: 0.394281][accuracy: 0.153646][lr: 0.000911]\n",
      "[0:01:06.160051][Epoch:  31][Iter:    395][Loss: 0.392256][val loss: 0.402382][accuracy: 0.132812][lr: 0.000910]\n",
      "[0:01:08.325172][Epoch:  31][Iter:    395][Loss: 0.393409][val loss: 0.395733][accuracy: 0.153646][lr: 0.000908]\n",
      "[0:01:08.922189][Epoch:  32][Iter:    408][Loss: 0.393198][val loss: 0.392018][accuracy: 0.158854][lr: 0.000908]\n",
      "[0:01:10.970346][Epoch:  32][Iter:    408][Loss: 0.391158][val loss: 0.392849][accuracy: 0.171875][lr: 0.000905]\n",
      "[0:01:11.576154][Epoch:  33][Iter:    421][Loss: 0.389969][val loss: 0.390554][accuracy: 0.166667][lr: 0.000905]\n",
      "[0:01:13.778288][Epoch:  33][Iter:    421][Loss: 0.389270][val loss: 0.395855][accuracy: 0.153646][lr: 0.000902]\n",
      "[0:01:14.429920][Epoch:  34][Iter:    434][Loss: 0.388665][val loss: 0.392193][accuracy: 0.158854][lr: 0.000902]\n",
      "[0:01:16.396198][Epoch:  34][Iter:    434][Loss: 0.385439][val loss: 0.391644][accuracy: 0.153646][lr: 0.000900]\n",
      "[0:01:16.890989][Epoch:  35][Iter:    447][Loss: 0.385481][val loss: 0.391858][accuracy: 0.182292][lr: 0.000899]\n",
      "[0:01:18.955519][Epoch:  35][Iter:    447][Loss: 0.388002][val loss: 0.384027][accuracy: 0.195312][lr: 0.000897]\n",
      "[0:01:19.690492][Epoch:  36][Iter:    460][Loss: 0.389904][val loss: 0.398992][accuracy: 0.161458][lr: 0.000896]\n",
      "[0:01:21.886161][Epoch:  36][Iter:    460][Loss: 0.387816][val loss: 0.391748][accuracy: 0.166667][lr: 0.000894]\n",
      "[0:01:22.776927][Epoch:  37][Iter:    473][Loss: 0.389230][val loss: 0.392552][accuracy: 0.182292][lr: 0.000893]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0:01:25.018104][Epoch:  37][Iter:    473][Loss: 0.385855][val loss: 0.391034][accuracy: 0.166667][lr: 0.000891]\n",
      "[0:01:25.796281][Epoch:  38][Iter:    486][Loss: 0.386991][val loss: 0.392193][accuracy: 0.164062][lr: 0.000891]\n",
      "[0:01:28.108865][Epoch:  38][Iter:    486][Loss: 0.385045][val loss: 0.390774][accuracy: 0.161458][lr: 0.000888]\n",
      "[0:01:28.679656][Epoch:  39][Iter:    499][Loss: 0.380409][val loss: 0.387492][accuracy: 0.161458][lr: 0.000888]\n",
      "[0:01:30.458209][Epoch:  39][Iter:    499][Loss: 0.377356][val loss: 0.384832][accuracy: 0.182292][lr: 0.000886]\n",
      "[0:01:30.946014][Epoch:  40][Iter:    512][Loss: 0.381513][val loss: 0.388127][accuracy: 0.153646][lr: 0.000885]\n",
      "[0:01:32.918407][Epoch:  40][Iter:    512][Loss: 0.380386][val loss: 0.390825][accuracy: 0.177083][lr: 0.000883]\n",
      "[0:01:33.549798][Epoch:  41][Iter:    525][Loss: 0.379032][val loss: 0.390661][accuracy: 0.161458][lr: 0.000882]\n",
      "[0:01:35.126626][Epoch:  41][Iter:    525][Loss: 0.378442][val loss: 0.386431][accuracy: 0.177083][lr: 0.000880]\n",
      "[0:01:35.618751][Epoch:  42][Iter:    538][Loss: 0.378307][val loss: 0.388983][accuracy: 0.174479][lr: 0.000880]\n",
      "[0:01:37.243925][Epoch:  42][Iter:    538][Loss: 0.379677][val loss: 0.389824][accuracy: 0.174479][lr: 0.000877]\n",
      "[0:01:37.746651][Epoch:  43][Iter:    551][Loss: 0.377749][val loss: 0.388717][accuracy: 0.177083][lr: 0.000877]\n",
      "[0:01:38.975820][Epoch:  43][Iter:    551][Loss: 0.378281][val loss: 0.393121][accuracy: 0.161458][lr: 0.000875]\n",
      "[0:01:39.317699][Epoch:  44][Iter:    564][Loss: 0.376097][val loss: 0.385597][accuracy: 0.179688][lr: 0.000874]\n",
      "[0:01:40.439992][Epoch:  44][Iter:    564][Loss: 0.377497][val loss: 0.392496][accuracy: 0.171875][lr: 0.000872]\n",
      "[0:01:40.766553][Epoch:  45][Iter:    577][Loss: 0.375787][val loss: 0.395287][accuracy: 0.177083][lr: 0.000871]\n",
      "[0:01:41.889931][Epoch:  45][Iter:    577][Loss: 0.375710][val loss: 0.384215][accuracy: 0.177083][lr: 0.000869]\n",
      "[0:01:42.175757][Epoch:  46][Iter:    590][Loss: 0.379878][val loss: 0.379586][accuracy: 0.192708][lr: 0.000869]\n",
      "[0:01:43.237510][Epoch:  46][Iter:    590][Loss: 0.376819][val loss: 0.390698][accuracy: 0.164062][lr: 0.000867]\n",
      "[0:01:43.614916][Epoch:  47][Iter:    603][Loss: 0.373409][val loss: 0.382448][accuracy: 0.190104][lr: 0.000866]\n",
      "[0:01:45.056484][Epoch:  47][Iter:    603][Loss: 0.373492][val loss: 0.384529][accuracy: 0.177083][lr: 0.000864]\n",
      "[0:01:45.352778][Epoch:  48][Iter:    616][Loss: 0.376663][val loss: 0.380533][accuracy: 0.182292][lr: 0.000863]\n",
      "[0:01:46.754655][Epoch:  48][Iter:    616][Loss: 0.373456][val loss: 0.382881][accuracy: 0.184896][lr: 0.000861]\n",
      "[0:01:47.198291][Epoch:  49][Iter:    629][Loss: 0.374309][val loss: 0.386688][accuracy: 0.179688][lr: 0.000860]\n",
      "[0:01:48.577675][Epoch:  49][Iter:    629][Loss: 0.373135][val loss: 0.389663][accuracy: 0.190104][lr: 0.000858]\n",
      "[0:01:48.903017][Epoch:  50][Iter:    642][Loss: 0.372992][val loss: 0.394350][accuracy: 0.169271][lr: 0.000858]\n",
      "[0:01:49.959713][Epoch:  50][Iter:    642][Loss: 0.372178][val loss: 0.385480][accuracy: 0.179688][lr: 0.000856]\n",
      "[0:01:50.329708][Epoch:  51][Iter:    655][Loss: 0.369143][val loss: 0.386232][accuracy: 0.171875][lr: 0.000855]\n",
      "[0:01:51.186754][Epoch:  51][Iter:    655][Loss: 0.370472][val loss: 0.389643][accuracy: 0.151042][lr: 0.000853]\n",
      "[0:01:51.561594][Epoch:  52][Iter:    668][Loss: 0.369699][val loss: 0.387373][accuracy: 0.187500][lr: 0.000852]\n",
      "[0:01:52.919077][Epoch:  52][Iter:    668][Loss: 0.367762][val loss: 0.395227][accuracy: 0.169271][lr: 0.000850]\n",
      "[0:01:53.225844][Epoch:  53][Iter:    681][Loss: 0.369105][val loss: 0.380846][accuracy: 0.177083][lr: 0.000850]\n",
      "[0:01:54.469965][Epoch:  53][Iter:    681][Loss: 0.367766][val loss: 0.383127][accuracy: 0.187500][lr: 0.000848]\n",
      "[0:01:54.872183][Epoch:  54][Iter:    694][Loss: 0.369046][val loss: 0.380322][accuracy: 0.177083][lr: 0.000847]\n",
      "[0:01:56.058376][Epoch:  54][Iter:    694][Loss: 0.366145][val loss: 0.382286][accuracy: 0.166667][lr: 0.000845]\n",
      "[0:01:56.590263][Epoch:  55][Iter:    707][Loss: 0.369335][val loss: 0.378271][accuracy: 0.187500][lr: 0.000844]\n",
      "[0:01:57.990490][Epoch:  55][Iter:    707][Loss: 0.367080][val loss: 0.381174][accuracy: 0.174479][lr: 0.000842]\n",
      "[0:01:58.437986][Epoch:  56][Iter:    720][Loss: 0.368487][val loss: 0.384894][accuracy: 0.164062][lr: 0.000842]\n",
      "[0:02:00.358101][Epoch:  56][Iter:    720][Loss: 0.367252][val loss: 0.381284][accuracy: 0.190104][lr: 0.000840]\n",
      "[0:02:00.603280][Epoch:  57][Iter:    733][Loss: 0.364319][val loss: 0.383744][accuracy: 0.190104][lr: 0.000839]\n",
      "[0:02:02.405014][Epoch:  57][Iter:    733][Loss: 0.364929][val loss: 0.387686][accuracy: 0.169271][lr: 0.000837]\n",
      "[0:02:02.981526][Epoch:  58][Iter:    746][Loss: 0.361756][val loss: 0.383668][accuracy: 0.182292][lr: 0.000837]\n",
      "[0:02:05.024263][Epoch:  58][Iter:    746][Loss: 0.361336][val loss: 0.373948][accuracy: 0.171875][lr: 0.000835]\n",
      "[0:02:05.568712][Epoch:  59][Iter:    759][Loss: 0.360932][val loss: 0.383369][accuracy: 0.182292][lr: 0.000834]\n",
      "[0:02:07.182852][Epoch:  59][Iter:    759][Loss: 0.358599][val loss: 0.375653][accuracy: 0.187500][lr: 0.000832]\n",
      "[0:02:07.867357][Epoch:  60][Iter:    772][Loss: 0.359123][val loss: 0.376646][accuracy: 0.205729][lr: 0.000831]\n",
      "[0:02:09.839455][Epoch:  60][Iter:    772][Loss: 0.359907][val loss: 0.379317][accuracy: 0.195312][lr: 0.000829]\n",
      "[0:02:10.313332][Epoch:  61][Iter:    785][Loss: 0.360329][val loss: 0.383085][accuracy: 0.179688][lr: 0.000829]\n",
      "[0:02:12.062938][Epoch:  61][Iter:    785][Loss: 0.358487][val loss: 0.385309][accuracy: 0.187500][lr: 0.000827]\n",
      "[0:02:12.406598][Epoch:  62][Iter:    798][Loss: 0.359775][val loss: 0.382358][accuracy: 0.148438][lr: 0.000826]\n",
      "[0:02:13.897230][Epoch:  62][Iter:    798][Loss: 0.359308][val loss: 0.377636][accuracy: 0.184896][lr: 0.000824]\n",
      "[0:02:14.403668][Epoch:  63][Iter:    811][Loss: 0.359882][val loss: 0.385398][accuracy: 0.192708][lr: 0.000824]\n",
      "[0:02:15.963754][Epoch:  63][Iter:    811][Loss: 0.359646][val loss: 0.389787][accuracy: 0.182292][lr: 0.000822]\n",
      "[0:02:16.578529][Epoch:  64][Iter:    824][Loss: 0.357546][val loss: 0.382584][accuracy: 0.184896][lr: 0.000821]\n",
      "[0:02:18.430529][Epoch:  64][Iter:    824][Loss: 0.356273][val loss: 0.385114][accuracy: 0.182292][lr: 0.000819]\n",
      "[0:02:18.903643][Epoch:  65][Iter:    837][Loss: 0.360074][val loss: 0.381135][accuracy: 0.210938][lr: 0.000818]\n",
      "[0:02:20.626958][Epoch:  65][Iter:    837][Loss: 0.359885][val loss: 0.380060][accuracy: 0.171875][lr: 0.000816]\n",
      "[0:02:21.182176][Epoch:  66][Iter:    850][Loss: 0.355657][val loss: 0.383192][accuracy: 0.169271][lr: 0.000816]\n",
      "[0:02:22.634710][Epoch:  66][Iter:    850][Loss: 0.355934][val loss: 0.388739][accuracy: 0.164062][lr: 0.000814]\n",
      "[0:02:23.174054][Epoch:  67][Iter:    863][Loss: 0.357203][val loss: 0.376701][accuracy: 0.166667][lr: 0.000813]\n",
      "[0:02:24.866839][Epoch:  67][Iter:    863][Loss: 0.355662][val loss: 0.381795][accuracy: 0.171875][lr: 0.000811]\n",
      "[0:02:25.100885][Epoch:  68][Iter:    876][Loss: 0.354689][val loss: 0.377719][accuracy: 0.208333][lr: 0.000811]\n",
      "[0:02:26.845214][Epoch:  68][Iter:    876][Loss: 0.353666][val loss: 0.383112][accuracy: 0.182292][lr: 0.000809]\n",
      "[0:02:27.369741][Epoch:  69][Iter:    889][Loss: 0.352347][val loss: 0.387362][accuracy: 0.169271][lr: 0.000808]\n",
      "[0:02:29.081570][Epoch:  69][Iter:    889][Loss: 0.354062][val loss: 0.384377][accuracy: 0.197917][lr: 0.000806]\n",
      "[0:02:29.530180][Epoch:  70][Iter:    902][Loss: 0.354840][val loss: 0.385475][accuracy: 0.177083][lr: 0.000806]\n",
      "[0:02:30.950521][Epoch:  70][Iter:    902][Loss: 0.353631][val loss: 0.388097][accuracy: 0.192708][lr: 0.000804]\n",
      "[0:02:31.492566][Epoch:  71][Iter:    915][Loss: 0.351774][val loss: 0.376947][accuracy: 0.195312][lr: 0.000803]\n",
      "[0:02:33.068678][Epoch:  71][Iter:    915][Loss: 0.352927][val loss: 0.382100][accuracy: 0.205729][lr: 0.000801]\n",
      "[0:02:33.599335][Epoch:  72][Iter:    928][Loss: 0.352903][val loss: 0.385577][accuracy: 0.192708][lr: 0.000801]\n",
      "[0:02:35.258683][Epoch:  72][Iter:    928][Loss: 0.352146][val loss: 0.383171][accuracy: 0.187500][lr: 0.000799]\n",
      "[0:02:35.714960][Epoch:  73][Iter:    941][Loss: 0.354046][val loss: 0.382781][accuracy: 0.203125][lr: 0.000798]\n",
      "[0:02:37.502847][Epoch:  73][Iter:    941][Loss: 0.351957][val loss: 0.369074][accuracy: 0.205729][lr: 0.000796]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0:02:37.991931][Epoch:  74][Iter:    954][Loss: 0.354375][val loss: 0.376693][accuracy: 0.192708][lr: 0.000796]\n",
      "[0:02:40.182070][Epoch:  74][Iter:    954][Loss: 0.350927][val loss: 0.377760][accuracy: 0.195312][lr: 0.000794]\n",
      "[0:02:41.067468][Epoch:  75][Iter:    967][Loss: 0.352272][val loss: 0.378233][accuracy: 0.195312][lr: 0.000793]\n",
      "[0:02:43.255662][Epoch:  75][Iter:    967][Loss: 0.350527][val loss: 0.377634][accuracy: 0.190104][lr: 0.000791]\n",
      "[0:02:43.819618][Epoch:  76][Iter:    980][Loss: 0.350838][val loss: 0.381604][accuracy: 0.184896][lr: 0.000791]\n",
      "[0:02:45.405721][Epoch:  76][Iter:    980][Loss: 0.349089][val loss: 0.381208][accuracy: 0.182292][lr: 0.000789]\n",
      "[0:02:46.038227][Epoch:  77][Iter:    993][Loss: 0.347591][val loss: 0.382406][accuracy: 0.174479][lr: 0.000788]\n",
      "[0:02:48.584743][Epoch:  77][Iter:    993][Loss: 0.351005][val loss: 0.383890][accuracy: 0.184896][lr: 0.000786]\n",
      "[0:02:49.597480][Epoch:  78][Iter:   1006][Loss: 0.352526][val loss: 0.387877][accuracy: 0.182292][lr: 0.000786]\n",
      "[0:02:52.099063][Epoch:  78][Iter:   1006][Loss: 0.348826][val loss: 0.379444][accuracy: 0.190104][lr: 0.000784]\n",
      "[0:02:52.691471][Epoch:  79][Iter:   1019][Loss: 0.349196][val loss: 0.378821][accuracy: 0.190104][lr: 0.000783]\n",
      "[0:02:54.930924][Epoch:  79][Iter:   1019][Loss: 0.346038][val loss: 0.383220][accuracy: 0.161458][lr: 0.000781]\n",
      "[0:02:55.845535][Epoch:  80][Iter:   1032][Loss: 0.345522][val loss: 0.387419][accuracy: 0.179688][lr: 0.000781]\n",
      "[0:02:58.192854][Epoch:  80][Iter:   1032][Loss: 0.344676][val loss: 0.387964][accuracy: 0.187500][lr: 0.000779]\n",
      "[0:02:58.762085][Epoch:  81][Iter:   1045][Loss: 0.345204][val loss: 0.378970][accuracy: 0.200521][lr: 0.000778]\n",
      "[0:03:00.943920][Epoch:  81][Iter:   1045][Loss: 0.344968][val loss: 0.384850][accuracy: 0.190104][lr: 0.000777]\n",
      "[0:03:01.611139][Epoch:  82][Iter:   1058][Loss: 0.342747][val loss: 0.390239][accuracy: 0.190104][lr: 0.000776]\n",
      "[0:03:03.498867][Epoch:  82][Iter:   1058][Loss: 0.344331][val loss: 0.383254][accuracy: 0.200521][lr: 0.000774]\n",
      "[0:03:04.333350][Epoch:  83][Iter:   1071][Loss: 0.342730][val loss: 0.386363][accuracy: 0.182292][lr: 0.000774]\n",
      "[0:03:06.581477][Epoch:  83][Iter:   1071][Loss: 0.344914][val loss: 0.375113][accuracy: 0.190104][lr: 0.000772]\n",
      "[0:03:07.364280][Epoch:  84][Iter:   1084][Loss: 0.341869][val loss: 0.377699][accuracy: 0.203125][lr: 0.000771]\n",
      "[0:03:09.503211][Epoch:  84][Iter:   1084][Loss: 0.342974][val loss: 0.389537][accuracy: 0.184896][lr: 0.000769]\n",
      "[0:03:10.059908][Epoch:  85][Iter:   1097][Loss: 0.342324][val loss: 0.382540][accuracy: 0.208333][lr: 0.000769]\n",
      "[0:03:12.119790][Epoch:  85][Iter:   1097][Loss: 0.341926][val loss: 0.385965][accuracy: 0.200521][lr: 0.000767]\n",
      "[0:03:12.856897][Epoch:  86][Iter:   1110][Loss: 0.341148][val loss: 0.385727][accuracy: 0.187500][lr: 0.000766]\n",
      "[0:03:14.598427][Epoch:  86][Iter:   1110][Loss: 0.335900][val loss: 0.383240][accuracy: 0.205729][lr: 0.000765]\n",
      "[0:03:15.305936][Epoch:  87][Iter:   1123][Loss: 0.336514][val loss: 0.386220][accuracy: 0.192708][lr: 0.000764]\n",
      "[0:03:16.993685][Epoch:  87][Iter:   1123][Loss: 0.337904][val loss: 0.377290][accuracy: 0.169271][lr: 0.000762]\n",
      "[0:03:17.453995][Epoch:  88][Iter:   1136][Loss: 0.338383][val loss: 0.386031][accuracy: 0.182292][lr: 0.000762]\n",
      "[0:03:19.134306][Epoch:  88][Iter:   1136][Loss: 0.339600][val loss: 0.382891][accuracy: 0.205729][lr: 0.000760]\n",
      "[0:03:19.638004][Epoch:  89][Iter:   1149][Loss: 0.340894][val loss: 0.390303][accuracy: 0.205729][lr: 0.000759]\n",
      "[0:03:21.358708][Epoch:  89][Iter:   1149][Loss: 0.339346][val loss: 0.389789][accuracy: 0.208333][lr: 0.000757]\n",
      "[0:03:21.971086][Epoch:  90][Iter:   1162][Loss: 0.338844][val loss: 0.379617][accuracy: 0.184896][lr: 0.000757]\n",
      "[0:03:23.784896][Epoch:  90][Iter:   1162][Loss: 0.342286][val loss: 0.381904][accuracy: 0.200521][lr: 0.000755]\n",
      "[0:03:24.343192][Epoch:  91][Iter:   1175][Loss: 0.340119][val loss: 0.378558][accuracy: 0.203125][lr: 0.000754]\n",
      "[0:03:26.027440][Epoch:  91][Iter:   1175][Loss: 0.339363][val loss: 0.392900][accuracy: 0.166667][lr: 0.000753]\n",
      "[0:03:26.606486][Epoch:  92][Iter:   1188][Loss: 0.340346][val loss: 0.382943][accuracy: 0.213542][lr: 0.000752]\n",
      "[0:03:28.702088][Epoch:  92][Iter:   1188][Loss: 0.339504][val loss: 0.388498][accuracy: 0.169271][lr: 0.000750]\n",
      "[0:03:29.188712][Epoch:  93][Iter:   1201][Loss: 0.342810][val loss: 0.382321][accuracy: 0.216146][lr: 0.000750]\n",
      "[0:03:30.992846][Epoch:  93][Iter:   1201][Loss: 0.338663][val loss: 0.380078][accuracy: 0.205729][lr: 0.000748]\n",
      "[0:03:31.439549][Epoch:  94][Iter:   1214][Loss: 0.340279][val loss: 0.381705][accuracy: 0.195312][lr: 0.000747]\n",
      "[0:03:33.069449][Epoch:  94][Iter:   1214][Loss: 0.341960][val loss: 0.380972][accuracy: 0.182292][lr: 0.000746]\n",
      "[0:03:33.457457][Epoch:  95][Iter:   1227][Loss: 0.337139][val loss: 0.385265][accuracy: 0.208333][lr: 0.000745]\n",
      "[0:03:35.662587][Epoch:  95][Iter:   1227][Loss: 0.338039][val loss: 0.386183][accuracy: 0.164062][lr: 0.000743]\n",
      "[0:03:36.359583][Epoch:  96][Iter:   1240][Loss: 0.334891][val loss: 0.380629][accuracy: 0.210938][lr: 0.000743]\n",
      "[0:03:38.426649][Epoch:  96][Iter:   1240][Loss: 0.335615][val loss: 0.389591][accuracy: 0.205729][lr: 0.000741]\n",
      "[0:03:39.135238][Epoch:  97][Iter:   1253][Loss: 0.335140][val loss: 0.385798][accuracy: 0.203125][lr: 0.000740]\n",
      "[0:03:40.896281][Epoch:  97][Iter:   1253][Loss: 0.334393][val loss: 0.385124][accuracy: 0.203125][lr: 0.000739]\n",
      "[0:03:41.560947][Epoch:  98][Iter:   1266][Loss: 0.335456][val loss: 0.394464][accuracy: 0.195312][lr: 0.000738]\n",
      "[0:03:43.220788][Epoch:  98][Iter:   1266][Loss: 0.332809][val loss: 0.386561][accuracy: 0.203125][lr: 0.000736]\n",
      "[0:03:43.814085][Epoch:  99][Iter:   1279][Loss: 0.333675][val loss: 0.383224][accuracy: 0.216146][lr: 0.000736]\n",
      "[0:03:45.922765][Epoch:  99][Iter:   1279][Loss: 0.334151][val loss: 0.384080][accuracy: 0.179688][lr: 0.000734]\n",
      "[0:03:46.595350][Epoch: 100][Iter:   1292][Loss: 0.331546][val loss: 0.377446][accuracy: 0.195312][lr: 0.000733]\n",
      "[0:03:47.783433][Epoch: 100][Iter:   1292][Loss: 0.330545][val loss: 0.385388][accuracy: 0.184896][lr: 0.000732]\n",
      "[0:03:48.152600][Epoch: 101][Iter:   1305][Loss: 0.331197][val loss: 0.391557][accuracy: 0.187500][lr: 0.000731]\n",
      "[0:03:49.461152][Epoch: 101][Iter:   1305][Loss: 0.332042][val loss: 0.376278][accuracy: 0.195312][lr: 0.000729]\n",
      "[0:03:50.022339][Epoch: 102][Iter:   1318][Loss: 0.331479][val loss: 0.389114][accuracy: 0.187500][lr: 0.000729]\n",
      "[0:03:51.569852][Epoch: 102][Iter:   1318][Loss: 0.333158][val loss: 0.387231][accuracy: 0.213542][lr: 0.000727]\n",
      "[0:03:52.085986][Epoch: 103][Iter:   1331][Loss: 0.331083][val loss: 0.375108][accuracy: 0.210938][lr: 0.000727]\n",
      "[0:03:53.372893][Epoch: 103][Iter:   1331][Loss: 0.331168][val loss: 0.380075][accuracy: 0.221354][lr: 0.000725]\n",
      "[0:03:53.826742][Epoch: 104][Iter:   1344][Loss: 0.330821][val loss: 0.386319][accuracy: 0.195312][lr: 0.000724]\n",
      "[0:03:55.371653][Epoch: 104][Iter:   1344][Loss: 0.331970][val loss: 0.386342][accuracy: 0.190104][lr: 0.000723]\n",
      "[0:03:55.812781][Epoch: 105][Iter:   1357][Loss: 0.330106][val loss: 0.387988][accuracy: 0.203125][lr: 0.000722]\n",
      "[0:03:57.697625][Epoch: 105][Iter:   1357][Loss: 0.329458][val loss: 0.390035][accuracy: 0.221354][lr: 0.000720]\n",
      "[0:03:58.194642][Epoch: 106][Iter:   1370][Loss: 0.330553][val loss: 0.396199][accuracy: 0.179688][lr: 0.000720]\n",
      "[0:03:59.678046][Epoch: 106][Iter:   1370][Loss: 0.335677][val loss: 0.388121][accuracy: 0.213542][lr: 0.000718]\n",
      "[0:04:00.132198][Epoch: 107][Iter:   1383][Loss: 0.332513][val loss: 0.382636][accuracy: 0.208333][lr: 0.000718]\n",
      "[0:04:01.724370][Epoch: 107][Iter:   1383][Loss: 0.329640][val loss: 0.385018][accuracy: 0.205729][lr: 0.000716]\n",
      "[0:04:02.303173][Epoch: 108][Iter:   1396][Loss: 0.331804][val loss: 0.387615][accuracy: 0.195312][lr: 0.000715]\n",
      "[0:04:04.062529][Epoch: 108][Iter:   1396][Loss: 0.328674][val loss: 0.396584][accuracy: 0.179688][lr: 0.000714]\n",
      "[0:04:04.480510][Epoch: 109][Iter:   1409][Loss: 0.330151][val loss: 0.381458][accuracy: 0.210938][lr: 0.000713]\n",
      "[0:04:06.081981][Epoch: 109][Iter:   1409][Loss: 0.333424][val loss: 0.389796][accuracy: 0.192708][lr: 0.000711]\n",
      "[0:04:06.599945][Epoch: 110][Iter:   1422][Loss: 0.329737][val loss: 0.389146][accuracy: 0.190104][lr: 0.000711]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0:04:08.149762][Epoch: 110][Iter:   1422][Loss: 0.330222][val loss: 0.381399][accuracy: 0.187500][lr: 0.000709]\n",
      "[0:04:08.614528][Epoch: 111][Iter:   1435][Loss: 0.328895][val loss: 0.390295][accuracy: 0.221354][lr: 0.000709]\n",
      "[0:04:10.096176][Epoch: 111][Iter:   1435][Loss: 0.329852][val loss: 0.393786][accuracy: 0.187500][lr: 0.000707]\n",
      "[0:04:10.393427][Epoch: 112][Iter:   1448][Loss: 0.332715][val loss: 0.395040][accuracy: 0.187500][lr: 0.000706]\n",
      "[0:04:11.407910][Epoch: 112][Iter:   1448][Loss: 0.331749][val loss: 0.385067][accuracy: 0.184896][lr: 0.000705]\n",
      "[0:04:11.641832][Epoch: 113][Iter:   1461][Loss: 0.331810][val loss: 0.387956][accuracy: 0.190104][lr: 0.000704]\n",
      "[0:04:12.994308][Epoch: 113][Iter:   1461][Loss: 0.330864][val loss: 0.387964][accuracy: 0.190104][lr: 0.000703]\n",
      "[0:04:13.436163][Epoch: 114][Iter:   1474][Loss: 0.333095][val loss: 0.391090][accuracy: 0.203125][lr: 0.000702]\n",
      "[0:04:15.080436][Epoch: 114][Iter:   1474][Loss: 0.328345][val loss: 0.395536][accuracy: 0.187500][lr: 0.000700]\n",
      "[0:04:15.583863][Epoch: 115][Iter:   1487][Loss: 0.326851][val loss: 0.397845][accuracy: 0.179688][lr: 0.000700]\n",
      "[0:04:17.543752][Epoch: 115][Iter:   1487][Loss: 0.327435][val loss: 0.388090][accuracy: 0.231771][lr: 0.000698]\n",
      "[0:04:17.985539][Epoch: 116][Iter:   1500][Loss: 0.327460][val loss: 0.391428][accuracy: 0.190104][lr: 0.000698]\n",
      "[0:04:19.537099][Epoch: 116][Iter:   1500][Loss: 0.329522][val loss: 0.388593][accuracy: 0.226562][lr: 0.000696]\n",
      "[0:04:20.195446][Epoch: 117][Iter:   1513][Loss: 0.326145][val loss: 0.393710][accuracy: 0.187500][lr: 0.000695]\n",
      "[0:04:22.122696][Epoch: 117][Iter:   1513][Loss: 0.326452][val loss: 0.378262][accuracy: 0.195312][lr: 0.000694]\n",
      "[0:04:22.767977][Epoch: 118][Iter:   1526][Loss: 0.329924][val loss: 0.384797][accuracy: 0.205729][lr: 0.000693]\n",
      "[0:04:24.685462][Epoch: 118][Iter:   1526][Loss: 0.328345][val loss: 0.380124][accuracy: 0.213542][lr: 0.000692]\n",
      "[0:04:25.373029][Epoch: 119][Iter:   1539][Loss: 0.328056][val loss: 0.384414][accuracy: 0.216146][lr: 0.000691]\n",
      "[0:04:27.541340][Epoch: 119][Iter:   1539][Loss: 0.326369][val loss: 0.387467][accuracy: 0.177083][lr: 0.000689]\n",
      "[0:04:28.135845][Epoch: 120][Iter:   1552][Loss: 0.327241][val loss: 0.386127][accuracy: 0.203125][lr: 0.000689]\n",
      "[0:04:30.041581][Epoch: 120][Iter:   1552][Loss: 0.323792][val loss: 0.388793][accuracy: 0.197917][lr: 0.000687]\n",
      "[0:04:30.741514][Epoch: 121][Iter:   1565][Loss: 0.327975][val loss: 0.392222][accuracy: 0.208333][lr: 0.000687]\n",
      "[0:04:33.166758][Epoch: 121][Iter:   1565][Loss: 0.327151][val loss: 0.401432][accuracy: 0.184896][lr: 0.000685]\n",
      "[0:04:33.817310][Epoch: 122][Iter:   1578][Loss: 0.327457][val loss: 0.388917][accuracy: 0.213542][lr: 0.000685]\n",
      "[0:04:35.602525][Epoch: 122][Iter:   1578][Loss: 0.326449][val loss: 0.380112][accuracy: 0.200521][lr: 0.000683]\n",
      "[0:04:35.902599][Epoch: 123][Iter:   1591][Loss: 0.323439][val loss: 0.400648][accuracy: 0.184896][lr: 0.000683]\n",
      "[0:04:37.059936][Epoch: 123][Iter:   1591][Loss: 0.323092][val loss: 0.397669][accuracy: 0.192708][lr: 0.000681]\n",
      "[0:04:37.668821][Epoch: 124][Iter:   1604][Loss: 0.322973][val loss: 0.388405][accuracy: 0.197917][lr: 0.000680]\n",
      "[0:04:39.636773][Epoch: 124][Iter:   1604][Loss: 0.323282][val loss: 0.390136][accuracy: 0.226562][lr: 0.000679]\n",
      "[0:04:40.303855][Epoch: 125][Iter:   1617][Loss: 0.324404][val loss: 0.383380][accuracy: 0.184896][lr: 0.000678]\n",
      "[0:04:41.939617][Epoch: 125][Iter:   1617][Loss: 0.320867][val loss: 0.397477][accuracy: 0.187500][lr: 0.000677]\n",
      "[0:04:42.512637][Epoch: 126][Iter:   1630][Loss: 0.322417][val loss: 0.404465][accuracy: 0.187500][lr: 0.000676]\n",
      "[0:04:44.340482][Epoch: 126][Iter:   1630][Loss: 0.319809][val loss: 0.383958][accuracy: 0.197917][lr: 0.000675]\n",
      "[0:04:45.102139][Epoch: 127][Iter:   1643][Loss: 0.321100][val loss: 0.397980][accuracy: 0.200521][lr: 0.000674]\n",
      "[0:04:47.252398][Epoch: 127][Iter:   1643][Loss: 0.324880][val loss: 0.390336][accuracy: 0.200521][lr: 0.000672]\n",
      "[0:04:48.005049][Epoch: 128][Iter:   1656][Loss: 0.323880][val loss: 0.391126][accuracy: 0.203125][lr: 0.000672]\n",
      "[0:04:49.714752][Epoch: 128][Iter:   1656][Loss: 0.325534][val loss: 0.389878][accuracy: 0.218750][lr: 0.000670]\n",
      "[0:04:50.306640][Epoch: 129][Iter:   1669][Loss: 0.322182][val loss: 0.389780][accuracy: 0.195312][lr: 0.000670]\n",
      "[0:04:52.260984][Epoch: 129][Iter:   1669][Loss: 0.321319][val loss: 0.395445][accuracy: 0.205729][lr: 0.000668]\n",
      "[0:04:52.662788][Epoch: 130][Iter:   1682][Loss: 0.321717][val loss: 0.390931][accuracy: 0.223958][lr: 0.000668]\n",
      "[0:04:54.590466][Epoch: 130][Iter:   1682][Loss: 0.323685][val loss: 0.383136][accuracy: 0.190104][lr: 0.000666]\n",
      "[0:04:55.220213][Epoch: 131][Iter:   1695][Loss: 0.322496][val loss: 0.391565][accuracy: 0.190104][lr: 0.000666]\n",
      "[0:04:57.100607][Epoch: 131][Iter:   1695][Loss: 0.322401][val loss: 0.399247][accuracy: 0.187500][lr: 0.000664]\n",
      "[0:04:57.573646][Epoch: 132][Iter:   1708][Loss: 0.322423][val loss: 0.392013][accuracy: 0.171875][lr: 0.000664]\n",
      "[0:04:59.128265][Epoch: 132][Iter:   1708][Loss: 0.321196][val loss: 0.389300][accuracy: 0.177083][lr: 0.000662]\n",
      "[0:04:59.646057][Epoch: 133][Iter:   1721][Loss: 0.320203][val loss: 0.399481][accuracy: 0.195312][lr: 0.000661]\n",
      "[0:05:01.182830][Epoch: 133][Iter:   1721][Loss: 0.317895][val loss: 0.392814][accuracy: 0.187500][lr: 0.000660]\n",
      "[0:05:01.623713][Epoch: 134][Iter:   1734][Loss: 0.316229][val loss: 0.393617][accuracy: 0.161458][lr: 0.000659]\n",
      "[0:05:03.212269][Epoch: 134][Iter:   1734][Loss: 0.317535][val loss: 0.387786][accuracy: 0.200521][lr: 0.000658]\n",
      "[0:05:03.705045][Epoch: 135][Iter:   1747][Loss: 0.317270][val loss: 0.388391][accuracy: 0.200521][lr: 0.000657]\n",
      "[0:05:05.286921][Epoch: 135][Iter:   1747][Loss: 0.316208][val loss: 0.386055][accuracy: 0.187500][lr: 0.000656]\n",
      "[0:05:05.759586][Epoch: 136][Iter:   1760][Loss: 0.316235][val loss: 0.395030][accuracy: 0.208333][lr: 0.000655]\n",
      "[0:05:07.396049][Epoch: 136][Iter:   1760][Loss: 0.316502][val loss: 0.392637][accuracy: 0.200521][lr: 0.000654]\n",
      "[0:05:07.963700][Epoch: 137][Iter:   1773][Loss: 0.318130][val loss: 0.397687][accuracy: 0.182292][lr: 0.000653]\n",
      "[0:05:09.759114][Epoch: 137][Iter:   1773][Loss: 0.317634][val loss: 0.391353][accuracy: 0.192708][lr: 0.000652]\n",
      "[0:05:10.406327][Epoch: 138][Iter:   1786][Loss: 0.319067][val loss: 0.393191][accuracy: 0.179688][lr: 0.000651]\n",
      "[0:05:11.718717][Epoch: 138][Iter:   1786][Loss: 0.315427][val loss: 0.387532][accuracy: 0.218750][lr: 0.000650]\n",
      "[0:05:12.051456][Epoch: 139][Iter:   1799][Loss: 0.313541][val loss: 0.397498][accuracy: 0.203125][lr: 0.000649]\n",
      "[0:05:12.794491][Epoch: 139][Iter:   1799][Loss: 0.316936][val loss: 0.396785][accuracy: 0.190104][lr: 0.000648]\n",
      "[0:05:13.095585][Epoch: 140][Iter:   1812][Loss: 0.314517][val loss: 0.390329][accuracy: 0.182292][lr: 0.000647]\n",
      "[0:05:14.911181][Epoch: 140][Iter:   1812][Loss: 0.314934][val loss: 0.395326][accuracy: 0.197917][lr: 0.000646]\n",
      "[0:05:15.481369][Epoch: 141][Iter:   1825][Loss: 0.312796][val loss: 0.397659][accuracy: 0.177083][lr: 0.000645]\n",
      "[0:05:17.601086][Epoch: 141][Iter:   1825][Loss: 0.314107][val loss: 0.385834][accuracy: 0.213542][lr: 0.000644]\n",
      "[0:05:18.153915][Epoch: 142][Iter:   1838][Loss: 0.316098][val loss: 0.390002][accuracy: 0.210938][lr: 0.000643]\n",
      "[0:05:20.104663][Epoch: 142][Iter:   1838][Loss: 0.317925][val loss: 0.399925][accuracy: 0.182292][lr: 0.000642]\n",
      "[0:05:20.606648][Epoch: 143][Iter:   1851][Loss: 0.318007][val loss: 0.385782][accuracy: 0.218750][lr: 0.000641]\n",
      "[0:05:22.062459][Epoch: 143][Iter:   1851][Loss: 0.316728][val loss: 0.391446][accuracy: 0.179688][lr: 0.000640]\n",
      "[0:05:22.437633][Epoch: 144][Iter:   1864][Loss: 0.316741][val loss: 0.401640][accuracy: 0.210938][lr: 0.000639]\n",
      "[0:05:23.569682][Epoch: 144][Iter:   1864][Loss: 0.314026][val loss: 0.382854][accuracy: 0.229167][lr: 0.000638]\n",
      "[0:05:24.138956][Epoch: 145][Iter:   1877][Loss: 0.315772][val loss: 0.391397][accuracy: 0.218750][lr: 0.000637]\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "# training\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "net.train()\n",
    "os.makedirs(args.save_path, exist_ok=True)\n",
    "\n",
    "running_loss = 0.0\n",
    "train_begin = datetime.datetime.utcnow()\n",
    "print(\"Training start time: {}\".format(datetime.datetime.strftime(train_begin, '%d-%b-%Y-%H:%M:%S')))\n",
    "\n",
    "log_loss = []\n",
    "for epoch in range(1, model_args.num_epochs + 1):\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        for key in batch:\n",
    "            batch[key] = Variable(batch[key])\n",
    "            if args.gpuid >= 0:\n",
    "                batch[key] = batch[key].cuda()\n",
    "\n",
    "        # --------------------------------------------------------------------\n",
    "        # forward-backward pass and optimizer step\n",
    "        # --------------------------------------------------------------------\n",
    "        net_out = net(batch['features'])\n",
    "\n",
    "        cur_loss = criterion(net_out, batch['outputs'])\n",
    "        cur_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        gc.collect()\n",
    "\n",
    "        # --------------------------------------------------------------------\n",
    "        # update running loss and decay learning rates\n",
    "        # --------------------------------------------------------------------\n",
    "        #train_loss = cur_loss.data[0]\n",
    "        train_loss = cur_loss.item()\n",
    "        if running_loss > 0.0:\n",
    "            running_loss = 0.95 * running_loss + 0.05 * train_loss\n",
    "        else:\n",
    "            running_loss = train_loss \n",
    "\n",
    "        if optimizer.param_groups[0]['lr'] > args.min_lr:\n",
    "            scheduler.step()\n",
    "\n",
    "\n",
    "        # --------------------------------------------------------------------\n",
    "        # print after every few iterations\n",
    "        # --------------------------------------------------------------------\n",
    "        if i % 10 == 0:\n",
    "            test_losses = []\n",
    "            accuracy = []\n",
    "            for i in range(int(dataset.num_data_points['test']/args.batch_size)):\n",
    "                test_feat = dataset.X_test[i*args.batch_size:(i+1)*args.batch_size, :]\n",
    "                test_labels = dataset.y_test[i*args.batch_size:(i+1)*args.batch_size, :]\n",
    "                test_feat = Variable(test_feat)\n",
    "                test_labels = Variable(test_labels)\n",
    "                if args.gpuid >= 0:\n",
    "                    test_feat = test_feat.cuda()\n",
    "                    test_labels = test_labels.cuda()\n",
    "                net_out = net(test_feat)\n",
    "                cur_loss = criterion(net_out, test_labels)\n",
    "                test_losses.append(cur_loss.item())\n",
    "                \n",
    "                y_pred = torch.sigmoid(net_out).data > 0.5\n",
    "                y_pred = y_pred.cpu().numpy()\n",
    "                accuracy.append((test_labels.cpu().numpy() == y_pred).all(axis=1))\n",
    "\n",
    "            validation_loss = np.mean(test_losses)\n",
    "            \n",
    "            accuracy = np.mean(accuracy)\n",
    "\n",
    "            iteration = (epoch - 1) * args.iter_per_epoch + i\n",
    "\n",
    "            log_loss.append((epoch,\n",
    "                             iteration,\n",
    "                             running_loss,\n",
    "                             train_loss,\n",
    "                             validation_loss,\n",
    "                             accuracy,\n",
    "                             optimizer.param_groups[0]['lr']))\n",
    "\n",
    "            # print current time, running average, learning rate, iteration, epoch\n",
    "            print(\"[{}][Epoch: {:3d}][Iter: {:6d}][Loss: {:6f}][val loss: {:6f}][accuracy: {:6f}][lr: {:7f}]\".format(\n",
    "                datetime.datetime.utcnow() - train_begin, epoch,\n",
    "                    iteration, running_loss, validation_loss, accuracy,\n",
    "                    optimizer.param_groups[0]['lr']))\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # save checkpoints and final model\n",
    "    # ------------------------------------------------------------------------\n",
    "    if epoch % args.save_step == 0:\n",
    "        torch.save({\n",
    "            'net': net.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'model_args': net.args\n",
    "        }, os.path.join(args.save_path, 'model_epoch_{}.pth'.format(epoch)))\n",
    "\n",
    "torch.save({\n",
    "    'net': net.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "    'model_args': net.args\n",
    "}, os.path.join(args.save_path, 'model_final.pth'))\n",
    "\n",
    "np.save(os.path.join(args.save_path, 'log_loss'), log_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
