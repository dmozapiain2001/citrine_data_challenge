{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import scipy.ndimage as ndimage\n",
    "from torchvision import transforms, utils\n",
    "from toolz.curried import pipe, curry, compose\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "\n",
    "import scores\n",
    "\n",
    "import argparse\n",
    "import datetime\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_data.csv', 'training_data.csv']\n",
      "(2572, 99)\n",
      "/gpfs/pace1/project/coc-fujimoto/dmo7/citrine_data_challenge/data/training_data.csv\n"
     ]
    }
   ],
   "source": [
    "path_f=os.getcwd()\n",
    "\n",
    "path_f_1=os.path.join(path_f, 'data')\n",
    "\n",
    "\n",
    "names=[]\n",
    "for files_txts in os.listdir(path_f_1):\n",
    "    if files_txts.endswith(\".csv\"):\n",
    "        #print(files_txts)\n",
    "        names.append(files_txts)\n",
    "\n",
    "print(names)\n",
    "path_train=os.path.join(path_f_1, names[1])\n",
    "path_test=os.path.join(path_f_1, names[0])\n",
    "\n",
    "df_train=pd.read_csv(path_train)\n",
    "print(df_train.shape)\n",
    "print(path_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2572, 110)\n",
      "(2572, 110)\n",
      "(1228, 110)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formulaA</th>\n",
       "      <th>formulaB</th>\n",
       "      <th>formulaA_elements_AtomicVolume</th>\n",
       "      <th>formulaB_elements_AtomicVolume</th>\n",
       "      <th>formulaA_elements_AtomicWeight</th>\n",
       "      <th>formulaB_elements_AtomicWeight</th>\n",
       "      <th>formulaA_elements_BoilingT</th>\n",
       "      <th>formulaB_elements_BoilingT</th>\n",
       "      <th>formulaA_elements_BulkModulus</th>\n",
       "      <th>formulaB_elements_BulkModulus</th>\n",
       "      <th>...</th>\n",
       "      <th>A82B</th>\n",
       "      <th>A73B</th>\n",
       "      <th>A64B</th>\n",
       "      <th>A55B</th>\n",
       "      <th>A46B</th>\n",
       "      <th>A37B</th>\n",
       "      <th>A28B</th>\n",
       "      <th>A19B</th>\n",
       "      <th>B</th>\n",
       "      <th>Stable_compunds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89</td>\n",
       "      <td>47</td>\n",
       "      <td>37.433086</td>\n",
       "      <td>17.075648</td>\n",
       "      <td>227.0</td>\n",
       "      <td>107.868200</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>2435.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89</td>\n",
       "      <td>13</td>\n",
       "      <td>37.433086</td>\n",
       "      <td>16.594425</td>\n",
       "      <td>227.0</td>\n",
       "      <td>26.981539</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>2792.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>89</td>\n",
       "      <td>35</td>\n",
       "      <td>37.433086</td>\n",
       "      <td>42.527825</td>\n",
       "      <td>227.0</td>\n",
       "      <td>79.904000</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>89</td>\n",
       "      <td>49</td>\n",
       "      <td>37.433086</td>\n",
       "      <td>26.082658</td>\n",
       "      <td>227.0</td>\n",
       "      <td>114.818000</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>2345.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>89</td>\n",
       "      <td>81</td>\n",
       "      <td>37.433086</td>\n",
       "      <td>28.640877</td>\n",
       "      <td>227.0</td>\n",
       "      <td>204.383300</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>1746.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    formulaA  formulaB  formulaA_elements_AtomicVolume  \\\n",
       "0         89        47                       37.433086   \n",
       "1         89        13                       37.433086   \n",
       "5         89        35                       37.433086   \n",
       "10        89        49                       37.433086   \n",
       "28        89        81                       37.433086   \n",
       "\n",
       "    formulaB_elements_AtomicVolume  formulaA_elements_AtomicWeight  \\\n",
       "0                        17.075648                           227.0   \n",
       "1                        16.594425                           227.0   \n",
       "5                        42.527825                           227.0   \n",
       "10                       26.082658                           227.0   \n",
       "28                       28.640877                           227.0   \n",
       "\n",
       "    formulaB_elements_AtomicWeight  formulaA_elements_BoilingT  \\\n",
       "0                       107.868200                      3473.0   \n",
       "1                        26.981539                      3473.0   \n",
       "5                        79.904000                      3473.0   \n",
       "10                      114.818000                      3473.0   \n",
       "28                      204.383300                      3473.0   \n",
       "\n",
       "    formulaB_elements_BoilingT  formulaA_elements_BulkModulus  \\\n",
       "0                       2435.0                            0.0   \n",
       "1                       2792.0                            0.0   \n",
       "5                        332.0                            0.0   \n",
       "10                      2345.0                            0.0   \n",
       "28                      1746.0                            0.0   \n",
       "\n",
       "    formulaB_elements_BulkModulus       ...         A82B  A73B  A64B  A55B  \\\n",
       "0                           100.0       ...            0     1     0     1   \n",
       "1                            76.0       ...            0     1     0     0   \n",
       "5                             1.9       ...            0     1     0     0   \n",
       "10                            0.0       ...            0     1     0     0   \n",
       "28                           43.0       ...            0     0     0     0   \n",
       "\n",
       "    A46B  A37B  A28B  A19B  B  Stable_compunds  \n",
       "0      0     0     0     0  1                1  \n",
       "1      0     0     0     0  1                1  \n",
       "5      0     0     0     0  1                1  \n",
       "10     0     0     1     0  1                1  \n",
       "28     0     0     1     0  1                1  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stab_vector=df_train['stabilityVec'].values\n",
    "y=[]\n",
    "for x in stab_vector:\n",
    "    #print(x)\n",
    "    a=np.fromstring(x[1:-1],sep=',').astype(int)\n",
    "    y.append(a)\n",
    "y=np.array(y) \n",
    "\n",
    "df_tmp = pd.DataFrame(y, columns = ['A', 'A91B', 'A82B','A73B','A64B','A55B','A46B','A37B','A28B','A19B','B'])\n",
    "stab_vec_list=[ 'A91B', 'A82B','A73B','A64B','A55B','A46B','A37B','A28B','A19B']\n",
    "\n",
    "df_train=df_train.drop(\"stabilityVec\",axis=1) #removing the results which originally are a string\n",
    "feature_cols=list(df_train)\n",
    "\n",
    "\n",
    "\n",
    "df_train['formulaA']=df_train['formulaA_elements_Number']\n",
    "df_train['formulaB']=df_train['formulaB_elements_Number']\n",
    "\n",
    "\n",
    "df_train=pd.concat([df_train, df_tmp],axis=1)\n",
    "\n",
    "y_all=df_train[stab_vec_list]\n",
    "df_tmp_stable = pd.DataFrame( columns = ['Stable_compunds'])\n",
    "df_tmp_stable['Stable_compunds']=np.logical_not(y_all.sum(axis=1)==0).astype(int) ## A one means it has a stable value  a 0 \n",
    "\n",
    "df_train=pd.concat([df_train, df_tmp_stable],axis=1)\n",
    "print(df_train.shape)\n",
    "\n",
    "\n",
    "print(df_train.shape)\n",
    "\n",
    "\n",
    "df_stable=df_train.loc[np.logical_not(y_all.sum(axis=1)==0)]\n",
    "print(df_stable.shape)\n",
    "df_stable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new=df_stable[feature_cols]\n",
    "y_target=df_stable[stab_vec_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1228, 98)\n"
     ]
    }
   ],
   "source": [
    "## Normalizing by Zscore\n",
    "from scipy.stats import zscore\n",
    "X_train_new_Z_score=X_train_new.apply(zscore)\n",
    "print(X_train_new_Z_score.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A91B</th>\n",
       "      <th>A82B</th>\n",
       "      <th>A73B</th>\n",
       "      <th>A64B</th>\n",
       "      <th>A55B</th>\n",
       "      <th>A46B</th>\n",
       "      <th>A37B</th>\n",
       "      <th>A28B</th>\n",
       "      <th>A19B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A91B  A82B  A73B  A64B  A55B  A46B  A37B  A28B  A19B\n",
       "0      0     0     1     0     1     0     0     0     0\n",
       "1      0     0     1     0     0     0     0     0     0\n",
       "5      0     0     1     0     0     0     0     0     0\n",
       "10     0     0     1     0     0     0     0     1     0\n",
       "28     0     0     0     0     0     0     0     1     0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.argv=['']; del sys\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument_group('Optimization related arguments')\n",
    "parser.add_argument('-num_epochs', default=200, type=int, help='Epochs')\n",
    "parser.add_argument('-batch_size', default=64, type=int, help='Batch size')\n",
    "parser.add_argument('-lr', default=1e-3, type=float, help='Learning rate')\n",
    "parser.add_argument('-lr_decay_rate', default=0.9997592083, type=float, help='Decay for lr')\n",
    "parser.add_argument('-min_lr', default=5e-5, type=float, help='Minimum learning rate')\n",
    "parser.add_argument('-weight_init', default='xavier', choices=['xavier', 'kaiming'], help='Weight initialization strategy')\n",
    "parser.add_argument('-overfit', action='store_true', help='Overfit on 5 examples, meant for debugging')\n",
    "parser.add_argument('-gpuid', default=-1, type=int, help='GPU id to use')\n",
    "        \n",
    "parser.add_argument('-input_csv', default='./training_data.csv')\n",
    "parser.add_argument('-normalize', default=True)\n",
    "parser.add_argument('-test_size', default=0.33)\n",
    "\n",
    "parser.add_argument_group('Checkpointing related arguments')\n",
    "parser.add_argument('-load_path', default='', help='Checkpoint to load path from')\n",
    "parser.add_argument('-save_path', default='checkpoints/', help='Path to save checkpoints')\n",
    "parser.add_argument('-save_step', default=2, type=int, help='Save checkpoint after every save_step epochs')\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# input arguments and options\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class arg_dataset(Dataset):\n",
    "    \"\"\"Face landmarks Dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, data, y_true,test_size):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"        \n",
    "        self.data=data\n",
    "        self.y_true=y_true\n",
    "        self.test_size = test_size\n",
    "        assert len(data) == len(y_true)\n",
    "        \n",
    "    \n",
    "        X_train, X_test, y_train, y_test = train_test_split(data, y_true,\n",
    "                                                            test_size=test_size,\n",
    "                                                            shuffle=True,\n",
    "                                                            random_state=42)\n",
    "        self.data = data\n",
    "\n",
    "        self.X_train = torch.from_numpy(X_train.values).float()\n",
    "        self.y_train = torch.from_numpy(y_train.values).float()\n",
    "        self.X_test = torch.from_numpy(X_test.values).float()\n",
    "        self.y_test = torch.from_numpy(y_test.values).float()\n",
    "\n",
    "        self.num_data_points = {}\n",
    "        self.num_data_points['train'] = len(X_train)\n",
    "        self.num_data_points['test'] = len(X_test)\n",
    "        \n",
    "        self._split = 'train'\n",
    "\n",
    "    @property\n",
    "    def split(self):\n",
    "        return self._split\n",
    "\n",
    "    @split.setter\n",
    "    def split(self, split):\n",
    "        self._split = split\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # methods to override - __len__ and __getitem__ methods\n",
    "    # ------------------------------------------------------------------------\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_data_points[self._split]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dtype = self._split\n",
    "        item = {'index': idx}\n",
    "        item['features'] = self.X_train[idx,:]\n",
    "        item['outputs'] = self.y_train[idx,:]\n",
    "        return item\n",
    "\n",
    "    #-------------------------------------------------------------------------\n",
    "    # collate function utilized by dataloader for batching\n",
    "    #-------------------------------------------------------------------------\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        dtype = self._split\n",
    "        merged_batch = {key: [d[key] for d in batch] for key in batch[0]}\n",
    "        out = {}\n",
    "        for key in merged_batch:\n",
    "            if key in {'index'}:\n",
    "                out[key] = merged_batch[key]\n",
    "            else:\n",
    "                out[key] = torch.stack(merged_batch[key], 0)\n",
    "\n",
    "        batch_keys = ['features', 'outputs']\n",
    "        return {key: out[key] for key in batch_keys}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(98, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(60, 30),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(30, 15),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(15, 9)\n",
    "        )\n",
    "    def forward(self, batch):\n",
    "        return self.layers(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = arg_dataset(X_train_new_Z_score, y_target,.33)\n",
    "dataloader = DataLoader(dataset,\n",
    "                        batch_size=args.batch_size,\n",
    "                        shuffle=True,\n",
    "                        collate_fn=dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 iter per epoch.\n"
     ]
    }
   ],
   "source": [
    "setattr(args, 'iter_per_epoch', math.ceil(dataset.num_data_points['train'] / args.batch_size))\n",
    "print(\"{} iter per epoch.\".format(args.iter_per_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network(model_args)\n",
    "optimizer = optim.Adam(net.parameters())\n",
    "criterion = nn.MultiLabelSoftMarginLoss()\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=args.lr_decay_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start time: 23-Jan-2019-05:32:05\n",
      "[0:00:00.390055][Epoch:   1][Iter:      5][Loss: 0.669745][val loss: 0.666676][accuracy: 0.018229][lr: 0.001000]\n",
      "[0:00:01.747813][Epoch:   1][Iter:      5][Loss: 0.664610][val loss: 0.646542][accuracy: 0.031250][lr: 0.000998]\n",
      "[0:00:02.341572][Epoch:   2][Iter:     18][Loss: 0.661996][val loss: 0.638974][accuracy: 0.026042][lr: 0.000997]\n",
      "[0:00:03.919283][Epoch:   2][Iter:     18][Loss: 0.646100][val loss: 0.599980][accuracy: 0.057292][lr: 0.000994]\n",
      "[0:00:04.487911][Epoch:   3][Iter:     31][Loss: 0.638523][val loss: 0.587757][accuracy: 0.062500][lr: 0.000994]\n",
      "[0:00:06.277722][Epoch:   3][Iter:     31][Loss: 0.606604][val loss: 0.524428][accuracy: 0.088542][lr: 0.000991]\n",
      "[0:00:06.864728][Epoch:   4][Iter:     44][Loss: 0.594324][val loss: 0.509541][accuracy: 0.062500][lr: 0.000991]\n",
      "[0:00:08.667184][Epoch:   4][Iter:     44][Loss: 0.554157][val loss: 0.477895][accuracy: 0.062500][lr: 0.000988]\n",
      "[0:00:09.111633][Epoch:   5][Iter:     57][Loss: 0.543558][val loss: 0.471198][accuracy: 0.062500][lr: 0.000988]\n",
      "[0:00:10.854654][Epoch:   5][Iter:     57][Loss: 0.514677][val loss: 0.460705][accuracy: 0.091146][lr: 0.000985]\n",
      "[0:00:11.367560][Epoch:   6][Iter:     70][Loss: 0.508101][val loss: 0.462926][accuracy: 0.085938][lr: 0.000984]\n",
      "[0:00:12.967114][Epoch:   6][Iter:     70][Loss: 0.489955][val loss: 0.450739][accuracy: 0.109375][lr: 0.000982]\n",
      "[0:00:13.457560][Epoch:   7][Iter:     83][Loss: 0.485488][val loss: 0.452326][accuracy: 0.091146][lr: 0.000981]\n",
      "[0:00:15.175363][Epoch:   7][Iter:     83][Loss: 0.473039][val loss: 0.441249][accuracy: 0.117188][lr: 0.000979]\n",
      "[0:00:15.769240][Epoch:   8][Iter:     96][Loss: 0.472469][val loss: 0.451111][accuracy: 0.109375][lr: 0.000978]\n",
      "[0:00:17.510412][Epoch:   8][Iter:     96][Loss: 0.462967][val loss: 0.440106][accuracy: 0.130208][lr: 0.000976]\n",
      "[0:00:17.967788][Epoch:   9][Iter:    109][Loss: 0.459124][val loss: 0.438383][accuracy: 0.111979][lr: 0.000975]\n",
      "[0:00:19.460998][Epoch:   9][Iter:    109][Loss: 0.451611][val loss: 0.441724][accuracy: 0.127604][lr: 0.000973]\n",
      "[0:00:20.098740][Epoch:  10][Iter:    122][Loss: 0.448964][val loss: 0.439957][accuracy: 0.119792][lr: 0.000972]\n",
      "[0:00:21.810148][Epoch:  10][Iter:    122][Loss: 0.443327][val loss: 0.431396][accuracy: 0.119792][lr: 0.000970]\n",
      "[0:00:22.277456][Epoch:  11][Iter:    135][Loss: 0.442881][val loss: 0.427907][accuracy: 0.138021][lr: 0.000969]\n",
      "[0:00:23.944376][Epoch:  11][Iter:    135][Loss: 0.439240][val loss: 0.421510][accuracy: 0.125000][lr: 0.000967]\n",
      "[0:00:24.448277][Epoch:  12][Iter:    148][Loss: 0.435605][val loss: 0.428545][accuracy: 0.127604][lr: 0.000966]\n",
      "[0:00:25.719172][Epoch:  12][Iter:    148][Loss: 0.435027][val loss: 0.420056][accuracy: 0.130208][lr: 0.000964]\n",
      "[0:00:26.134318][Epoch:  13][Iter:    161][Loss: 0.432981][val loss: 0.428281][accuracy: 0.109375][lr: 0.000963]\n",
      "[0:00:27.834603][Epoch:  13][Iter:    161][Loss: 0.431803][val loss: 0.423620][accuracy: 0.143229][lr: 0.000961]\n",
      "[0:00:28.443729][Epoch:  14][Iter:    174][Loss: 0.427145][val loss: 0.418960][accuracy: 0.125000][lr: 0.000960]\n",
      "[0:00:29.984856][Epoch:  14][Iter:    174][Loss: 0.425132][val loss: 0.417591][accuracy: 0.151042][lr: 0.000958]\n",
      "[0:00:30.270919][Epoch:  15][Iter:    187][Loss: 0.424521][val loss: 0.413887][accuracy: 0.140625][lr: 0.000957]\n",
      "[0:00:31.701015][Epoch:  15][Iter:    187][Loss: 0.423501][val loss: 0.416296][accuracy: 0.148438][lr: 0.000955]\n",
      "[0:00:32.419676][Epoch:  16][Iter:    200][Loss: 0.422475][val loss: 0.420267][accuracy: 0.122396][lr: 0.000954]\n",
      "[0:00:34.409816][Epoch:  16][Iter:    200][Loss: 0.418615][val loss: 0.420637][accuracy: 0.158854][lr: 0.000952]\n",
      "[0:00:34.956191][Epoch:  17][Iter:    213][Loss: 0.419465][val loss: 0.422094][accuracy: 0.153646][lr: 0.000951]\n",
      "[0:00:36.999529][Epoch:  17][Iter:    213][Loss: 0.418596][val loss: 0.414323][accuracy: 0.151042][lr: 0.000949]\n",
      "[0:00:37.558050][Epoch:  18][Iter:    226][Loss: 0.416800][val loss: 0.416701][accuracy: 0.127604][lr: 0.000948]\n",
      "[0:00:39.182214][Epoch:  18][Iter:    226][Loss: 0.415245][val loss: 0.410288][accuracy: 0.148438][lr: 0.000946]\n",
      "[0:00:39.721972][Epoch:  19][Iter:    239][Loss: 0.411303][val loss: 0.408349][accuracy: 0.125000][lr: 0.000945]\n",
      "[0:00:41.252783][Epoch:  19][Iter:    239][Loss: 0.410617][val loss: 0.413955][accuracy: 0.145833][lr: 0.000943]\n",
      "[0:00:41.812510][Epoch:  20][Iter:    252][Loss: 0.408165][val loss: 0.414728][accuracy: 0.125000][lr: 0.000942]\n",
      "[0:00:43.993817][Epoch:  20][Iter:    252][Loss: 0.408140][val loss: 0.411812][accuracy: 0.130208][lr: 0.000940]\n",
      "[0:00:44.391760][Epoch:  21][Iter:    265][Loss: 0.411030][val loss: 0.412653][accuracy: 0.130208][lr: 0.000939]\n",
      "[0:00:46.207622][Epoch:  21][Iter:    265][Loss: 0.408926][val loss: 0.404004][accuracy: 0.148438][lr: 0.000937]\n",
      "[0:00:46.549643][Epoch:  22][Iter:    278][Loss: 0.412562][val loss: 0.412698][accuracy: 0.127604][lr: 0.000936]\n",
      "[0:00:48.406625][Epoch:  22][Iter:    278][Loss: 0.407386][val loss: 0.410775][accuracy: 0.127604][lr: 0.000934]\n",
      "[0:00:49.054833][Epoch:  23][Iter:    291][Loss: 0.406032][val loss: 0.403254][accuracy: 0.151042][lr: 0.000933]\n",
      "[0:00:50.621214][Epoch:  23][Iter:    291][Loss: 0.406004][val loss: 0.395482][accuracy: 0.130208][lr: 0.000931]\n",
      "[0:00:51.283016][Epoch:  24][Iter:    304][Loss: 0.405219][val loss: 0.401516][accuracy: 0.153646][lr: 0.000931]\n",
      "[0:00:52.484242][Epoch:  24][Iter:    304][Loss: 0.404217][val loss: 0.394312][accuracy: 0.158854][lr: 0.000928]\n",
      "[0:00:53.086923][Epoch:  25][Iter:    317][Loss: 0.401901][val loss: 0.404581][accuracy: 0.119792][lr: 0.000928]\n",
      "[0:00:54.867258][Epoch:  25][Iter:    317][Loss: 0.399400][val loss: 0.401328][accuracy: 0.156250][lr: 0.000925]\n",
      "[0:00:55.352454][Epoch:  26][Iter:    330][Loss: 0.397573][val loss: 0.403272][accuracy: 0.143229][lr: 0.000925]\n",
      "[0:00:57.051050][Epoch:  26][Iter:    330][Loss: 0.395252][val loss: 0.394863][accuracy: 0.171875][lr: 0.000922]\n",
      "[0:00:57.655527][Epoch:  27][Iter:    343][Loss: 0.400492][val loss: 0.400919][accuracy: 0.140625][lr: 0.000922]\n",
      "[0:00:59.219079][Epoch:  27][Iter:    343][Loss: 0.394673][val loss: 0.398848][accuracy: 0.135417][lr: 0.000920]\n",
      "[0:00:59.832535][Epoch:  28][Iter:    356][Loss: 0.393895][val loss: 0.401892][accuracy: 0.135417][lr: 0.000919]\n",
      "[0:01:01.068490][Epoch:  28][Iter:    356][Loss: 0.394960][val loss: 0.396536][accuracy: 0.164062][lr: 0.000917]\n",
      "[0:01:01.561204][Epoch:  29][Iter:    369][Loss: 0.396205][val loss: 0.395852][accuracy: 0.177083][lr: 0.000916]\n",
      "[0:01:03.286538][Epoch:  29][Iter:    369][Loss: 0.395908][val loss: 0.397760][accuracy: 0.156250][lr: 0.000914]\n",
      "[0:01:03.780593][Epoch:  30][Iter:    382][Loss: 0.393481][val loss: 0.397250][accuracy: 0.174479][lr: 0.000913]\n",
      "[0:01:05.534902][Epoch:  30][Iter:    382][Loss: 0.393596][val loss: 0.394281][accuracy: 0.153646][lr: 0.000911]\n",
      "[0:01:06.160051][Epoch:  31][Iter:    395][Loss: 0.392256][val loss: 0.402382][accuracy: 0.132812][lr: 0.000910]\n",
      "[0:01:08.325172][Epoch:  31][Iter:    395][Loss: 0.393409][val loss: 0.395733][accuracy: 0.153646][lr: 0.000908]\n",
      "[0:01:08.922189][Epoch:  32][Iter:    408][Loss: 0.393198][val loss: 0.392018][accuracy: 0.158854][lr: 0.000908]\n",
      "[0:01:10.970346][Epoch:  32][Iter:    408][Loss: 0.391158][val loss: 0.392849][accuracy: 0.171875][lr: 0.000905]\n",
      "[0:01:11.576154][Epoch:  33][Iter:    421][Loss: 0.389969][val loss: 0.390554][accuracy: 0.166667][lr: 0.000905]\n",
      "[0:01:13.778288][Epoch:  33][Iter:    421][Loss: 0.389270][val loss: 0.395855][accuracy: 0.153646][lr: 0.000902]\n",
      "[0:01:14.429920][Epoch:  34][Iter:    434][Loss: 0.388665][val loss: 0.392193][accuracy: 0.158854][lr: 0.000902]\n",
      "[0:01:16.396198][Epoch:  34][Iter:    434][Loss: 0.385439][val loss: 0.391644][accuracy: 0.153646][lr: 0.000900]\n",
      "[0:01:16.890989][Epoch:  35][Iter:    447][Loss: 0.385481][val loss: 0.391858][accuracy: 0.182292][lr: 0.000899]\n",
      "[0:01:18.955519][Epoch:  35][Iter:    447][Loss: 0.388002][val loss: 0.384027][accuracy: 0.195312][lr: 0.000897]\n",
      "[0:01:19.690492][Epoch:  36][Iter:    460][Loss: 0.389904][val loss: 0.398992][accuracy: 0.161458][lr: 0.000896]\n",
      "[0:01:21.886161][Epoch:  36][Iter:    460][Loss: 0.387816][val loss: 0.391748][accuracy: 0.166667][lr: 0.000894]\n",
      "[0:01:22.776927][Epoch:  37][Iter:    473][Loss: 0.389230][val loss: 0.392552][accuracy: 0.182292][lr: 0.000893]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0:01:25.018104][Epoch:  37][Iter:    473][Loss: 0.385855][val loss: 0.391034][accuracy: 0.166667][lr: 0.000891]\n",
      "[0:01:25.796281][Epoch:  38][Iter:    486][Loss: 0.386991][val loss: 0.392193][accuracy: 0.164062][lr: 0.000891]\n",
      "[0:01:28.108865][Epoch:  38][Iter:    486][Loss: 0.385045][val loss: 0.390774][accuracy: 0.161458][lr: 0.000888]\n",
      "[0:01:28.679656][Epoch:  39][Iter:    499][Loss: 0.380409][val loss: 0.387492][accuracy: 0.161458][lr: 0.000888]\n",
      "[0:01:30.458209][Epoch:  39][Iter:    499][Loss: 0.377356][val loss: 0.384832][accuracy: 0.182292][lr: 0.000886]\n",
      "[0:01:30.946014][Epoch:  40][Iter:    512][Loss: 0.381513][val loss: 0.388127][accuracy: 0.153646][lr: 0.000885]\n",
      "[0:01:32.918407][Epoch:  40][Iter:    512][Loss: 0.380386][val loss: 0.390825][accuracy: 0.177083][lr: 0.000883]\n",
      "[0:01:33.549798][Epoch:  41][Iter:    525][Loss: 0.379032][val loss: 0.390661][accuracy: 0.161458][lr: 0.000882]\n",
      "[0:01:35.126626][Epoch:  41][Iter:    525][Loss: 0.378442][val loss: 0.386431][accuracy: 0.177083][lr: 0.000880]\n",
      "[0:01:35.618751][Epoch:  42][Iter:    538][Loss: 0.378307][val loss: 0.388983][accuracy: 0.174479][lr: 0.000880]\n",
      "[0:01:37.243925][Epoch:  42][Iter:    538][Loss: 0.379677][val loss: 0.389824][accuracy: 0.174479][lr: 0.000877]\n",
      "[0:01:37.746651][Epoch:  43][Iter:    551][Loss: 0.377749][val loss: 0.388717][accuracy: 0.177083][lr: 0.000877]\n",
      "[0:01:38.975820][Epoch:  43][Iter:    551][Loss: 0.378281][val loss: 0.393121][accuracy: 0.161458][lr: 0.000875]\n",
      "[0:01:39.317699][Epoch:  44][Iter:    564][Loss: 0.376097][val loss: 0.385597][accuracy: 0.179688][lr: 0.000874]\n",
      "[0:01:40.439992][Epoch:  44][Iter:    564][Loss: 0.377497][val loss: 0.392496][accuracy: 0.171875][lr: 0.000872]\n",
      "[0:01:40.766553][Epoch:  45][Iter:    577][Loss: 0.375787][val loss: 0.395287][accuracy: 0.177083][lr: 0.000871]\n",
      "[0:01:41.889931][Epoch:  45][Iter:    577][Loss: 0.375710][val loss: 0.384215][accuracy: 0.177083][lr: 0.000869]\n",
      "[0:01:42.175757][Epoch:  46][Iter:    590][Loss: 0.379878][val loss: 0.379586][accuracy: 0.192708][lr: 0.000869]\n",
      "[0:01:43.237510][Epoch:  46][Iter:    590][Loss: 0.376819][val loss: 0.390698][accuracy: 0.164062][lr: 0.000867]\n",
      "[0:01:43.614916][Epoch:  47][Iter:    603][Loss: 0.373409][val loss: 0.382448][accuracy: 0.190104][lr: 0.000866]\n",
      "[0:01:45.056484][Epoch:  47][Iter:    603][Loss: 0.373492][val loss: 0.384529][accuracy: 0.177083][lr: 0.000864]\n",
      "[0:01:45.352778][Epoch:  48][Iter:    616][Loss: 0.376663][val loss: 0.380533][accuracy: 0.182292][lr: 0.000863]\n",
      "[0:01:46.754655][Epoch:  48][Iter:    616][Loss: 0.373456][val loss: 0.382881][accuracy: 0.184896][lr: 0.000861]\n",
      "[0:01:47.198291][Epoch:  49][Iter:    629][Loss: 0.374309][val loss: 0.386688][accuracy: 0.179688][lr: 0.000860]\n",
      "[0:01:48.577675][Epoch:  49][Iter:    629][Loss: 0.373135][val loss: 0.389663][accuracy: 0.190104][lr: 0.000858]\n",
      "[0:01:48.903017][Epoch:  50][Iter:    642][Loss: 0.372992][val loss: 0.394350][accuracy: 0.169271][lr: 0.000858]\n",
      "[0:01:49.959713][Epoch:  50][Iter:    642][Loss: 0.372178][val loss: 0.385480][accuracy: 0.179688][lr: 0.000856]\n",
      "[0:01:50.329708][Epoch:  51][Iter:    655][Loss: 0.369143][val loss: 0.386232][accuracy: 0.171875][lr: 0.000855]\n",
      "[0:01:51.186754][Epoch:  51][Iter:    655][Loss: 0.370472][val loss: 0.389643][accuracy: 0.151042][lr: 0.000853]\n",
      "[0:01:51.561594][Epoch:  52][Iter:    668][Loss: 0.369699][val loss: 0.387373][accuracy: 0.187500][lr: 0.000852]\n",
      "[0:01:52.919077][Epoch:  52][Iter:    668][Loss: 0.367762][val loss: 0.395227][accuracy: 0.169271][lr: 0.000850]\n",
      "[0:01:53.225844][Epoch:  53][Iter:    681][Loss: 0.369105][val loss: 0.380846][accuracy: 0.177083][lr: 0.000850]\n",
      "[0:01:54.469965][Epoch:  53][Iter:    681][Loss: 0.367766][val loss: 0.383127][accuracy: 0.187500][lr: 0.000848]\n",
      "[0:01:54.872183][Epoch:  54][Iter:    694][Loss: 0.369046][val loss: 0.380322][accuracy: 0.177083][lr: 0.000847]\n",
      "[0:01:56.058376][Epoch:  54][Iter:    694][Loss: 0.366145][val loss: 0.382286][accuracy: 0.166667][lr: 0.000845]\n",
      "[0:01:56.590263][Epoch:  55][Iter:    707][Loss: 0.369335][val loss: 0.378271][accuracy: 0.187500][lr: 0.000844]\n",
      "[0:01:57.990490][Epoch:  55][Iter:    707][Loss: 0.367080][val loss: 0.381174][accuracy: 0.174479][lr: 0.000842]\n",
      "[0:01:58.437986][Epoch:  56][Iter:    720][Loss: 0.368487][val loss: 0.384894][accuracy: 0.164062][lr: 0.000842]\n",
      "[0:02:00.358101][Epoch:  56][Iter:    720][Loss: 0.367252][val loss: 0.381284][accuracy: 0.190104][lr: 0.000840]\n",
      "[0:02:00.603280][Epoch:  57][Iter:    733][Loss: 0.364319][val loss: 0.383744][accuracy: 0.190104][lr: 0.000839]\n",
      "[0:02:02.405014][Epoch:  57][Iter:    733][Loss: 0.364929][val loss: 0.387686][accuracy: 0.169271][lr: 0.000837]\n",
      "[0:02:02.981526][Epoch:  58][Iter:    746][Loss: 0.361756][val loss: 0.383668][accuracy: 0.182292][lr: 0.000837]\n",
      "[0:02:05.024263][Epoch:  58][Iter:    746][Loss: 0.361336][val loss: 0.373948][accuracy: 0.171875][lr: 0.000835]\n",
      "[0:02:05.568712][Epoch:  59][Iter:    759][Loss: 0.360932][val loss: 0.383369][accuracy: 0.182292][lr: 0.000834]\n",
      "[0:02:07.182852][Epoch:  59][Iter:    759][Loss: 0.358599][val loss: 0.375653][accuracy: 0.187500][lr: 0.000832]\n",
      "[0:02:07.867357][Epoch:  60][Iter:    772][Loss: 0.359123][val loss: 0.376646][accuracy: 0.205729][lr: 0.000831]\n",
      "[0:02:09.839455][Epoch:  60][Iter:    772][Loss: 0.359907][val loss: 0.379317][accuracy: 0.195312][lr: 0.000829]\n",
      "[0:02:10.313332][Epoch:  61][Iter:    785][Loss: 0.360329][val loss: 0.383085][accuracy: 0.179688][lr: 0.000829]\n",
      "[0:02:12.062938][Epoch:  61][Iter:    785][Loss: 0.358487][val loss: 0.385309][accuracy: 0.187500][lr: 0.000827]\n",
      "[0:02:12.406598][Epoch:  62][Iter:    798][Loss: 0.359775][val loss: 0.382358][accuracy: 0.148438][lr: 0.000826]\n",
      "[0:02:13.897230][Epoch:  62][Iter:    798][Loss: 0.359308][val loss: 0.377636][accuracy: 0.184896][lr: 0.000824]\n",
      "[0:02:14.403668][Epoch:  63][Iter:    811][Loss: 0.359882][val loss: 0.385398][accuracy: 0.192708][lr: 0.000824]\n",
      "[0:02:15.963754][Epoch:  63][Iter:    811][Loss: 0.359646][val loss: 0.389787][accuracy: 0.182292][lr: 0.000822]\n",
      "[0:02:16.578529][Epoch:  64][Iter:    824][Loss: 0.357546][val loss: 0.382584][accuracy: 0.184896][lr: 0.000821]\n",
      "[0:02:18.430529][Epoch:  64][Iter:    824][Loss: 0.356273][val loss: 0.385114][accuracy: 0.182292][lr: 0.000819]\n",
      "[0:02:18.903643][Epoch:  65][Iter:    837][Loss: 0.360074][val loss: 0.381135][accuracy: 0.210938][lr: 0.000818]\n",
      "[0:02:20.626958][Epoch:  65][Iter:    837][Loss: 0.359885][val loss: 0.380060][accuracy: 0.171875][lr: 0.000816]\n",
      "[0:02:21.182176][Epoch:  66][Iter:    850][Loss: 0.355657][val loss: 0.383192][accuracy: 0.169271][lr: 0.000816]\n",
      "[0:02:22.634710][Epoch:  66][Iter:    850][Loss: 0.355934][val loss: 0.388739][accuracy: 0.164062][lr: 0.000814]\n",
      "[0:02:23.174054][Epoch:  67][Iter:    863][Loss: 0.357203][val loss: 0.376701][accuracy: 0.166667][lr: 0.000813]\n",
      "[0:02:24.866839][Epoch:  67][Iter:    863][Loss: 0.355662][val loss: 0.381795][accuracy: 0.171875][lr: 0.000811]\n",
      "[0:02:25.100885][Epoch:  68][Iter:    876][Loss: 0.354689][val loss: 0.377719][accuracy: 0.208333][lr: 0.000811]\n",
      "[0:02:26.845214][Epoch:  68][Iter:    876][Loss: 0.353666][val loss: 0.383112][accuracy: 0.182292][lr: 0.000809]\n",
      "[0:02:27.369741][Epoch:  69][Iter:    889][Loss: 0.352347][val loss: 0.387362][accuracy: 0.169271][lr: 0.000808]\n",
      "[0:02:29.081570][Epoch:  69][Iter:    889][Loss: 0.354062][val loss: 0.384377][accuracy: 0.197917][lr: 0.000806]\n",
      "[0:02:29.530180][Epoch:  70][Iter:    902][Loss: 0.354840][val loss: 0.385475][accuracy: 0.177083][lr: 0.000806]\n",
      "[0:02:30.950521][Epoch:  70][Iter:    902][Loss: 0.353631][val loss: 0.388097][accuracy: 0.192708][lr: 0.000804]\n",
      "[0:02:31.492566][Epoch:  71][Iter:    915][Loss: 0.351774][val loss: 0.376947][accuracy: 0.195312][lr: 0.000803]\n",
      "[0:02:33.068678][Epoch:  71][Iter:    915][Loss: 0.352927][val loss: 0.382100][accuracy: 0.205729][lr: 0.000801]\n",
      "[0:02:33.599335][Epoch:  72][Iter:    928][Loss: 0.352903][val loss: 0.385577][accuracy: 0.192708][lr: 0.000801]\n",
      "[0:02:35.258683][Epoch:  72][Iter:    928][Loss: 0.352146][val loss: 0.383171][accuracy: 0.187500][lr: 0.000799]\n",
      "[0:02:35.714960][Epoch:  73][Iter:    941][Loss: 0.354046][val loss: 0.382781][accuracy: 0.203125][lr: 0.000798]\n",
      "[0:02:37.502847][Epoch:  73][Iter:    941][Loss: 0.351957][val loss: 0.369074][accuracy: 0.205729][lr: 0.000796]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0:02:37.991931][Epoch:  74][Iter:    954][Loss: 0.354375][val loss: 0.376693][accuracy: 0.192708][lr: 0.000796]\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "# training\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "net.train()\n",
    "os.makedirs(args.save_path, exist_ok=True)\n",
    "\n",
    "running_loss = 0.0\n",
    "train_begin = datetime.datetime.utcnow()\n",
    "print(\"Training start time: {}\".format(datetime.datetime.strftime(train_begin, '%d-%b-%Y-%H:%M:%S')))\n",
    "\n",
    "log_loss = []\n",
    "for epoch in range(1, model_args.num_epochs + 1):\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        for key in batch:\n",
    "            batch[key] = Variable(batch[key])\n",
    "            if args.gpuid >= 0:\n",
    "                batch[key] = batch[key].cuda()\n",
    "\n",
    "        # --------------------------------------------------------------------\n",
    "        # forward-backward pass and optimizer step\n",
    "        # --------------------------------------------------------------------\n",
    "        net_out = net(batch['features'])\n",
    "\n",
    "        cur_loss = criterion(net_out, batch['outputs'])\n",
    "        cur_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        gc.collect()\n",
    "\n",
    "        # --------------------------------------------------------------------\n",
    "        # update running loss and decay learning rates\n",
    "        # --------------------------------------------------------------------\n",
    "        #train_loss = cur_loss.data[0]\n",
    "        train_loss = cur_loss.item()\n",
    "        if running_loss > 0.0:\n",
    "            running_loss = 0.95 * running_loss + 0.05 * train_loss\n",
    "        else:\n",
    "            running_loss = train_loss \n",
    "\n",
    "        if optimizer.param_groups[0]['lr'] > args.min_lr:\n",
    "            scheduler.step()\n",
    "\n",
    "\n",
    "        # --------------------------------------------------------------------\n",
    "        # print after every few iterations\n",
    "        # --------------------------------------------------------------------\n",
    "        if i % 10 == 0:\n",
    "            test_losses = []\n",
    "            accuracy = []\n",
    "            for i in range(int(dataset.num_data_points['test']/args.batch_size)):\n",
    "                test_feat = dataset.X_test[i*args.batch_size:(i+1)*args.batch_size, :]\n",
    "                test_labels = dataset.y_test[i*args.batch_size:(i+1)*args.batch_size, :]\n",
    "                test_feat = Variable(test_feat)\n",
    "                test_labels = Variable(test_labels)\n",
    "                if args.gpuid >= 0:\n",
    "                    test_feat = test_feat.cuda()\n",
    "                    test_labels = test_labels.cuda()\n",
    "                net_out = net(test_feat)\n",
    "                cur_loss = criterion(net_out, test_labels)\n",
    "                test_losses.append(cur_loss.item())\n",
    "                \n",
    "                y_pred = torch.sigmoid(net_out).data > 0.5\n",
    "                y_pred = y_pred.cpu().numpy()\n",
    "                accuracy.append((test_labels.cpu().numpy() == y_pred).all(axis=1))\n",
    "\n",
    "            validation_loss = np.mean(test_losses)\n",
    "            \n",
    "            accuracy = np.mean(accuracy)\n",
    "\n",
    "            iteration = (epoch - 1) * args.iter_per_epoch + i\n",
    "\n",
    "            log_loss.append((epoch,\n",
    "                             iteration,\n",
    "                             running_loss,\n",
    "                             train_loss,\n",
    "                             validation_loss,\n",
    "                             accuracy,\n",
    "                             optimizer.param_groups[0]['lr']))\n",
    "\n",
    "            # print current time, running average, learning rate, iteration, epoch\n",
    "            print(\"[{}][Epoch: {:3d}][Iter: {:6d}][Loss: {:6f}][val loss: {:6f}][accuracy: {:6f}][lr: {:7f}]\".format(\n",
    "                datetime.datetime.utcnow() - train_begin, epoch,\n",
    "                    iteration, running_loss, validation_loss, accuracy,\n",
    "                    optimizer.param_groups[0]['lr']))\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # save checkpoints and final model\n",
    "    # ------------------------------------------------------------------------\n",
    "    if epoch % args.save_step == 0:\n",
    "        torch.save({\n",
    "            'net': net.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'model_args': net.args\n",
    "        }, os.path.join(args.save_path, 'model_epoch_{}.pth'.format(epoch)))\n",
    "\n",
    "torch.save({\n",
    "    'net': net.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "    'model_args': net.args\n",
    "}, os.path.join(args.save_path, 'model_final.pth'))\n",
    "\n",
    "np.save(os.path.join(args.save_path, 'log_loss'), log_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
