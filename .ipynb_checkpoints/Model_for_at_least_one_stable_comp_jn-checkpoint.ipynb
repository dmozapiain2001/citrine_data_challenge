{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data is being read ....\n",
      "(2572, 98)\n",
      "(2572, 109)\n",
      "Training Data has been read and feature engineering is being performed....\n",
      "(2572, 110)\n",
      "Pearson Correlation has been calculated to build the model in the most relevant features ....\n",
      "Pearson Correlation has identified 38 with  0.1\n",
      "(2572, 38)\n",
      "(2572, 38)\n",
      "(2572, 38)\n",
      "(2572, 38)\n",
      "(2572, 38)\n",
      "(2572, 98)\n",
      "(2572, 98)\n",
      "(2572, 20)\n",
      "(2572, 20)\n",
      "(2572, 21)\n",
      "Training Model Using Z-normalized Data\n",
      "(2314, 38) (2314,)\n",
      "(258, 38) (258,)\n",
      " -- Random Forest --\n",
      " -- Random Forest --\n",
      "This are the best Parameters for Random Forest:\n",
      "      test_results_auc  test_recall                               features\n",
      "2144          0.903148     0.949153  [5, entropy, False, 10, 10, 1, 5e-07]\n",
      "2145          0.903148     0.949153  [5, entropy, False, 10, 10, 1, 1e-06]\n",
      "4256          0.903148     0.949153     [50, gini, False, 10, 3, 1, 5e-07]\n",
      "4257          0.903148     0.949153     [50, gini, False, 10, 3, 1, 1e-06]\n",
      "4265          0.902482     0.940678     [50, gini, False, 10, 4, 1, 1e-06]\n",
      " -- Decision Trees --\n",
      " -- Decision Tree --\n",
      "This are the best Parameters for Decision Tree:\n",
      "     train_results_mean  train_results_std  train_results_auc  \\\n",
      "144            0.840970           0.027633           0.994186   \n",
      "145            0.840970           0.027633           0.994186   \n",
      "148            0.837083           0.030328           0.979785   \n",
      "149            0.837083           0.030328           0.979785   \n",
      "176            0.840970           0.027633           0.994186   \n",
      "\n",
      "     test_results_auc  test_accuracy  test_precision  train_recall  \\\n",
      "144          0.890436       0.887597        0.844961      1.000000   \n",
      "145          0.890436       0.887597        0.844961      1.000000   \n",
      "148          0.890436       0.887597        0.844961      0.992793   \n",
      "149          0.890436       0.887597        0.844961      0.992793   \n",
      "176          0.890436       0.887597        0.844961      1.000000   \n",
      "\n",
      "     test_recall                           features  \n",
      "144     0.923729  [entropy, 100, best, 2, 1, 5e-07]  \n",
      "145     0.923729  [entropy, 100, best, 2, 1, 1e-06]  \n",
      "148     0.923729  [entropy, 100, best, 4, 1, 5e-07]  \n",
      "149     0.923729  [entropy, 100, best, 4, 1, 1e-06]  \n",
      "176     0.923729  [entropy, 250, best, 2, 1, 5e-07]  \n",
      " -- KNN --\n",
      " -- KNN Classifier --\n",
      "This are the best Parameters for KNN :\n",
      "    train_results_mean  train_results_std  train_results_auc  \\\n",
      "0              0.86344           0.019907                1.0   \n",
      "5              0.86344           0.019907                1.0   \n",
      "30             0.86344           0.019907                1.0   \n",
      "\n",
      "    test_results_auc  test_accuracy  test_precision  train_recall  \\\n",
      "0           0.893341       0.891473        0.857143           1.0   \n",
      "5           0.893341       0.891473        0.857143           1.0   \n",
      "30          0.893341       0.891473        0.857143           1.0   \n",
      "\n",
      "    test_recall          features  \n",
      "0      0.915254  [distance, 1, 1]  \n",
      "5      0.915254  [distance, 2, 1]  \n",
      "30     0.915254   [uniform, 1, 1]  \n",
      " -- SVM --\n",
      " -- SVM Classifier --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/nv/hp22/dmo7/data/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This are the best Parameters for SVM :\n",
      "    train_results_mean  train_results_std  train_results_auc  \\\n",
      "10            0.873408           0.022131           0.966419   \n",
      "\n",
      "    test_results_auc  test_accuracy  test_precision  train_recall  \\\n",
      "10          0.894673       0.891473        0.846154       0.98018   \n",
      "\n",
      "    test_recall       features  \n",
      "10     0.932203  [rbf, 0.1, 5]  \n",
      " -- Logistic Regression --\n",
      " -- Logistic Regression --\n",
      "This are the best Parameters for Logistic Regression :\n",
      "   train_results_mean  train_results_std  train_results_auc  test_results_auc  \\\n",
      "0            0.745904           0.035418           0.761530          0.732506   \n",
      "1            0.745904           0.035418           0.761530          0.732506   \n",
      "2            0.746337           0.035584           0.761115          0.732506   \n",
      "3            0.745904           0.035418           0.761530          0.732506   \n",
      "4            0.745904           0.035418           0.761530          0.732506   \n",
      "\n",
      "   test_accuracy  test_precision  train_recall  test_recall     features  \n",
      "0       0.736434        0.723214      0.731532     0.686441  [newton-cg]  \n",
      "1       0.736434        0.723214      0.731532     0.686441      [lbfgs]  \n",
      "2       0.736434        0.723214      0.731532     0.686441  [liblinear]  \n",
      "3       0.736434        0.723214      0.731532     0.686441        [sag]  \n",
      "4       0.736434        0.723214      0.731532     0.686441       [saga]  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import scores\n",
    "\n",
    "\n",
    "# # Reading in the Data\n",
    "\n",
    "path_f=os.getcwd()\n",
    "\n",
    "path_f_1=os.path.join(path_f, 'data')\n",
    "\n",
    "\n",
    "names=[]\n",
    "for files_txts in os.listdir(path_f_1):\n",
    "    if files_txts.endswith(\".csv\"):\n",
    "        #print(files_txts)\n",
    "        names.append(files_txts)\n",
    "        \n",
    "path_train=os.path.join(path_f_1, names[1])\n",
    "path_test=os.path.join(path_f_1, names[0])\n",
    "\n",
    "df_train=pd.read_csv(path_train)\n",
    "df_train.shape\n",
    "\n",
    "\n",
    "# ## Data Manipulation\n",
    "print('Training Data is being read ....')\n",
    "#  - Transforming the outcome to a numpy vector\n",
    "\n",
    "stab_vector=df_train['stabilityVec'].values\n",
    "y=[]\n",
    "for x in stab_vector:\n",
    "    #print(x)\n",
    "    a=np.fromstring(x[1:-1],sep=',').astype(int)\n",
    "    y.append(a)\n",
    "y=np.array(y) \n",
    "\n",
    "df_tmp = pd.DataFrame(y, columns = ['A', 'A91B', 'A82B','A73B','A64B','A55B','A46B','A37B','A28B','A19B','B'])\n",
    "stab_vec_list=[ 'A91B', 'A82B','A73B','A64B','A55B','A46B','A37B','A28B','A19B']\n",
    "\n",
    "df_train=df_train.drop(\"stabilityVec\",axis=1) #removing the results which originally are a string\n",
    "feature_cols=list(df_train)\n",
    "\n",
    "print(df_train.shape)\n",
    "\n",
    "df_train['formulaA']=df_train['formulaA_elements_Number']\n",
    "df_train['formulaB']=df_train['formulaB_elements_Number']\n",
    "\n",
    "df_train=pd.concat([df_train, df_tmp],axis=1)\n",
    "print(df_train.shape)\n",
    "\n",
    "# ### Input Data Normalization and Feature Engineering\n",
    "print('Training Data has been read and feature engineering is being performed....')\n",
    "\n",
    "y_all=df_train[stab_vec_list]\n",
    "df_tmp_stable = pd.DataFrame( columns = ['Stable_compunds'])\n",
    "df_tmp_stable['Stable_compunds']=np.logical_not(y_all.sum(axis=1)==0).astype(int) ## A one means it has a stable value  a 0 \n",
    "\n",
    "df_train=pd.concat([df_train, df_tmp_stable],axis=1)\n",
    "print(df_train.shape)\n",
    "\n",
    "df_train.head()\n",
    "\n",
    "# Pearson Correlation to Identify the features that influence the most on the output \n",
    "print('Pearson Correlation has been calculated to build the model in the most relevant features ....')\n",
    "\n",
    "X_train_new=df_train[feature_cols]\n",
    "y_new=df_train['Stable_compunds']\n",
    "\n",
    "corr_df=pd.concat([X_train_new, y_new],axis=1)\n",
    "a=corr_df.corr()\n",
    "#a['Stable_compunds'].hist(bins=7, figsize=(18, 12), xlabelsize=10)\n",
    "\n",
    "## Incorporating the Features that contribute the most based on a pearson correlation coefficient threshold\n",
    "\n",
    "thr=.1\n",
    "\n",
    "corr_variables=list(a[a['Stable_compunds'].abs()>thr].index)\n",
    "\n",
    "del(corr_variables[-1])\n",
    "\n",
    "\n",
    "print('Pearson Correlation has identified', len(corr_variables), 'with ', str(thr) )\n",
    "\n",
    "## Normalization of Input Data\n",
    "\n",
    "## Using Un-normalized data as input\n",
    "X_train_new=df_train[corr_variables]\n",
    "\n",
    "print(X_train_new.shape)\n",
    "\n",
    "\n",
    "# Normalizing such that the magnitude is one\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "X_train_new_mag_1=normalize(X_train_new, axis=1) # vector magnitude is one\n",
    "print(X_train_new_mag_1.shape)\n",
    "\n",
    "\n",
    "## Normalizing by Zscore\n",
    "from scipy.stats import zscore\n",
    "X_train_new_Z_score=X_train_new.apply(zscore)\n",
    "print(X_train_new_Z_score.shape)\n",
    "\n",
    "\n",
    "\n",
    "## Normalizing so that range is 0-1\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train_new_0_1=min_max_scaler.fit_transform(X_train_new)\n",
    "print(X_train_new_0_1.shape)\n",
    "\n",
    "\n",
    "## Normalizing so that range is -1 to 1\n",
    "from sklearn import preprocessing\n",
    "max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "X_train_new_m1_p1=max_abs_scaler.fit_transform(X_train_new)\n",
    "print(X_train_new_m1_p1.shape)\n",
    "\n",
    "\n",
    "# Using PCA as input\n",
    "X_train_4_PCA=df_train[feature_cols]\n",
    "print(X_train_4_PCA.shape)\n",
    "X_train_new_mag_1_PCA=normalize(X_train_4_PCA, axis=1)\n",
    "print(X_train_new_mag_1_PCA.shape)\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X_train_new_mag_1_PCA)\n",
    "components = pca.components_[:20,:]\n",
    "new_data = np.dot(X_train_new_mag_1_PCA, components.T)\n",
    "X_train_new_PCA=new_data\n",
    "\n",
    "print(X_train_new_PCA.shape)\n",
    "\n",
    "\n",
    "## Using Pearson Correlation in PCA\n",
    "df1= pd.DataFrame(data=X_train_new_PCA)\n",
    "print(df1.shape)\n",
    "\n",
    "\n",
    "corr_df_PCA=pd.concat([df1, y_new],axis=1)\n",
    "\n",
    "print(corr_df_PCA.shape)\n",
    "a_PCA=corr_df_PCA.corr()\n",
    "#a_PCA['Stable_compunds'].hist(bins=7, figsize=(18, 12), xlabelsize=10)\n",
    "\n",
    "\n",
    "thr=.01\n",
    "corr_variables_PCA=list(a_PCA[a_PCA['Stable_compunds'].abs()>thr].index)\n",
    "\n",
    "del(corr_variables_PCA[-1])\n",
    "\n",
    "\n",
    "X_train_PCA_PC=df1[corr_variables_PCA]\n",
    "\n",
    "\n",
    "\n",
    "# ### First we will build a model to determine if the input elements will produce at least one stable compound\n",
    "\n",
    "y_new=df_train['Stable_compunds']\n",
    "\n",
    "\n",
    "# # Model Generation\n",
    "\n",
    "print('Training Model Using Z-normalized Data')\n",
    "## test-train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_new_Z_score, y_new,\n",
    "                                                    test_size=.1,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=42)\n",
    "\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape,y_test.shape)\n",
    "\n",
    "# Hyper-Parameter Search Grid Using 10-Fold CV and Test\n",
    "print(' -- Random Forest --')\n",
    "\n",
    "#first pass\n",
    "n_estimators = [1,3,5,10,50,100]\n",
    "criterion=['entropy','gini']\n",
    "bootstrap= [True, False]\n",
    "max_depth=[2,5,10]\n",
    "\n",
    "min_samples_splits=[2,3,4,6,7,8,9,10,20]\n",
    "min_samples_leafs=[1,2,5,10]\n",
    "min_impurity_splits=[5e-7 ,1e-6]\n",
    "\n",
    "#second pass\n",
    "#n_estimators = [10,20,50]\n",
    "#criterion=['entropy']\n",
    "#bootstrap= [True, False]\n",
    "#max_depth=[5,6]\n",
    "#min_samples_splits=[2,3,4,5,6]\n",
    "#min_samples_leafs=[1,3,5]\n",
    "#min_impurity_splits=[3e-7, 5e-7,1e-6]\n",
    "\n",
    "#n_estimators = [1,3,5,8]\n",
    "#criterion=['entropy']\n",
    "#bootstrap= [True, False]\n",
    "#max_depth=[1,3,4]\n",
    "\n",
    "\n",
    "#min_samples_splits=[2,3,4,5]\n",
    "#min_samples_leafs=[1]\n",
    "#min_impurity_splits=[3e-7, 5e-7,8e-7]\n",
    "\n",
    "df_results_RF=scores.hp_tune_Random_Forest(X_train,y_train,X_test,y_test,5,n_estimators,criterion,bootstrap,max_depth,min_samples_splits,min_samples_leafs,min_impurity_splits)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('This are the best Parameters for Random Forest:')\n",
    "print(df_results_RF[['test_results_auc','test_recall','features']][df_results_RF['test_accuracy']==df_results_RF['test_accuracy'].max()].head())\n",
    "\n",
    "\n",
    "# # Decision Trees\n",
    "\n",
    "\n",
    "# Hyper-Parameter Search Grid Using 10-Fold CV and Test\n",
    "print(' -- Decision Trees --')\n",
    "\n",
    "\n",
    "criterion=['entropy','gini']\n",
    "bootstrap= [True, False]\n",
    "max_depth=[1,2,5,10,100,250,1000]\n",
    "split=['random','best']\n",
    "min_samples_splits=[2,3,4,6,7,8,9,10]\n",
    "min_samples_leafs=[1]\n",
    "min_impurity_splits=[5e-7 ,1e-6]\n",
    "\n",
    "#second pass\n",
    "#criterion=['entropy']\n",
    "#max_depth=[10,11,15]\n",
    "#split=['random','best']\n",
    "#min_samples_splits=[2,3,4,6]\n",
    "#min_samples_leafs=[1,3,5]\n",
    "#min_impurity_splits=[3e-7, 5e-7,1e-6]\n",
    "\n",
    "#criterion=['entropy']\n",
    "#max_depth=[1,3,510]\n",
    "#split=['best']\n",
    "#min_samples_splits=[2,3]\n",
    "#min_samples_leafs=[1]\n",
    "#min_impurity_splits=[3e-7, 5e-7,8e-5]\n",
    "\n",
    "df_results_DT=scores.hp_tune_Decision_tree(X_train,y_train,X_test,y_test,5,criterion,max_depth,split,min_samples_splits,min_samples_leafs,min_impurity_splits)\n",
    "\n",
    "print('This are the best Parameters for Decision Tree:')\n",
    "print(df_results_DT[df_results_DT[['test_results_auc','test_recall','features']]['test_results_auc']==df_results_DT['test_results_auc'].max()].head())\n",
    "\n",
    "\n",
    "\n",
    "# # KNN \n",
    "\n",
    "\n",
    "# Hyper-Parameter Search Grid Using 10-Fold CV and Test\n",
    "print(' -- KNN --')\n",
    "\n",
    "criterion=['distance', 'uniform']\n",
    "neighbors=[1,2,3,10,50,100]\n",
    "distances = [1, 2, 3, 4, 5]\n",
    "\n",
    "df_results_KNN=scores.hp_tune_KNN(X_train,y_train,X_test,y_test,5,criterion,neighbors,distances)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('This are the best Parameters for KNN :')\n",
    "print(df_results_KNN[df_results_KNN[['test_results_auc','test_recall','features']]['test_results_auc']==df_results_KNN['test_results_auc'].max()].head())\n",
    "\n",
    "\n",
    "# # SVM\n",
    "\n",
    "\n",
    "# Hyper-Parameter Search Grid Using 10-Fold CV and Test\n",
    "print(' -- SVM --')\n",
    "\n",
    "kernel=['rbf', 'linear', 'poly', 'sigmoid']\n",
    "gammas = [.001,.1,1,3,5]\n",
    "cs = [.0001,.1,1,5,10,15,20]\n",
    "\n",
    "df_results_SVM=scores.hp_tune_SVM(X_train,y_train,X_test,y_test,10,kernel,gammas,cs)\n",
    "\n",
    "\n",
    "\n",
    "print('This are the best Parameters for SVM :')\n",
    "print(df_results_SVM[df_results_SVM[['test_results_auc','test_recall','features']]['test_results_auc']==df_results_SVM['test_results_auc'].max()].head())\n",
    "\n",
    "\n",
    "# # Logistic Regression\n",
    "\n",
    "# Hyper-Parameter Search Grid Using 10-Fold CV and Test\n",
    "print(' -- Logistic Regression --')\n",
    "\n",
    "criterion=['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "\n",
    "df_results_log_reg=scores.hp_tune_log_reg(X_train,y_train,X_test,y_test,10,criterion)\n",
    "\n",
    "print('This are the best Parameters for Logistic Regression :')\n",
    "print(df_results_log_reg[df_results_log_reg[['test_results_auc','test_recall','features']]['test_results_auc']==df_results_log_reg['test_results_auc'].max()].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Optimal Random Forest --\n",
      "Training precision:  0.9054393305439331   recall:  0.9747747747747748   F1:  0.9388286334056399   accuracy:  0.939066551426102\n",
      "Training Confusion matrix\n",
      "[[1091  113]\n",
      " [  28 1082]]\n",
      "Training AUC: 0.9404604770883842\n",
      "Optimal precision:  0.8484848484848485   recall:  0.9491525423728814   F1:  0.896   accuracy:  0.8992248062015504\n",
      "optimal Confusion matrix\n",
      "[[120  20]\n",
      " [  6 112]]\n",
      "Optimal AUC: 0.9031476997578695\n",
      " -- Default Random Forest --\n",
      "DEF Training precision:  0.9972850678733032   recall:  0.9927927927927928   F1:  0.9950338600451466   accuracy:  0.9952463267070009\n",
      "DEF Training Confusion matrix\n",
      "[[1201    3]\n",
      " [   8 1102]]\n",
      "DEF Training AUC: 0.9951505492203168\n",
      "Defualt Model precision:  0.8455284552845529   recall:  0.8813559322033898   F1:  0.8630705394190872   accuracy:  0.872093023255814\n",
      "Defualt ModelConfusion matrix\n",
      "[[121  19]\n",
      " [ 14 104]]\n",
      "Defualt ModelAUC: 0.872820823244552\n"
     ]
    }
   ],
   "source": [
    "## Fitting best Model\n",
    "print(' -- Optimal Random Forest --')\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc_opt = RandomForestClassifier(n_estimators=5,criterion='entropy',bootstrap=False,max_depth=10, \n",
    "                                 min_samples_split=10,\n",
    "                                 min_samples_leaf=1,\n",
    "                                 min_impurity_decrease=5e-07,\n",
    "                                 random_state=0\n",
    "                                 ,n_jobs=-1,class_weight={0:y_train.mean(), 1:1-y_train.mean()})\n",
    "rfc_opt.fit(X_train, y_train)\n",
    "\n",
    "train_pred = rfc_opt.predict(X_train)\n",
    "    \n",
    "precision,recall,F1,accuracy,confusion,roc_auc=scores.scores(y_train,train_pred)\n",
    "print('Training precision: ', precision, '  recall: ', recall, '  F1: ', F1, '  accuracy: ', accuracy)\n",
    "print('Training Confusion matrix')\n",
    "print(confusion)\n",
    "print('Training AUC:',roc_auc)\n",
    "\n",
    "\n",
    "y_pred = rfc_opt.predict(X_test)\n",
    "\n",
    "\n",
    "precision,recall,F1,accuracy,confusion,roc_auc=scores.scores(y_test,y_pred)\n",
    "print('Optimal precision: ', precision, '  recall: ', recall, '  F1: ', F1, '  accuracy: ', accuracy)\n",
    "print('optimal Confusion matrix')\n",
    "print(confusion)\n",
    "print('Optimal AUC:',roc_auc)\n",
    "\n",
    "\n",
    "## Compare to Default Model\n",
    "print(' -- Default Random Forest --')\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc_def = RandomForestClassifier(class_weight={0:y_train.mean(), 1:1-y_train.mean()})\n",
    "rfc_def.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "train_pred = rfc_def.predict(X_train)\n",
    "    \n",
    "precision,recall,F1,accuracy,confusion,roc_auc=scores.scores(y_train,train_pred)\n",
    "print('DEF Training precision: ', precision, '  recall: ', recall, '  F1: ', F1, '  accuracy: ', accuracy)\n",
    "print('DEF Training Confusion matrix')\n",
    "print(confusion)\n",
    "print('DEF Training AUC:',roc_auc)\n",
    "\n",
    "y_pred = rfc_def.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "precision,recall,F1,accuracy,confusion,roc_auc=scores.scores(y_test,y_pred)\n",
    "print('Defualt Model precision: ', precision, '  recall: ', recall, '  F1: ', F1, '  accuracy: ', accuracy)\n",
    "print('Defualt ModelConfusion matrix')\n",
    "print(confusion)\n",
    "print('Defualt ModelAUC:',roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ ADAboosting with Random Forest ----\n",
      "0.9608907874816964\n",
      "Defualt Model precision:  0.8449612403100775   recall:  0.923728813559322   F1:  0.8825910931174089   accuracy:  0.8875968992248062\n",
      "Defualt ModelConfusion matrix\n",
      "[[120  20]\n",
      " [  9 109]]\n",
      "Defualt ModelAUC: 0.8904358353510896\n"
     ]
    }
   ],
   "source": [
    "## ADAboosting\n",
    "print('------ ADAboosting with Random Forest ----')\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "rfc_opt = RandomForestClassifier(n_estimators=5,criterion='entropy',bootstrap=False,max_depth=10, \n",
    "                                 min_samples_split=10,\n",
    "                                 min_samples_leaf=1,\n",
    "                                 min_impurity_decrease=5e-07,\n",
    "                                 random_state=0\n",
    "                                 ,n_jobs=-1,class_weight={0:y_train.mean(), 1:1-y_train.mean()})\n",
    "\n",
    "clf = AdaBoostClassifier(base_estimator=rfc_opt, n_estimators=100,learning_rate=1)\n",
    "\n",
    "all_accuracies = cross_val_score(estimator=clf,X=X_train, y=y_train, cv=10,scoring='roc_auc')\n",
    "\n",
    "print(all_accuracies.mean())\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "precision,recall,F1,accuracy,confusion,roc_auc=scores.scores(y_test,y_pred)\n",
    "print('Defualt Model precision: ', precision, '  recall: ', recall, '  F1: ', F1, '  accuracy: ', accuracy)\n",
    "print('Defualt ModelConfusion matrix')\n",
    "print(confusion)\n",
    "print('Defualt ModelAUC:',roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
