{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import scipy.ndimage as ndimage\n",
    "from torchvision import transforms, utils\n",
    "from toolz.curried import pipe, curry, compose\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "\n",
    "import scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_data.csv', 'training_data.csv']\n",
      "(2572, 99)\n",
      "/gpfs/pace1/project/coc-fujimoto/dmo7/citrine_data_challenge/data/training_data.csv\n"
     ]
    }
   ],
   "source": [
    "path_f=os.getcwd()\n",
    "\n",
    "path_f_1=os.path.join(path_f, 'data')\n",
    "\n",
    "\n",
    "names=[]\n",
    "for files_txts in os.listdir(path_f_1):\n",
    "    if files_txts.endswith(\".csv\"):\n",
    "        #print(files_txts)\n",
    "        names.append(files_txts)\n",
    "\n",
    "print(names)\n",
    "path_train=os.path.join(path_f_1, names[1])\n",
    "path_test=os.path.join(path_f_1, names[0])\n",
    "\n",
    "df_train=pd.read_csv(path_train)\n",
    "print(df_train.shape)\n",
    "print(path_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2572, 110)\n",
      "(2572, 110)\n",
      "(1228, 110)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formulaA</th>\n",
       "      <th>formulaB</th>\n",
       "      <th>formulaA_elements_AtomicVolume</th>\n",
       "      <th>formulaB_elements_AtomicVolume</th>\n",
       "      <th>formulaA_elements_AtomicWeight</th>\n",
       "      <th>formulaB_elements_AtomicWeight</th>\n",
       "      <th>formulaA_elements_BoilingT</th>\n",
       "      <th>formulaB_elements_BoilingT</th>\n",
       "      <th>formulaA_elements_BulkModulus</th>\n",
       "      <th>formulaB_elements_BulkModulus</th>\n",
       "      <th>...</th>\n",
       "      <th>A82B</th>\n",
       "      <th>A73B</th>\n",
       "      <th>A64B</th>\n",
       "      <th>A55B</th>\n",
       "      <th>A46B</th>\n",
       "      <th>A37B</th>\n",
       "      <th>A28B</th>\n",
       "      <th>A19B</th>\n",
       "      <th>B</th>\n",
       "      <th>Stable_compunds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89</td>\n",
       "      <td>47</td>\n",
       "      <td>37.433086</td>\n",
       "      <td>17.075648</td>\n",
       "      <td>227.0</td>\n",
       "      <td>107.868200</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>2435.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89</td>\n",
       "      <td>13</td>\n",
       "      <td>37.433086</td>\n",
       "      <td>16.594425</td>\n",
       "      <td>227.0</td>\n",
       "      <td>26.981539</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>2792.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>89</td>\n",
       "      <td>35</td>\n",
       "      <td>37.433086</td>\n",
       "      <td>42.527825</td>\n",
       "      <td>227.0</td>\n",
       "      <td>79.904000</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>332.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>89</td>\n",
       "      <td>49</td>\n",
       "      <td>37.433086</td>\n",
       "      <td>26.082658</td>\n",
       "      <td>227.0</td>\n",
       "      <td>114.818000</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>2345.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>89</td>\n",
       "      <td>81</td>\n",
       "      <td>37.433086</td>\n",
       "      <td>28.640877</td>\n",
       "      <td>227.0</td>\n",
       "      <td>204.383300</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>1746.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    formulaA  formulaB  formulaA_elements_AtomicVolume  \\\n",
       "0         89        47                       37.433086   \n",
       "1         89        13                       37.433086   \n",
       "5         89        35                       37.433086   \n",
       "10        89        49                       37.433086   \n",
       "28        89        81                       37.433086   \n",
       "\n",
       "    formulaB_elements_AtomicVolume  formulaA_elements_AtomicWeight  \\\n",
       "0                        17.075648                           227.0   \n",
       "1                        16.594425                           227.0   \n",
       "5                        42.527825                           227.0   \n",
       "10                       26.082658                           227.0   \n",
       "28                       28.640877                           227.0   \n",
       "\n",
       "    formulaB_elements_AtomicWeight  formulaA_elements_BoilingT  \\\n",
       "0                       107.868200                      3473.0   \n",
       "1                        26.981539                      3473.0   \n",
       "5                        79.904000                      3473.0   \n",
       "10                      114.818000                      3473.0   \n",
       "28                      204.383300                      3473.0   \n",
       "\n",
       "    formulaB_elements_BoilingT  formulaA_elements_BulkModulus  \\\n",
       "0                       2435.0                            0.0   \n",
       "1                       2792.0                            0.0   \n",
       "5                        332.0                            0.0   \n",
       "10                      2345.0                            0.0   \n",
       "28                      1746.0                            0.0   \n",
       "\n",
       "    formulaB_elements_BulkModulus       ...         A82B  A73B  A64B  A55B  \\\n",
       "0                           100.0       ...            0     1     0     1   \n",
       "1                            76.0       ...            0     1     0     0   \n",
       "5                             1.9       ...            0     1     0     0   \n",
       "10                            0.0       ...            0     1     0     0   \n",
       "28                           43.0       ...            0     0     0     0   \n",
       "\n",
       "    A46B  A37B  A28B  A19B  B  Stable_compunds  \n",
       "0      0     0     0     0  1                1  \n",
       "1      0     0     0     0  1                1  \n",
       "5      0     0     0     0  1                1  \n",
       "10     0     0     1     0  1                1  \n",
       "28     0     0     1     0  1                1  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stab_vector=df_train['stabilityVec'].values\n",
    "y=[]\n",
    "for x in stab_vector:\n",
    "    #print(x)\n",
    "    a=np.fromstring(x[1:-1],sep=',').astype(int)\n",
    "    y.append(a)\n",
    "y=np.array(y) \n",
    "\n",
    "df_tmp = pd.DataFrame(y, columns = ['A', 'A91B', 'A82B','A73B','A64B','A55B','A46B','A37B','A28B','A19B','B'])\n",
    "stab_vec_list=[ 'A91B', 'A82B','A73B','A64B','A55B','A46B','A37B','A28B','A19B']\n",
    "\n",
    "df_train=df_train.drop(\"stabilityVec\",axis=1) #removing the results which originally are a string\n",
    "feature_cols=list(df_train)\n",
    "\n",
    "\n",
    "\n",
    "df_train['formulaA']=df_train['formulaA_elements_Number']\n",
    "df_train['formulaB']=df_train['formulaB_elements_Number']\n",
    "\n",
    "\n",
    "df_train=pd.concat([df_train, df_tmp],axis=1)\n",
    "\n",
    "y_all=df_train[stab_vec_list]\n",
    "df_tmp_stable = pd.DataFrame( columns = ['Stable_compunds'])\n",
    "df_tmp_stable['Stable_compunds']=np.logical_not(y_all.sum(axis=1)==0).astype(int) ## A one means it has a stable value  a 0 \n",
    "\n",
    "df_train=pd.concat([df_train, df_tmp_stable],axis=1)\n",
    "print(df_train.shape)\n",
    "\n",
    "\n",
    "print(df_train.shape)\n",
    "\n",
    "\n",
    "df_stable=df_train.loc[np.logical_not(y_all.sum(axis=1)==0)]\n",
    "print(df_stable.shape)\n",
    "df_stable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_new=df_stable[feature_cols]\n",
    "y_target=df_stable[stab_vec_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A91B</th>\n",
       "      <th>A82B</th>\n",
       "      <th>A73B</th>\n",
       "      <th>A64B</th>\n",
       "      <th>A55B</th>\n",
       "      <th>A46B</th>\n",
       "      <th>A37B</th>\n",
       "      <th>A28B</th>\n",
       "      <th>A19B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A91B  A82B  A73B  A64B  A55B  A46B  A37B  A28B  A19B\n",
       "0      0     0     1     0     1     0     0     0     0\n",
       "1      0     0     1     0     0     0     0     0     0\n",
       "5      0     0     1     0     0     0     0     0     0\n",
       "10     0     0     1     0     0     0     0     1     0\n",
       "28     0     0     0     0     0     0     0     1     0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan 22 23:51:41 2019       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 390.30                 Driver Version: 390.30                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  On   | 00000000:02:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    26W / 250W |      0MiB / 16280MiB |      0%   E. Process |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla P100-PCIE...  On   | 00000000:03:00.0 Off |                    0 |\n",
      "| N/A   27C    P0    26W / 250W |      0MiB / 16280MiB |      0%   E. Process |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla P100-PCIE...  On   | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   27C    P0    26W / 250W |      0MiB / 16280MiB |      0%   E. Process |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")#device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(98, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(120, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(60, 30),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(30, 9)\n",
    "        )\n",
    "    def forward(self, batch):\n",
    "        return self.layers(batch)\n",
    "    \n",
    "class MKSnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MKSnet, self).__init__()\n",
    "        self.fc1=nn.Linear(98,120)\n",
    "        self.relu1=nn.ReLU()\n",
    "        self.do1=nn.Dropout(p=0.2)\n",
    "        self.fc2=nn.Linear(120,60)\n",
    "        self.relu2=nn.ReLU()\n",
    "        self.do2=nn.Dropout(p=0.2)\n",
    "        self.fc3=nn.Linear(60,30)\n",
    "        self.relu3=nn.ReLU()\n",
    "        self.do3=nn.Dropout(p=0.2)\n",
    "        self.fc4=nn.Linear(30,9)\n",
    "    def forward(self,x):\n",
    "        ut=self.fc1(x)\n",
    "        out=self.relu1(out)\n",
    "        out=self.do1(out)\n",
    "        out=self.fc2(out)\n",
    "        out=self.relu2(out)\n",
    "        out=self.do3(out)\n",
    "        out=self.fc3(out)\n",
    "        out=self.relu3(out)\n",
    "        out=self.do3(out)\n",
    "        out=self.fc4(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class feature_Dataset(Dataset):\n",
    "    \"\"\"Face landmarks Dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, X_features, y_target,test_size):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"        \n",
    "        self.X_features=X_features\n",
    "        self.y_target=y_target\n",
    "        self.test_size = test_size\n",
    "        assert len(X_features) == len(y_target)\n",
    "        \n",
    "\n",
    "\n",
    "        self.X_features = torch.from_numpy(X_features.values).float()\n",
    "        self.y_target = torch.from_numpy(y_target.values).float()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X_features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        \n",
    "        item = {'index': idx}\n",
    "        item['features'] = self.X_features[idx,:]\n",
    "        item['outputs'] = self.y_target[idx,:]\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class arg_dataset(Dataset):\n",
    "    \"\"\"Face landmarks Dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, data, y_true,test_size):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"        \n",
    "        self.data=data\n",
    "        self.y_true=y_true\n",
    "        self.test_size = test_size\n",
    "        assert len(data) == len(y_true)\n",
    "        \n",
    "    \n",
    "        X_train, X_test, y_train, y_test = train_test_split(data, y_true,\n",
    "                                                            test_size=test_size,\n",
    "                                                            shuffle=True,\n",
    "                                                            random_state=42)\n",
    "        self.data = data\n",
    "\n",
    "        self.X_train = torch.from_numpy(X_train.values).float()\n",
    "        self.y_train = torch.from_numpy(y_train.values).float()\n",
    "        self.X_test = torch.from_numpy(X_test.values).float()\n",
    "        self.y_test = torch.from_numpy(y_test.values).float()\n",
    "\n",
    "        self.num_data_points = {}\n",
    "        self.num_data_points['train'] = len(X_train)\n",
    "        self.num_data_points['test'] = len(X_test)\n",
    "        \n",
    "        self._split = 'train'\n",
    "\n",
    "    @property\n",
    "    def split(self):\n",
    "        return self._split\n",
    "\n",
    "    @split.setter\n",
    "    def split(self, split):\n",
    "        self._split = split\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # methods to override - __len__ and __getitem__ methods\n",
    "    # ------------------------------------------------------------------------\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_data_points[self._split]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dtype = self._split\n",
    "        item = {'index': idx}\n",
    "        item['features'] = self.X_train[idx,:]\n",
    "        item['outputs'] = self.y_train[idx,:]\n",
    "        return item\n",
    "\n",
    "    #-------------------------------------------------------------------------\n",
    "    # collate function utilized by dataloader for batching\n",
    "    #-------------------------------------------------------------------------\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        dtype = self._split\n",
    "        merged_batch = {key: [d[key] for d in batch] for key in batch[0]}\n",
    "        out = {}\n",
    "        for key in merged_batch:\n",
    "            if key in {'index'}:\n",
    "                out[key] = merged_batch[key]\n",
    "            else:\n",
    "                out[key] = torch.stack(merged_batch[key], 0)\n",
    "\n",
    "        batch_keys = ['features', 'outputs']\n",
    "        return {key: out[key] for key in batch_keys}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1105, 98) (1105, 9)\n",
      "(123, 98) (123, 9)\n"
     ]
    }
   ],
   "source": [
    "## test-train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_new, y_target,\n",
    "                                                    test_size=.1,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=42)\n",
    "\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape,y_test.shape)\n",
    "#X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formulaA</th>\n",
       "      <th>formulaB</th>\n",
       "      <th>formulaA_elements_AtomicVolume</th>\n",
       "      <th>formulaB_elements_AtomicVolume</th>\n",
       "      <th>formulaA_elements_AtomicWeight</th>\n",
       "      <th>formulaB_elements_AtomicWeight</th>\n",
       "      <th>formulaA_elements_BoilingT</th>\n",
       "      <th>formulaB_elements_BoilingT</th>\n",
       "      <th>formulaA_elements_BulkModulus</th>\n",
       "      <th>formulaB_elements_BulkModulus</th>\n",
       "      <th>...</th>\n",
       "      <th>formulaA_elements_Row</th>\n",
       "      <th>formulaB_elements_Row</th>\n",
       "      <th>formulaA_elements_ShearModulus</th>\n",
       "      <th>formulaB_elements_ShearModulus</th>\n",
       "      <th>formulaA_elements_SpaceGroupNumber</th>\n",
       "      <th>formulaB_elements_SpaceGroupNumber</th>\n",
       "      <th>avg_coordination_A</th>\n",
       "      <th>avg_coordination_B</th>\n",
       "      <th>avg_nearest_neighbor_distance_A</th>\n",
       "      <th>avg_nearest_neighbor_distance_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2490</th>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>43.739672</td>\n",
       "      <td>24.611742</td>\n",
       "      <td>173.054000</td>\n",
       "      <td>200.590000</td>\n",
       "      <td>1469.00</td>\n",
       "      <td>629.73</td>\n",
       "      <td>31.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225</td>\n",
       "      <td>166</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.85320</td>\n",
       "      <td>3.39770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>75</td>\n",
       "      <td>15</td>\n",
       "      <td>14.710334</td>\n",
       "      <td>28.214122</td>\n",
       "      <td>186.207000</td>\n",
       "      <td>30.973762</td>\n",
       "      <td>5869.00</td>\n",
       "      <td>553.50</td>\n",
       "      <td>370.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>194</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.76299</td>\n",
       "      <td>2.21377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>45</td>\n",
       "      <td>82</td>\n",
       "      <td>13.725510</td>\n",
       "      <td>30.341423</td>\n",
       "      <td>102.905500</td>\n",
       "      <td>207.200000</td>\n",
       "      <td>3968.00</td>\n",
       "      <td>2022.00</td>\n",
       "      <td>380.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>150.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>225</td>\n",
       "      <td>225</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.72142</td>\n",
       "      <td>3.57454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>21</td>\n",
       "      <td>44</td>\n",
       "      <td>25.009311</td>\n",
       "      <td>13.567874</td>\n",
       "      <td>44.955912</td>\n",
       "      <td>101.070000</td>\n",
       "      <td>3103.00</td>\n",
       "      <td>4423.00</td>\n",
       "      <td>57.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>29.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>194</td>\n",
       "      <td>194</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.21375</td>\n",
       "      <td>2.66567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>80</td>\n",
       "      <td>89</td>\n",
       "      <td>24.611742</td>\n",
       "      <td>37.433086</td>\n",
       "      <td>200.590000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>629.73</td>\n",
       "      <td>3473.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166</td>\n",
       "      <td>225</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.39770</td>\n",
       "      <td>3.99462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      formulaA  formulaB  formulaA_elements_AtomicVolume  \\\n",
       "2490        70        80                       43.739672   \n",
       "1783        75        15                       14.710334   \n",
       "1809        45        82                       13.725510   \n",
       "1936        21        44                       25.009311   \n",
       "851         80        89                       24.611742   \n",
       "\n",
       "      formulaB_elements_AtomicVolume  formulaA_elements_AtomicWeight  \\\n",
       "2490                       24.611742                      173.054000   \n",
       "1783                       28.214122                      186.207000   \n",
       "1809                       30.341423                      102.905500   \n",
       "1936                       13.567874                       44.955912   \n",
       "851                        37.433086                      200.590000   \n",
       "\n",
       "      formulaB_elements_AtomicWeight  formulaA_elements_BoilingT  \\\n",
       "2490                      200.590000                     1469.00   \n",
       "1783                       30.973762                     5869.00   \n",
       "1809                      207.200000                     3968.00   \n",
       "1936                      101.070000                     3103.00   \n",
       "851                       227.000000                      629.73   \n",
       "\n",
       "      formulaB_elements_BoilingT  formulaA_elements_BulkModulus  \\\n",
       "2490                      629.73                           31.0   \n",
       "1783                      553.50                          370.0   \n",
       "1809                     2022.00                          380.0   \n",
       "1936                     4423.00                           57.0   \n",
       "851                      3473.00                           25.0   \n",
       "\n",
       "      formulaB_elements_BulkModulus               ...                 \\\n",
       "2490                           25.0               ...                  \n",
       "1783                           11.0               ...                  \n",
       "1809                           46.0               ...                  \n",
       "1936                          220.0               ...                  \n",
       "851                             0.0               ...                  \n",
       "\n",
       "      formulaA_elements_Row  formulaB_elements_Row  \\\n",
       "2490                      6                      6   \n",
       "1783                      6                      3   \n",
       "1809                      5                      6   \n",
       "1936                      4                      5   \n",
       "851                       6                      7   \n",
       "\n",
       "      formulaA_elements_ShearModulus  formulaB_elements_ShearModulus  \\\n",
       "2490                             9.9                             0.0   \n",
       "1783                           178.0                             0.0   \n",
       "1809                           150.0                             5.6   \n",
       "1936                            29.0                           173.0   \n",
       "851                              0.0                             0.0   \n",
       "\n",
       "      formulaA_elements_SpaceGroupNumber  formulaB_elements_SpaceGroupNumber  \\\n",
       "2490                                 225                                 166   \n",
       "1783                                 194                                   2   \n",
       "1809                                 225                                 225   \n",
       "1936                                 194                                 194   \n",
       "851                                  166                                 225   \n",
       "\n",
       "      avg_coordination_A  avg_coordination_B  avg_nearest_neighbor_distance_A  \\\n",
       "2490                12.0                12.0                          3.85320   \n",
       "1783                12.0                 3.0                          2.76299   \n",
       "1809                12.0                12.0                          2.72142   \n",
       "1936                12.0                12.0                          3.21375   \n",
       "851                 12.0                12.0                          3.39770   \n",
       "\n",
       "      avg_nearest_neighbor_distance_B  \n",
       "2490                          3.39770  \n",
       "1783                          2.21377  \n",
       "1809                          3.57454  \n",
       "1936                          2.66567  \n",
       "851                           3.99462  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dataset = feature_Dataset(X_train, y_train,.33) ## Now you can feed any X-train and Y-train. normalize it and feed the highest pearson correlated one\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=6)\n",
    "\n",
    "val_dataset = feature_Dataset(X_test, y_test,.33)\n",
    "\n",
    "valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:  tensor([[   70.0000,    80.0000,    43.7397,    24.6117,   173.0540,   200.5900,\n",
      "          1469.0000,   629.7300,    31.0000,    25.0000,     3.0000,    12.0000,\n",
      "           187.0000,   132.0000,  6570.0000, 13534.0000,     0.9200,     1.2400,\n",
      "             1.2600,     2.0000,     6.2542,    10.4375,     0.0000,     0.0000,\n",
      "            -1.4741,    -0.2501,     4.0865,     3.6957,     5.1486,     4.6562,\n",
      "             0.0000,     0.0000,    34.1200,    25.2376,  9500.0000,  5500.0000,\n",
      "          3100.0000,  3100.0000,     0.1550,     0.1400,    26.7400,    27.9830,\n",
      "             7.6600,     2.2950,    41.1700,    23.8200,     0.0000,     0.0000,\n",
      "             0.0000,     1.0000,     1.0000,     0.0000,     1.0000,     1.0000,\n",
      "             0.0000,     0.0000,     0.0000,     0.0000,  1092.0000,   234.3200,\n",
      "            39.0000,    71.0000,   190.0000,   152.0000,     0.0000,     0.0000,\n",
      "            16.0000,    26.0000,     0.0000,     0.0000,     0.0000,    10.0000,\n",
      "             0.0000,     0.0000,    14.0000,    14.0000,     0.0000,     0.0000,\n",
      "             0.0000,     0.0000,     0.0000,     0.0000,     2.0000,     2.0000,\n",
      "            70.0000,    80.0000,    20.9000,     5.3600,     6.0000,     6.0000,\n",
      "             9.9000,     0.0000,   225.0000,   166.0000,    12.0000,    12.0000,\n",
      "             3.8532,     3.3977]])\n",
      "outputs:  tensor([0., 0., 1., 0., 1., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "item = train_dataset[0]\n",
    "\n",
    "x = item['features'][None]\n",
    "print(\"features: \", x)\n",
    "y = item['outputs']\n",
    "print(\"outputs: \", y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of steps per epoch: 18\n"
     ]
    }
   ],
   "source": [
    "total_step = len(trainloader)\n",
    "print(\"No. of steps per epoch: %d\" % total_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "num_epochs = 200\n",
    "learning_rate = 0.001\n",
    "criterion = nn.MultiLabelSoftMarginLoss()\n",
    "#criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of steps per epoch: 18\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "total_step = len(trainloader)\n",
    "print(\"No. of steps per epoch: %d\" % total_step)\n",
    "# Loss and optimizer\n",
    "num_epochs = 200\n",
    "learning_rate = 0.001\n",
    "criterion = nn.MultiLabelSoftMarginLoss()\n",
    "#criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiLabelSoftMarginLoss()\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.001\n",
      "    weight_decay: 0\n",
      ")\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n"
     ]
    }
   ],
   "source": [
    "print(criterion)\n",
    "print(optimizer)\n",
    "for epoch in range(num_epochs):\n",
    "    if epoch > 0:\n",
    "        learning_rate = 0.0005\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    elif epoch >= 10:\n",
    "        learning_rate = 0.0002\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    elif epoch > 80:\n",
    "        learning_rate = 0.0001\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for i, item in enumerate(trainloader):\n",
    "        model.train()\n",
    "        x = item['features'].to(device)\n",
    "        target = item['outputs'].to(device)\n",
    "        # Forward pass\n",
    "        output = model(x)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-ffcdcdd5b18d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                 \u001b[0my_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0my_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                 \u001b[0mval_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/data/anaconda3/envs/pytorch_PACE/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/anaconda3/envs/pytorch_PACE/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultilabel_soft_margin_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/anaconda3/envs/pytorch_PACE/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmultilabel_soft_margin_loss\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   1779\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1781\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data/anaconda3/envs/pytorch_PACE/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   1590\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1592\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1593\u001b[0m         warnings.warn(\"Using a target size ({}) that is different to the input size ({}) is deprecated. \"\n\u001b[1;32m   1594\u001b[0m                       \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "val_loss = 0.0\n",
    "for i1, item1 in enumerate(valloader):\n",
    "                x_val = item1['features'].to(device)\n",
    "                y_val = item1['outputs'].to(device)\n",
    "                model.eval()\n",
    "                y_pre = model(x_val)\n",
    "                y_pre = torch.sigmoid(y_pre).data > 0.5\n",
    "                y_pre = y_pre.cpu().numpy()\n",
    "                val_loss += criterion(y_val, y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        if (i) % 20 == 0:\n",
    "            # np.random.seed(2*i + 1865 + 39 * epoch)\n",
    "            # indx = np.random.randint(0, 1999, 1)[0]\n",
    "            # item1 = val_dataset[indx]\n",
    "            niter = 10\n",
    "            val_loss = 0.0\n",
    "            for i1, item1 in enumerate(valloader):\n",
    "                x_val = item1['features'].to(device)\n",
    "                y_val = item1['outputs'].to(device)\n",
    "                model.eval()\n",
    "                y_pre = model(x_val)\n",
    "                y_pre = torch.sigmoid(y_pre).data > 0.5\n",
    "                y_pre = y_pre.cpu().numpy()\n",
    "                val_loss += criterion(y_val, y_pre)\n",
    "                if i1 == niter-1:\n",
    "                    break\n",
    "            if val_loss.item()/niter < 26.5:\n",
    "                torch.save(model.state_dict(), \"learnt_weights_C3_%d_%d\" % (i, epoch))\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.6f}, Val Loss: {:.6f}' \n",
    "                   .format(epoch+1, num_epochs, i, total_step, loss.item(), val_loss.item()/niter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 1., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 1., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 1., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 1., 0., 1., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 1., 1., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 1., 1., 0., 0., 0.],\n",
       "        [0., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0., 1., 1., 1., 1., 0.],\n",
       "        [0., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 1., 1., 0., 0., 0.],\n",
       "        [0., 1., 1., 0., 1., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 1., 1., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 1., 1., 0.],\n",
       "        [0., 0., 0., 1., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 1., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 1., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1., 1., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
