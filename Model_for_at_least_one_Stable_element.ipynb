{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "\n",
    "import scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2572, 99)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_f=os.getcwd()\n",
    "\n",
    "path_f_1=os.path.join(path_f, 'data')\n",
    "\n",
    "\n",
    "names=[]\n",
    "for files_txts in os.listdir(path_f_1):\n",
    "    if files_txts.endswith(\".csv\"):\n",
    "        #print(files_txts)\n",
    "        names.append(files_txts)\n",
    "        \n",
    "path_train=os.path.join(path_f_1, names[0])\n",
    "path_test=os.path.join(path_f_1, names[1])\n",
    "\n",
    "df_train=pd.read_csv(path_train)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation\n",
    "\n",
    " - Transforming the outcome to a numpy vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2572, 98)\n",
      "(2572, 109)\n"
     ]
    }
   ],
   "source": [
    "stab_vector=df_train['stabilityVec'].values\n",
    "y=[]\n",
    "for x in stab_vector:\n",
    "    #print(x)\n",
    "    a=np.fromstring(x[1:-1],sep=',').astype(int)\n",
    "    y.append(a)\n",
    "y=np.array(y) \n",
    "\n",
    "df_tmp = pd.DataFrame(y, columns = ['A', 'A91B', 'A82B','A73B','A64B','A55B','A46B','A37B','A28B','A19B','B'])\n",
    "stab_vec_list=[ 'A91B', 'A82B','A73B','A64B','A55B','A46B','A37B','A28B','A19B']\n",
    "\n",
    "df_train=df_train.drop(\"stabilityVec\",axis=1) #removing the results which originally are a string\n",
    "feature_cols=list(df_train)\n",
    "\n",
    "print(df_train.shape)\n",
    "\n",
    "csvfile = csv.reader(open(path_train,'r'))\n",
    "header = next(csvfile)\n",
    "\n",
    "formulaA = []\n",
    "formulaB = []\n",
    "\n",
    "for row in csvfile:\n",
    "    formulaA.append(row[0])\n",
    "    formulaB.append(row[1])\n",
    "formulas = formulaA + formulaB\n",
    "formulas = list(set(formulas))\n",
    "\n",
    "# -- /!\\ need to save the dict as the ordering may difer at each run\n",
    "formula2int = {}\n",
    "int2formula = {}\n",
    "for i, f in enumerate(formulas):\n",
    "    formula2int[f] = i\n",
    "    int2formula[i] = f\n",
    "\n",
    "formulaAint = np.array([formula2int[x] for x in formulaA])\n",
    "formulaBint = np.array([formula2int[x] for x in formulaB])\n",
    "\n",
    "df_train['formulaA']=formulaAint\n",
    "df_train['formulaB']=formulaBint\n",
    "\n",
    "df_train=pd.concat([df_train, df_tmp],axis=1)\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Data Normalization and Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2572, 110)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formulaA</th>\n",
       "      <th>formulaB</th>\n",
       "      <th>formulaA_elements_AtomicVolume</th>\n",
       "      <th>formulaB_elements_AtomicVolume</th>\n",
       "      <th>formulaA_elements_AtomicWeight</th>\n",
       "      <th>formulaB_elements_AtomicWeight</th>\n",
       "      <th>formulaA_elements_BoilingT</th>\n",
       "      <th>formulaB_elements_BoilingT</th>\n",
       "      <th>formulaA_elements_BulkModulus</th>\n",
       "      <th>formulaB_elements_BulkModulus</th>\n",
       "      <th>...</th>\n",
       "      <th>A82B</th>\n",
       "      <th>A73B</th>\n",
       "      <th>A64B</th>\n",
       "      <th>A55B</th>\n",
       "      <th>A46B</th>\n",
       "      <th>A37B</th>\n",
       "      <th>A28B</th>\n",
       "      <th>A19B</th>\n",
       "      <th>B</th>\n",
       "      <th>Stable_compunds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>81</td>\n",
       "      <td>37.433086</td>\n",
       "      <td>17.075648</td>\n",
       "      <td>227.0</td>\n",
       "      <td>107.868200</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>2435.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>63</td>\n",
       "      <td>37.433086</td>\n",
       "      <td>16.594425</td>\n",
       "      <td>227.0</td>\n",
       "      <td>26.981539</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>2792.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>77</td>\n",
       "      <td>37.433086</td>\n",
       "      <td>21.723966</td>\n",
       "      <td>227.0</td>\n",
       "      <td>74.921600</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>887.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>22</td>\n",
       "      <td>37.433086</td>\n",
       "      <td>64.969282</td>\n",
       "      <td>227.0</td>\n",
       "      <td>137.327000</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>2143.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>28</td>\n",
       "      <td>37.433086</td>\n",
       "      <td>35.483459</td>\n",
       "      <td>227.0</td>\n",
       "      <td>208.980400</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>1837.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   formulaA  formulaB  formulaA_elements_AtomicVolume  \\\n",
       "0        47        81                       37.433086   \n",
       "1        47        63                       37.433086   \n",
       "2        47        77                       37.433086   \n",
       "3        47        22                       37.433086   \n",
       "4        47        28                       37.433086   \n",
       "\n",
       "   formulaB_elements_AtomicVolume  formulaA_elements_AtomicWeight  \\\n",
       "0                       17.075648                           227.0   \n",
       "1                       16.594425                           227.0   \n",
       "2                       21.723966                           227.0   \n",
       "3                       64.969282                           227.0   \n",
       "4                       35.483459                           227.0   \n",
       "\n",
       "   formulaB_elements_AtomicWeight  formulaA_elements_BoilingT  \\\n",
       "0                      107.868200                      3473.0   \n",
       "1                       26.981539                      3473.0   \n",
       "2                       74.921600                      3473.0   \n",
       "3                      137.327000                      3473.0   \n",
       "4                      208.980400                      3473.0   \n",
       "\n",
       "   formulaB_elements_BoilingT  formulaA_elements_BulkModulus  \\\n",
       "0                      2435.0                            0.0   \n",
       "1                      2792.0                            0.0   \n",
       "2                       887.0                            0.0   \n",
       "3                      2143.0                            0.0   \n",
       "4                      1837.0                            0.0   \n",
       "\n",
       "   formulaB_elements_BulkModulus       ...         A82B  A73B  A64B  A55B  \\\n",
       "0                          100.0       ...            0     1     0     1   \n",
       "1                           76.0       ...            0     1     0     0   \n",
       "2                           22.0       ...            0     0     0     0   \n",
       "3                            9.6       ...            0     0     0     0   \n",
       "4                           31.0       ...            0     0     0     0   \n",
       "\n",
       "   A46B  A37B  A28B  A19B  B  Stable_compunds  \n",
       "0     0     0     0     0  1                1  \n",
       "1     0     0     0     0  1                1  \n",
       "2     0     0     0     0  1                0  \n",
       "3     0     0     0     0  1                0  \n",
       "4     0     0     0     0  1                0  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all=df_train[stab_vec_list]\n",
    "df_tmp_stable = pd.DataFrame( columns = ['Stable_compunds'])\n",
    "df_tmp_stable['Stable_compunds']=np.logical_not(y_all.sum(axis=1)==0).astype(int) ## A one means it has a stable value  a 0 \n",
    "\n",
    "df_train=pd.concat([df_train, df_tmp_stable],axis=1)\n",
    "print(df_train.shape)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson Correlation to Identify the features that influence the most on the output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 99)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0f831908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_new=df_train[feature_cols]\n",
    "y_new=df_train['Stable_compunds']\n",
    "\n",
    "corr_df=pd.concat([X_train_new, y_new],axis=1)\n",
    "a=corr_df.corr()\n",
    "a['Stable_compunds'].hist(bins=7, figsize=(18, 12), xlabelsize=10)\n",
    "\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Incorporating the Features that contribute the most based on a pearson correlation coefficient threshold\n",
    "thr=.1\n",
    "print(a[a['Stable_compunds'].abs()>thr].shape)\n",
    "corr_variables=list(a[a['Stable_compunds'].abs()>thr].index)\n",
    "\n",
    "del(corr_variables[-1])\n",
    "\n",
    "print(corr_variables[-1])\n",
    "print(a['avg_nearest_neighbor_distance_B'].iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using Un-normalized data as input\n",
    "X_train_new=df_train[corr_variables]\n",
    "\n",
    "print(X_train_new.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Normalizing such that the magnitude is one\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "X_train_new_mag_1=normalize(X_train_new, axis=1) # vector magnitude is one\n",
    "print(X_train_new_mag_1.shape)\n",
    "\n",
    "\n",
    "## Normalizing by Zscore\n",
    "from scipy.stats import zscore\n",
    "X_train_new_Z_score=X_train_new.apply(zscore)\n",
    "print(X_train_new_Z_score.shape)\n",
    "\n",
    "\n",
    "## Normalizing by Zscore and then 0-1\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train_new_Z_0_1=min_max_scaler.fit_transform(X_train_new_Z_score)\n",
    "print(X_train_new_Z_0_1.shape)\n",
    "\n",
    "\n",
    "## Normalizing so that range is 0-1\n",
    "from sklearn import preprocessing\n",
    "X_train_new_0_1=min_max_scaler.fit_transform(X_train_new)\n",
    "print(X_train_new_0_1.shape)\n",
    "\n",
    "\n",
    "## Normalizing so that range is -1 to 1\n",
    "from sklearn import preprocessing\n",
    "max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "X_train_new_m1_p1=max_abs_scaler.fit_transform(X_train_new)\n",
    "print(X_train_new_m1_p1.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using PCA as input\n",
    "X_train_4_PCA=df_train[feature_cols]\n",
    "print(X_train_4_PCA.shape)\n",
    "X_train_new_mag_1_PCA=normalize(X_train_4_PCA, axis=1)\n",
    "print(X_train_new_mag_1_PCA.shape)\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X_train_new_mag_1_PCA)\n",
    "components = pca.components_[:20,:]\n",
    "new_data = np.dot(X_train_new_mag_1_PCA, components.T)\n",
    "X_train_new_PCA=new_data\n",
    "\n",
    "print(X_train_new_PCA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using Pearson Correlation in PCA\n",
    "df1= pd.DataFrame(data=X_train_new_PCA)\n",
    "print(df1.shape)\n",
    "\n",
    "\n",
    "corr_df_PCA=pd.concat([df1, y_new],axis=1)\n",
    "\n",
    "print(corr_df_PCA.shape)\n",
    "a_PCA=corr_df_PCA.corr()\n",
    "#a_PCA['Stable_compunds'].hist(bins=7, figsize=(18, 12), xlabelsize=10)\n",
    "a_PCA.shape\n",
    "\n",
    "thr=.01\n",
    "print(a_PCA[a_PCA['Stable_compunds'].abs()>thr].shape)\n",
    "corr_variables_PCA=list(a_PCA[a_PCA['Stable_compunds'].abs()>thr].index)\n",
    "\n",
    "del(corr_variables_PCA[-1])\n",
    "print(corr_variables_PCA)\n",
    "\n",
    "X_train_PCA_PC=df1[corr_variables_PCA]\n",
    "X_train_PCA_PC.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the Output Data Recieved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train[stab_vec_list]\n",
    "print(y.sum(axis=1).value_counts())\n",
    "## Observing how many element pairs produce a stable compound per % and overall\n",
    "f,a = plt.subplots(3,3)\n",
    "f.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "a = a.ravel()\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "y_all=df_train[stab_vec_list]\n",
    "\n",
    "for count,ax in enumerate(a):\n",
    "    \n",
    "    y = df_train[stab_vec_list[count]]\n",
    "    #print(y.value_counts())\n",
    "    hist_1, bin_edges_1 = np.histogram(y)\n",
    "    freq_1=hist_1/y.size\n",
    "    \n",
    "    ax.hist(y.values, bins=10, label='all elements')\n",
    "\n",
    "\n",
    "    #ax.xlim(min(bin_edges), max(bin_edges))\n",
    "    #ax.title(stab_vec_list[count])\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_xlabel('Value')\n",
    "    \n",
    "    \n",
    "\n",
    "#for count in range(9):\n",
    "\n",
    "    #y = df_train[stab_vec_list[count]]\n",
    "    stable_comp=df_train.loc[y==1,['formulaA','formulaB']]\n",
    "    #print('Compound being analyzed is',stab_vec_list[count])\n",
    "    stable_comp_num=stable_comp.values\n",
    "    stable_A=np.unique(stable_comp_num[:,0])\n",
    "    stable_B=np.unique(stable_comp_num[:,1])\n",
    "    df_unique= pd.DataFrame()\n",
    "    #print(df_unique.shape)\n",
    "\n",
    "    y_unique= pd.DataFrame()\n",
    "    \n",
    "    for cnt in range(stable_A.shape[0]):\n",
    "        #print(stable_A[cnt])\n",
    "        df_tmp=y.loc[df_train['formulaA']==stable_A[cnt]]\n",
    "        y_unique=pd.concat([y_unique, df_tmp],axis=0)\n",
    "        #print(df_tmp.shape)\n",
    "        #print(df_unique.shape)\n",
    "    \n",
    "    #print(y_unique.shape)\n",
    "\n",
    "    for cnt in range(stable_B.shape[0]):\n",
    "        #print(stable_A[cnt])\n",
    "        df_tmp=y.loc[df_train['formulaB']==stable_B[cnt]]\n",
    "        y_unique=pd.concat([y_unique, df_tmp],axis=0)\n",
    "\n",
    "    \n",
    "    y_unique=y.iloc[y_unique.index.unique()]\n",
    "    ax.hist(y_unique.values, bins=10, label='stable elements')\n",
    "    #print(y_unique.value_counts())\n",
    "\n",
    "    #ax.xlim(min(bin_edges), max(bin_edges))\n",
    "    #ax.title()\n",
    "    #print(stab_vec_list[count])\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_xlabel('Value')\n",
    "    \n",
    "    \n",
    "    y_stable=y_unique.loc[np.logical_not(y_all.sum(axis=1)==0)]\n",
    "    ax.hist(y_stable.values, bins=10, label='stable elements')\n",
    "    #print(y_stable.value_counts())\n",
    "\n",
    "    #ax.xlim(min(bin_edges), max(bin_edges))\n",
    "    #ax.title()\n",
    "    #print(stab_vec_list[count])\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_xlabel('Value')\n",
    "    \n",
    "    ax.legend(loc='upper right')\n",
    "    \n",
    "    \n",
    "    ax.legend(loc='upper right')\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we will build a model to determine if the input elements will produce at least one stable compound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train[stab_vec_list]\n",
    "print(y.sum(axis=1).value_counts())\n",
    "\n",
    "print('These are example of elements that produce no stable compounds')\n",
    "\n",
    "(df_train.loc[y_all.sum(axis=1)==0].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new=df_train['Stable_compunds']\n",
    "y_new.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test-train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_new_Z_score, y_new,\n",
    "                                                    test_size=.1,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=42)\n",
    "\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape,y_test.shape)\n",
    "#X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-Parameter Search Grid Using 10-Fold CV and Test\n",
    "print(' -- Random Forest --')\n",
    "\n",
    "n_estimators = [50,100,200]\n",
    "criterion=['gini', 'entropy']\n",
    "bootstrap= [True, False]\n",
    "max_depth=[10, 20,30]\n",
    "\n",
    "\n",
    "df_results=scores.hp_tune_Random_Forest(X_train,y_train,X_test,y_test,10,n_estimators,criterion,bootstrap,max_depth)\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[df_results['test_accuracy']==df_results['test_accuracy'].max()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fitting best Model\n",
    "print(' -- Optimal Random Forest --')\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=200,criterion='gini',bootstrap=True,max_depth=30,random_state=0,class_weight={0:1-y_train.mean(), 1:y_train.mean()},n_jobs=-1)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "precision,recall,F1,accuracy,confusion,roc_auc=scores.scores(y_test,y_pred)\n",
    "print('Optimal precision: ', precision, '  recall: ', recall, '  F1: ', F1, '  accuracy: ', accuracy)\n",
    "print('optimal Confusion matrix')\n",
    "print(confusion)\n",
    "print('Optimal AUC:',roc_auc)\n",
    "\n",
    "\n",
    "## Compare to Default Model\n",
    "print(' -- Default Random Forest --')\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(class_weight={0:1-y_train.mean(), 1:y_train.mean()},n_jobs=-1,random_state=0)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "precision,recall,F1,accuracy,confusion,roc_auc=scores.scores(y_test,y_pred)\n",
    "print('Defualt Model precision: ', precision, '  recall: ', recall, '  F1: ', F1, '  accuracy: ', accuracy)\n",
    "print('Defualt ModelConfusion matrix')\n",
    "print(confusion)\n",
    "print('Defualt ModelAUC:',roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-Parameter Search Grid Using 10-Fold CV and Test\n",
    "print(' -- Decision Trees --')\n",
    "\n",
    "criterion=['gini', 'entropy']\n",
    "max_depth=[10,20,30,50]\n",
    "split=['random','best']\n",
    "\n",
    "df_results=scores.hp_tune_Decision_tree(X_train,y_train,X_test,y_test,10,criterion,max_depth,split)\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[df_results['test_accuracy']==df_results['test_accuracy'].max()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fitting best Model\n",
    "print(' -- Optimal Decision Tree --')\n",
    "import sklearn.tree\n",
    "\n",
    "rfc = sklearn.tree.DecisionTreeClassifier(class_weight={0:1-y_train.mean(), 1:y_train.mean()},criterion='gini',max_depth=15,min_weight_fraction_leaf=0.0,random_state=0,splitter='random')\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "precision,recall,F1,accuracy,confusion,roc_auc=scores.scores(y_test,y_pred)\n",
    "print('Optimal precision: ', precision, '  recall: ', recall, '  F1: ', F1, '  accuracy: ', accuracy)\n",
    "print('optimal Confusion matrix')\n",
    "print(confusion)\n",
    "print('Optimal AUC:',roc_auc)\n",
    "\n",
    "\n",
    "print(' -- Defualt Decision Tree --')\n",
    "\n",
    "\n",
    "rfc = sklearn.tree.DecisionTreeClassifier(class_weight={0:1-y_train.mean(), 1:y_train.mean()},random_state=0)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "precision,recall,F1,accuracy,confusion,roc_auc=scores.scores(y_test,y_pred)\n",
    "print('Defualt Model precision: ', precision, '  recall: ', recall, '  F1: ', F1, '  accuracy: ', accuracy)\n",
    "print('Defualt ModelConfusion matrix')\n",
    "print(confusion)\n",
    "print('Defualt ModelAUC:',roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-Parameter Search Grid Using 10-Fold CV and Test\n",
    "print(' -- KNN --')\n",
    "\n",
    "criterion=['distance', 'uniform']\n",
    "neighbors=[2,3,5,7,10]\n",
    "distances = [1, 2, 3, 4, 5]\n",
    "\n",
    "df_results=scores.hp_tune_KNN(X_train,y_train,X_test,y_test,10,criterion,neighbors,distances)\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[df_results['test_accuracy']==df_results['test_accuracy'].max()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fitting best Model\n",
    "print(' -- Optimal KNN --')\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "rfc = KNeighborsClassifier(algorithm='auto',metric='minkowski',n_jobs=-1, n_neighbors=3, p=1,weights='uniform')\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "precision,recall,F1,accuracy,confusion,roc_auc=scores.scores(y_test,y_pred)\n",
    "print('Optimal precision: ', precision, '  recall: ', recall, '  F1: ', F1, '  accuracy: ', accuracy)\n",
    "print('optimal Confusion matrix')\n",
    "print(confusion)\n",
    "print('Optimal AUC:',roc_auc)\n",
    "\n",
    "\n",
    "print(' -- Defualt KNN --')\n",
    "\n",
    "rfc = KNeighborsClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "precision,recall,F1,accuracy,confusion,roc_auc=scores.scores(y_test,y_pred)\n",
    "print('Defualt Model precision: ', precision, '  recall: ', recall, '  F1: ', F1, '  accuracy: ', accuracy)\n",
    "print('Defualt ModelConfusion matrix')\n",
    "print(confusion)\n",
    "print('Defualt ModelAUC:',roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-Parameter Search Grid Using 10-Fold CV and Test\n",
    "print(' -- SVM --')\n",
    "\n",
    "kernel=['rbf', 'linear', 'poly', 'sigmoid']\n",
    "gammas = [0.1,.5, 1]\n",
    "cs = [0.1,.5, 1, 3,10]\n",
    "\n",
    "df_results=scores.hp_tune_SVM(X_train,y_train,X_test,y_test,10,kernel,gammas,cs)\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[df_results['test_accuracy']==df_results['test_accuracy'].max()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fitting best Model\n",
    "print(' -- Optimal SVM --')\n",
    "import sklearn.svm\n",
    "\n",
    "rfc = sklearn.svm.SVC(kernel='poly', gamma=.1,C=3,random_state=0,class_weight={0:1-y_train.mean(), 1:y_train.mean()})\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "precision,recall,F1,accuracy,confusion,roc_auc=scores.scores(y_test,y_pred)\n",
    "print('Optimal precision: ', precision, '  recall: ', recall, '  F1: ', F1, '  accuracy: ', accuracy)\n",
    "print('optimal Confusion matrix')\n",
    "print(confusion)\n",
    "print('Optimal AUC:',roc_auc)\n",
    "\n",
    "\n",
    "print(' -- Defualt SVM --')\n",
    "\n",
    "rfc = sklearn.svm.SVC()\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "precision,recall,F1,accuracy,confusion,roc_auc=scores.scores(y_test,y_pred)\n",
    "print('Defualt Model precision: ', precision, '  recall: ', recall, '  F1: ', F1, '  accuracy: ', accuracy)\n",
    "print('Defualt ModelConfusion matrix')\n",
    "print(confusion)\n",
    "print('Defualt ModelAUC:',roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-Parameter Search Grid Using 10-Fold CV and Test\n",
    "print(' -- Logistic Regression --')\n",
    "\n",
    "criterion=['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "\n",
    "df_results=scores.hp_tune_log_reg(X_train,y_train,X_test,y_test,10,criterion,)\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[df_results['test_accuracy']==df_results['test_accuracy'].max()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fitting best Model\n",
    "print(' -- Optimal Logistic Regression --')\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "rfc =LogisticRegression(class_weight={0:1-y_train.mean(), 1:y_train.mean()},random_state=0,solver='lbfgs')\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "precision,recall,F1,accuracy,confusion,roc_auc=scores.scores(y_test,y_pred)\n",
    "print('Optimal precision: ', precision, '  recall: ', recall, '  F1: ', F1, '  accuracy: ', accuracy)\n",
    "print('optimal Confusion matrix')\n",
    "print(confusion)\n",
    "print('Optimal AUC:',roc_auc)\n",
    "\n",
    "\n",
    "print(' -- Defualt logistic Regression --')\n",
    "\n",
    "rfc =LogisticRegression(class_weight={0:1-y_train.mean(), 1:y_train.mean()},random_state=0)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "precision,recall,F1,accuracy,confusion,roc_auc=scores.scores(y_test,y_pred)\n",
    "print('Defualt Model precision: ', precision, '  recall: ', recall, '  F1: ', F1, '  accuracy: ', accuracy)\n",
    "print('Defualt ModelConfusion matrix')\n",
    "print(confusion)\n",
    "print('Defualt ModelAUC:',roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
