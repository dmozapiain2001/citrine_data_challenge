{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import scipy.ndimage as ndimage\n",
    "from torchvision import transforms, utils\n",
    "from toolz.curried import pipe, curry, compose\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "\n",
    "import scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['training_data.csv', 'test_data.csv']\n",
      "(2572, 99)\n",
      "/Users/davidmontesdeoca/Desktop/challenge_data/data/training_data.csv\n"
     ]
    }
   ],
   "source": [
    "path_f=os.getcwd()\n",
    "\n",
    "path_f_1=os.path.join(path_f, 'data')\n",
    "\n",
    "\n",
    "names=[]\n",
    "for files_txts in os.listdir(path_f_1):\n",
    "    if files_txts.endswith(\".csv\"):\n",
    "        #print(files_txts)\n",
    "        names.append(files_txts)\n",
    "\n",
    "print(names)\n",
    "path_train=os.path.join(path_f_1, names[0])\n",
    "path_test=os.path.join(path_f_1, names[1])\n",
    "\n",
    "df_train=pd.read_csv(path_train)\n",
    "print(df_train.shape)\n",
    "print(path_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2572, 110)\n",
      "(2572, 110)\n",
      "(1228, 110)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formulaA</th>\n",
       "      <th>formulaB</th>\n",
       "      <th>formulaA_elements_AtomicVolume</th>\n",
       "      <th>formulaB_elements_AtomicVolume</th>\n",
       "      <th>formulaA_elements_AtomicWeight</th>\n",
       "      <th>formulaB_elements_AtomicWeight</th>\n",
       "      <th>formulaA_elements_BoilingT</th>\n",
       "      <th>formulaB_elements_BoilingT</th>\n",
       "      <th>formulaA_elements_BulkModulus</th>\n",
       "      <th>formulaB_elements_BulkModulus</th>\n",
       "      <th>...</th>\n",
       "      <th>A82B</th>\n",
       "      <th>A73B</th>\n",
       "      <th>A64B</th>\n",
       "      <th>A55B</th>\n",
       "      <th>A46B</th>\n",
       "      <th>A37B</th>\n",
       "      <th>A28B</th>\n",
       "      <th>A19B</th>\n",
       "      <th>B</th>\n",
       "      <th>Stable_compunds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89</td>\n",
       "      <td>47</td>\n",
       "      <td>37.433086</td>\n",
       "      <td>17.075648</td>\n",
       "      <td>227.0</td>\n",
       "      <td>107.868200</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>2435.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89</td>\n",
       "      <td>13</td>\n",
       "      <td>37.433086</td>\n",
       "      <td>16.594425</td>\n",
       "      <td>227.0</td>\n",
       "      <td>26.981539</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>2792.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89</td>\n",
       "      <td>33</td>\n",
       "      <td>37.433086</td>\n",
       "      <td>21.723966</td>\n",
       "      <td>227.0</td>\n",
       "      <td>74.921600</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>887.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89</td>\n",
       "      <td>56</td>\n",
       "      <td>37.433086</td>\n",
       "      <td>64.969282</td>\n",
       "      <td>227.0</td>\n",
       "      <td>137.327000</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>2143.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89</td>\n",
       "      <td>83</td>\n",
       "      <td>37.433086</td>\n",
       "      <td>35.483459</td>\n",
       "      <td>227.0</td>\n",
       "      <td>208.980400</td>\n",
       "      <td>3473.0</td>\n",
       "      <td>1837.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   formulaA  formulaB  formulaA_elements_AtomicVolume  \\\n",
       "0        89        47                       37.433086   \n",
       "1        89        13                       37.433086   \n",
       "2        89        33                       37.433086   \n",
       "3        89        56                       37.433086   \n",
       "4        89        83                       37.433086   \n",
       "\n",
       "   formulaB_elements_AtomicVolume  formulaA_elements_AtomicWeight  \\\n",
       "0                       17.075648                           227.0   \n",
       "1                       16.594425                           227.0   \n",
       "2                       21.723966                           227.0   \n",
       "3                       64.969282                           227.0   \n",
       "4                       35.483459                           227.0   \n",
       "\n",
       "   formulaB_elements_AtomicWeight  formulaA_elements_BoilingT  \\\n",
       "0                      107.868200                      3473.0   \n",
       "1                       26.981539                      3473.0   \n",
       "2                       74.921600                      3473.0   \n",
       "3                      137.327000                      3473.0   \n",
       "4                      208.980400                      3473.0   \n",
       "\n",
       "   formulaB_elements_BoilingT  formulaA_elements_BulkModulus  \\\n",
       "0                      2435.0                            0.0   \n",
       "1                      2792.0                            0.0   \n",
       "2                       887.0                            0.0   \n",
       "3                      2143.0                            0.0   \n",
       "4                      1837.0                            0.0   \n",
       "\n",
       "   formulaB_elements_BulkModulus       ...         A82B  A73B  A64B  A55B  \\\n",
       "0                          100.0       ...            0     1     0     1   \n",
       "1                           76.0       ...            0     1     0     0   \n",
       "2                           22.0       ...            0     0     0     0   \n",
       "3                            9.6       ...            0     0     0     0   \n",
       "4                           31.0       ...            0     0     0     0   \n",
       "\n",
       "   A46B  A37B  A28B  A19B  B  Stable_compunds  \n",
       "0     0     0     0     0  1                1  \n",
       "1     0     0     0     0  1                1  \n",
       "2     0     0     0     0  1                0  \n",
       "3     0     0     0     0  1                0  \n",
       "4     0     0     0     0  1                0  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stab_vector=df_train['stabilityVec'].values\n",
    "y=[]\n",
    "for x in stab_vector:\n",
    "    #print(x)\n",
    "    a=np.fromstring(x[1:-1],sep=',').astype(int)\n",
    "    y.append(a)\n",
    "y=np.array(y) \n",
    "\n",
    "df_tmp = pd.DataFrame(y, columns = ['A', 'A91B', 'A82B','A73B','A64B','A55B','A46B','A37B','A28B','A19B','B'])\n",
    "stab_vec_list=[ 'A91B', 'A82B','A73B','A64B','A55B','A46B','A37B','A28B','A19B','Stable_compunds']\n",
    "\n",
    "df_train=df_train.drop(\"stabilityVec\",axis=1) #removing the results which originally are a string\n",
    "feature_cols=list(df_train)\n",
    "\n",
    "\n",
    "\n",
    "df_train['formulaA']=df_train['formulaA_elements_Number']\n",
    "df_train['formulaB']=df_train['formulaB_elements_Number']\n",
    "\n",
    "\n",
    "df_train=pd.concat([df_train, df_tmp],axis=1)\n",
    "\n",
    "y_all=df_train[stab_vec_list[0:-1]]\n",
    "\n",
    "\n",
    "df_tmp_stable = pd.DataFrame( columns = ['Stable_compunds'])\n",
    "df_tmp_stable['Stable_compunds']=np.logical_not(y_all.sum(axis=1)==0).astype(int) ## A one means it has a stable value  a 0 \n",
    "\n",
    "df_train=pd.concat([df_train, df_tmp_stable],axis=1)\n",
    "\n",
    "y_all=df_train[stab_vec_list]\n",
    "print(df_train.shape)\n",
    "\n",
    "\n",
    "print(df_train.shape)\n",
    "\n",
    "\n",
    "df_stable=df_train.loc[np.logical_not(y_all.sum(axis=1)==0)]\n",
    "print(df_stable.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2572, 98) (2572, 10)\n"
     ]
    }
   ],
   "source": [
    "#X_train_new=df_stable[feature_cols] #training only on stable elements\n",
    "#y_target=df_stable[stab_vec_list]\n",
    "###\n",
    "\n",
    "X_train_new=df_train[feature_cols]   #training  on all elements\n",
    "y_target=df_train[stab_vec_list]\n",
    "\n",
    "print(X_train_new.shape,y_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2572, 98)\n",
      "(2572, 98)\n",
      "(2572, 98)\n",
      "(2572, 98)\n",
      "(2572, 20)\n",
      "(2572, 98)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/pytorch/lib/python3.5/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# Normalizing such that the magnitude is one\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "X_train_new_mag_1=normalize(X_train_new, axis=1) # vector magnitude is one\n",
    "X_train_new_mag_1=pd.DataFrame(data=X_train_new_mag_1,columns=feature_cols)\n",
    "print(X_train_new_mag_1.shape)\n",
    "\n",
    "\n",
    "## Normalizing by Zscore\n",
    "from scipy.stats import zscore\n",
    "X_train_new_Z_score=X_train_new.apply(zscore)\n",
    "print(X_train_new_Z_score.shape)\n",
    "\n",
    "\n",
    "\n",
    "## Normalizing so that range is 0-1\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train_new_0_1=min_max_scaler.fit_transform(X_train_new)\n",
    "X_train_new_0_1=pd.DataFrame(data=X_train_new_0_1,columns=feature_cols)\n",
    "print(X_train_new_0_1.shape)\n",
    "\n",
    "\n",
    "## Normalizing so that range is -1 to 1\n",
    "from sklearn import preprocessing\n",
    "max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "X_train_new_m1_p1=max_abs_scaler.fit_transform(X_train_new)\n",
    "X_train_new_m1_p1=pd.DataFrame(data=X_train_new_m1_p1,columns=feature_cols)\n",
    "print(X_train_new_m1_p1.shape)\n",
    "\n",
    "\n",
    "# Using PCA as input\n",
    "X_train_4_PCA=df_train[feature_cols]\n",
    "indx_4_PC=X_train_4_PCA.index\n",
    "X_train_new_mag_1_PCA=normalize(X_train_4_PCA, axis=1)\n",
    "\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X_train_new_mag_1_PCA)\n",
    "components = pca.components_[:20,:]\n",
    "new_data = np.dot(X_train_new_mag_1_PCA, components.T)\n",
    "X_train_new_PCA=new_data\n",
    "\n",
    "print(X_train_new_PCA.shape)\n",
    "\n",
    "\n",
    "## Taking Logarithm of High Values\n",
    "\n",
    "X_train_new_log=X_train_new.copy()\n",
    "X_train_new_log[X_train_new_log>100]=X_train_new_log[X_train_new_log>100].apply(np.log)\n",
    "print(X_train_new_log.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")#device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(98, 60),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(60, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(20, 10),\n",
    "            nn.ReLU())\n",
    "\n",
    "    def forward(self, batch):\n",
    "        return self.layers(batch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Network().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class feature_Dataset(Dataset):\n",
    "    \"\"\"Face landmarks Dataset\"\"\"\n",
    "    \n",
    "    def __init__(self, X_features, y_target):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"        \n",
    "        self.X_features=X_features\n",
    "        self.y_target=y_target\n",
    "        assert len(X_features) == len(y_target)\n",
    "        \n",
    "\n",
    "\n",
    "        self.X_features = torch.from_numpy(X_features.values).float()\n",
    "        self.y_target = torch.from_numpy(y_target.values).float()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X_features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        \n",
    "        item = {'index': idx}\n",
    "        item['features'] = self.X_features[idx,:]\n",
    "        item['outputs'] = self.y_target[idx,:]\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2186, 98) (2186, 10)\n",
      "(386, 98) (386, 10)\n"
     ]
    }
   ],
   "source": [
    "## test-train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_new_m1_p1, y_target,\n",
    "                                                    test_size=.15,\n",
    "                                                    shuffle=True,\n",
    "                                                    random_state=42)\n",
    "\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape,y_test.shape)\n",
    "#X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>formulaA</th>\n",
       "      <th>formulaB</th>\n",
       "      <th>formulaA_elements_AtomicVolume</th>\n",
       "      <th>formulaB_elements_AtomicVolume</th>\n",
       "      <th>formulaA_elements_AtomicWeight</th>\n",
       "      <th>formulaB_elements_AtomicWeight</th>\n",
       "      <th>formulaA_elements_BoilingT</th>\n",
       "      <th>formulaB_elements_BoilingT</th>\n",
       "      <th>formulaA_elements_BulkModulus</th>\n",
       "      <th>formulaB_elements_BulkModulus</th>\n",
       "      <th>...</th>\n",
       "      <th>formulaA_elements_Row</th>\n",
       "      <th>formulaB_elements_Row</th>\n",
       "      <th>formulaA_elements_ShearModulus</th>\n",
       "      <th>formulaB_elements_ShearModulus</th>\n",
       "      <th>formulaA_elements_SpaceGroupNumber</th>\n",
       "      <th>formulaB_elements_SpaceGroupNumber</th>\n",
       "      <th>avg_coordination_A</th>\n",
       "      <th>avg_coordination_B</th>\n",
       "      <th>avg_nearest_neighbor_distance_A</th>\n",
       "      <th>avg_nearest_neighbor_distance_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1711</th>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.215054</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.819581</td>\n",
       "      <td>0.168375</td>\n",
       "      <td>0.698245</td>\n",
       "      <td>0.299370</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.044737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.274775</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.982533</td>\n",
       "      <td>0.982533</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.528179</td>\n",
       "      <td>0.731902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>0.376344</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.335690</td>\n",
       "      <td>0.050459</td>\n",
       "      <td>0.056568</td>\n",
       "      <td>0.732663</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.086842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.279476</td>\n",
       "      <td>0.847162</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.448680</td>\n",
       "      <td>0.267487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>0.516129</td>\n",
       "      <td>0.301075</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.472258</td>\n",
       "      <td>0.246581</td>\n",
       "      <td>0.177202</td>\n",
       "      <td>0.542852</td>\n",
       "      <td>0.110526</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.085586</td>\n",
       "      <td>0.342342</td>\n",
       "      <td>0.847162</td>\n",
       "      <td>0.982533</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.564966</td>\n",
       "      <td>0.465925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.215054</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.168375</td>\n",
       "      <td>0.432324</td>\n",
       "      <td>0.299370</td>\n",
       "      <td>0.676095</td>\n",
       "      <td>0.044737</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.675676</td>\n",
       "      <td>0.982533</td>\n",
       "      <td>0.982533</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.731902</td>\n",
       "      <td>0.511166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.053763</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.218444</td>\n",
       "      <td>0.045419</td>\n",
       "      <td>0.501619</td>\n",
       "      <td>0.728063</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.518018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.724891</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.463537</td>\n",
       "      <td>0.324075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      formulaA  formulaB  formulaA_elements_AtomicVolume  \\\n",
       "1711  0.838710  0.215054                        0.000413   \n",
       "332   0.376344  0.064516                        0.001142   \n",
       "432   0.516129  0.301075                        0.000580   \n",
       "407   0.215054  0.483871                        0.001153   \n",
       "508   0.258065  0.053763                        0.000325   \n",
       "\n",
       "      formulaB_elements_AtomicVolume  formulaA_elements_AtomicWeight  \\\n",
       "1711                        0.001153                        0.819581   \n",
       "332                         0.000237                        0.335690   \n",
       "432                         0.000294                        0.472258   \n",
       "407                         0.000369                        0.168375   \n",
       "508                         0.000196                        0.218444   \n",
       "\n",
       "      formulaB_elements_AtomicWeight  formulaA_elements_BoilingT  \\\n",
       "1711                        0.168375                    0.698245   \n",
       "332                         0.050459                    0.056568   \n",
       "432                         0.246581                    0.177202   \n",
       "407                         0.432324                    0.299370   \n",
       "508                         0.045419                    0.501619   \n",
       "\n",
       "      formulaB_elements_BoilingT  formulaA_elements_BulkModulus  \\\n",
       "1711                    0.299370                       0.605263   \n",
       "332                     0.732663                       0.005000   \n",
       "432                     0.542852                       0.110526   \n",
       "407                     0.676095                       0.044737   \n",
       "508                     0.728063                       0.421053   \n",
       "\n",
       "      formulaB_elements_BulkModulus               ...                 \\\n",
       "1711                       0.044737               ...                  \n",
       "332                        0.086842               ...                  \n",
       "432                        0.473684               ...                  \n",
       "407                        1.000000               ...                  \n",
       "508                        0.842105               ...                  \n",
       "\n",
       "      formulaA_elements_Row  formulaB_elements_Row  \\\n",
       "1711               0.857143               0.571429   \n",
       "332                0.571429               0.285714   \n",
       "432                0.714286               0.571429   \n",
       "407                0.571429               0.714286   \n",
       "508                0.571429               0.285714   \n",
       "\n",
       "      formulaA_elements_ShearModulus  formulaB_elements_ShearModulus  \\\n",
       "1711                        0.274775                        0.033333   \n",
       "332                         0.000000                        0.000000   \n",
       "432                         0.085586                        0.342342   \n",
       "407                         0.033333                        0.675676   \n",
       "508                         0.518018                        0.000000   \n",
       "\n",
       "      formulaA_elements_SpaceGroupNumber  formulaB_elements_SpaceGroupNumber  \\\n",
       "1711                            0.982533                            0.982533   \n",
       "332                             0.279476                            0.847162   \n",
       "432                             0.847162                            0.982533   \n",
       "407                             0.982533                            0.982533   \n",
       "508                             1.000000                            0.724891   \n",
       "\n",
       "      avg_coordination_A  avg_coordination_B  avg_nearest_neighbor_distance_A  \\\n",
       "1711            1.000000            1.000000                         0.528179   \n",
       "332             0.083333            0.250000                         0.448680   \n",
       "432             0.500000            1.000000                         0.564966   \n",
       "407             1.000000            1.000000                         0.731902   \n",
       "508             0.666667            0.458333                         0.463537   \n",
       "\n",
       "      avg_nearest_neighbor_distance_B  \n",
       "1711                         0.731902  \n",
       "332                          0.267487  \n",
       "432                          0.465925  \n",
       "407                          0.511166  \n",
       "508                          0.324075  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dataset = feature_Dataset(X_train, y_train) ## Now you can feed any X-train and Y-train. normalize it and feed the highest pearson correlated one\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=6)\n",
    "\n",
    "val_dataset = feature_Dataset(X_test, y_test)\n",
    "\n",
    "valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:  tensor([[ 0.8387,  0.2151,  0.0004,  0.0012,  0.8196,  0.1684,  0.6982,  0.2994,\n",
      "          0.6053,  0.0447,  0.5556,  0.1111,  0.5574,  0.7213,  0.9336,  0.0686,\n",
      "          0.9622,  0.4919,  0.7600,  0.3333,  0.3644,  0.2486,  0.0000,  0.0000,\n",
      "         -0.4652, -0.1503,  0.5062,  0.6884,  0.5062,  0.6884,  0.0000,  0.0000,\n",
      "          0.1297,  0.3263,  0.5612,  0.3980,  1.0000,  0.1648,  0.0259,  0.1261,\n",
      "          0.3417,  0.3426,  0.1889,  0.0727,  0.1622,  0.4747,  0.0000,  1.0000,\n",
      "          1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.5340,  0.2917,  0.6176,  0.0686,  0.5265,  0.7614,\n",
      "          0.0909,  0.0000,  0.8276,  0.0690,  0.1111,  0.0000,  0.9000,  0.0000,\n",
      "          0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          1.0000,  0.0000,  0.5000,  1.0000,  0.8387,  0.2151,  0.1094,  0.4331,\n",
      "          0.8571,  0.5714,  0.2748,  0.0333,  0.9825,  0.9825,  1.0000,  1.0000,\n",
      "          0.5282,  0.7319]])\n",
      "outputs:  tensor([0., 0., 0., 1., 0., 0., 1., 1., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "item = train_dataset[0]\n",
    "\n",
    "x = item['features'][None]\n",
    "print(\"features: \", x)\n",
    "y = item['outputs']\n",
    "print(\"outputs: \", y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(y1, y2):\n",
    "    \"\"\"standard MSE definition\"\"\"\n",
    "    return ((y1 - y2) ** 2).sum() / y1.data.nelement() * 500\n",
    "\n",
    "\n",
    "def class_loss(y1, y2):\n",
    "    \"\"\"Standard MAE definition\"\"\"\n",
    "    return ((y1 - y2).abs()).sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of steps per epoch: 35\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "num_epochs = 20\n",
    "learning_rate = .00001\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = class_loss\n",
    "#criterion = nn.MultiLabelSoftMarginLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "total_step = len(trainloader)\n",
    "print(\"No. of steps per epoch: %d\" % total_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function class_loss at 0x1a1e082c80>\n",
      "Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 1e-05\n",
      "    weight_decay: 0\n",
      ")\n",
      "Epoch [1/20], Step [0/35], Loss: 108.000000, Val Loss: 17.600000\n",
      "Epoch [1/20], Step [0/35], Loss: 108.000000, Val Loss: 33.400000\n",
      "Epoch [1/20], Step [0/35], Loss: 108.000000, Val Loss: 50.600000\n",
      "Epoch [1/20], Step [0/35], Loss: 108.000000, Val Loss: 70.200000\n",
      "Epoch [2/20], Step [0/35], Loss: 108.000000, Val Loss: 15.000000\n",
      "Epoch [2/20], Step [0/35], Loss: 108.000000, Val Loss: 38.800000\n",
      "Epoch [2/20], Step [0/35], Loss: 108.000000, Val Loss: 57.200000\n",
      "Epoch [2/20], Step [0/35], Loss: 108.000000, Val Loss: 71.200000\n",
      "Epoch [3/20], Step [0/35], Loss: 91.000000, Val Loss: 13.400000\n",
      "Epoch [3/20], Step [0/35], Loss: 91.000000, Val Loss: 30.400000\n",
      "Epoch [3/20], Step [0/35], Loss: 91.000000, Val Loss: 50.400000\n",
      "Epoch [3/20], Step [0/35], Loss: 91.000000, Val Loss: 67.000000\n",
      "Epoch [4/20], Step [0/35], Loss: 76.000000, Val Loss: 17.000000\n",
      "Epoch [4/20], Step [0/35], Loss: 76.000000, Val Loss: 34.000000\n",
      "Epoch [4/20], Step [0/35], Loss: 76.000000, Val Loss: 52.000000\n",
      "Epoch [4/20], Step [0/35], Loss: 76.000000, Val Loss: 64.800000\n",
      "Epoch [5/20], Step [0/35], Loss: 112.000000, Val Loss: 16.400000\n",
      "Epoch [5/20], Step [0/35], Loss: 112.000000, Val Loss: 34.000000\n",
      "Epoch [5/20], Step [0/35], Loss: 112.000000, Val Loss: 54.800000\n",
      "Epoch [5/20], Step [0/35], Loss: 112.000000, Val Loss: 72.000000\n",
      "Epoch [6/20], Step [0/35], Loss: 118.000000, Val Loss: 19.200000\n",
      "Epoch [6/20], Step [0/35], Loss: 118.000000, Val Loss: 33.600000\n",
      "Epoch [6/20], Step [0/35], Loss: 118.000000, Val Loss: 55.200000\n",
      "Epoch [6/20], Step [0/35], Loss: 118.000000, Val Loss: 74.800000\n",
      "Epoch [7/20], Step [0/35], Loss: 73.000000, Val Loss: 16.400000\n",
      "Epoch [7/20], Step [0/35], Loss: 73.000000, Val Loss: 32.200000\n",
      "Epoch [7/20], Step [0/35], Loss: 73.000000, Val Loss: 48.600000\n",
      "Epoch [7/20], Step [0/35], Loss: 73.000000, Val Loss: 64.600000\n",
      "Epoch [8/20], Step [0/35], Loss: 74.000000, Val Loss: 19.000000\n",
      "Epoch [8/20], Step [0/35], Loss: 74.000000, Val Loss: 33.800000\n",
      "Epoch [8/20], Step [0/35], Loss: 74.000000, Val Loss: 47.800000\n",
      "Epoch [8/20], Step [0/35], Loss: 74.000000, Val Loss: 65.600000\n",
      "Epoch [9/20], Step [0/35], Loss: 99.000000, Val Loss: 16.600000\n",
      "Epoch [9/20], Step [0/35], Loss: 99.000000, Val Loss: 30.200000\n",
      "Epoch [9/20], Step [0/35], Loss: 99.000000, Val Loss: 49.600000\n",
      "Epoch [9/20], Step [0/35], Loss: 99.000000, Val Loss: 69.200000\n",
      "Epoch [10/20], Step [0/35], Loss: 97.000000, Val Loss: 14.000000\n",
      "Epoch [10/20], Step [0/35], Loss: 97.000000, Val Loss: 35.000000\n",
      "Epoch [10/20], Step [0/35], Loss: 97.000000, Val Loss: 51.200000\n",
      "Epoch [10/20], Step [0/35], Loss: 97.000000, Val Loss: 67.200000\n"
     ]
    }
   ],
   "source": [
    "print(criterion)\n",
    "print(optimizer)\n",
    "for epoch in range(10):\n",
    "    if epoch > 0:\n",
    "        learning_rate = .00001\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    elif epoch >= 10:\n",
    "        learning_rate = 0.0002\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    elif epoch > 80:\n",
    "        learning_rate = 0.0001\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for i, item in enumerate(trainloader):\n",
    "        model.train()\n",
    "        x = item['features'].to(device)\n",
    "        target = item['outputs'].to(device)\n",
    "        # Forward pass\n",
    "        output = model(x)\n",
    "        output1=Variable(data=(output>.9).float(), requires_grad=True)\n",
    "        loss = criterion(output1, target)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i % 35 == 0:\n",
    "            niter = 5\n",
    "            val_loss=0\n",
    "            for i1, item1 in enumerate(valloader):\n",
    "                x_val = item1['features'].to(device)\n",
    "                y_val = item1['outputs'].to(device)\n",
    "                model.eval()\n",
    "                y_pre = model(x_val)\n",
    "                y_pre1=Variable(data=(y_pre>.9).float(), requires_grad=True)\n",
    "                val_loss += criterion(y_pre1, y_val)\n",
    "\n",
    "                if i1 == niter-1:\n",
    "                    break\n",
    "                if val_loss.item()/niter < 6.5:\n",
    "                    torch.save(model.state_dict(), \"learnt_weights_C0_%d_%d\" % (i, epoch))\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.6f}, Val Loss: {:.6f}' \n",
    "                   .format(epoch+1, num_epochs, i, total_step, loss.item(), val_loss.item()/niter))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 1., 0., 1., 0., 0., 1.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output1[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
